[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Blog Info",
    "section": "",
    "text": "Middlebury College CSCI 0451A Blog - Col McDermott\n\n\n\nCheck out my completed blog posts from\n\n\nCSCI 0451 Machine Learning\n\n\nwith Professor Phil Chodrow"
  },
  {
    "objectID": "posts/post_2/index.html",
    "href": "posts/post_2/index.html",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "",
    "text": "The following study is an introductory exploration of an automated decision model. The primary aims of this analysis are to develop a deeper understanding of binary decision-making circumstances and how the use of ML models/algorithms can be used to assist and even automate this process. This analysis takes on a realistic problem using simulated data. Based on several characteristics of a potential borrower – like their financial status, reasons for seeking a loan, and age – is it wise or ill-advised to approve them for a given loan? The sections below attempt to produce a reasonable answer to this question through the creation of an automated decision-making model.\nThe general methodologies for this study involve an initial exploration of the data, constructing a model using certain features, and determining an optimal threshold based on a defined scoring function. It is necessary to observe some general patterns and trends present in the data before building a model. After the preliminary visualization and preprocessing steps, an initial model will be constructed and further refined using an iterative feature selection process supported by cross-validation. After an improved (by training accuracy) model is obtained, a scoring function will be defined using the weights determined by the best model version. With this scoring function, an optimal threshold can then be examined and set to maximize desirable values such as model accuracy and bank profit. Finally, with an optimal threshold selected and a refined model, the behavior of this model on unseen data can be evaluated. Following the final model’s evaluation this study concludes with a discussion of the implications behind automated decision algorithms with respect to general “fairness” from the perspective of all stakeholders (model designers, model users, and all impacted individuals, and etc.).\n\n\n\n\nCode\n# Includuing all additional imports\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport itertools\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\")\n\n\nIncluding all additional imports\nThe data used in this analysis is a simulated data set of credit bureau data based on patterns observed in real credit bureau data.\n\n\n\n\n\n\n\nCode\n# Data modification\ntrain_viz = train.copy()\nloan_status_recode = {0: \"Paid in Full\", 1: \"Defaulted\"}\nloan_intent_recode = {\"VENTURE\": \"Venture\", \"EDUCATION\": \"Education\", \"MEDICAL\": \"Medical\", \"HOMEIMPROVEMENT\": \"Home Improvement\", \"PERSONAL\": \"Personal\",\n \"DEBTCONSOLIDATION\" : \"Debt Consolidation\"}\ntrain_viz[\"loan_repayment\"] = train_viz[\"loan_status\"].map(loan_status_recode)\ntrain_viz[\"loan_intent\"] = train_viz[\"loan_intent\"].map(loan_intent_recode)\ntrain_viz.loc[train_viz[\"person_age\"] &gt;= 100, \"person_age\"] = None\ntrain_viz = train_viz.dropna()\n\n# Subsetting data by loan status\ndefaulted = train_viz[train_viz[\"loan_status\"] == 1].copy().dropna()\nrepaid = train_viz[train_viz[\"loan_status\"] == 0].copy().dropna()\n\n\nModifying training data for visualization\n\n\nCode\n# Creating linear regression models and calculating R^2 values\n## Defaulted\nc1 = np.polyfit(defaulted[\"loan_amnt\"], defaulted[\"person_income\"], 1)\np1 = np.polyval(c1, defaulted[\"loan_amnt\"])\nr1 = defaulted[\"person_income\"] - p1\nssr1 = np.sum(r1 ** 2)\nsst1 = np.sum((defaulted[\"person_income\"] - np.mean(defaulted[\"loan_amnt\"])) ** 2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Repaid\nc2 = np.polyfit(repaid[\"loan_amnt\"], repaid[\"person_income\"], 1)\np2 = np.polyval(c2, repaid[\"loan_amnt\"])\nr2 = repaid[\"person_income\"] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((repaid[\"person_income\"] - np.mean(repaid[\"loan_amnt\"]))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n\nCreating linear regression models and calculating R^2 values for subsets of defaulted and fully repaid loans\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (15, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Scatterplot and regression line for borrower income by loan amount of defaulted loans\nax[0] = sns.scatterplot(data = defaulted, x = \"loan_amnt\", y = \"person_income\", color = \"purple\", edgecolor = \"purple\", alpha = 0.25, ax = ax[0])\nsns.regplot(data = defaulted, x = \"loan_amnt\", y = \"person_income\", scatter = False, line_kws={\"color\": \"darkorange\"}, ax = ax[0])\nax[0].set_yscale(\"log\", base = 2)\nax[0].set_xlabel(\"\")\nax[0].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[0].set_xticklabels([\"$0\", \"$5000\", \"$10000\", \"$15000\", \"$20000\", \"$25000\", \"$30000\", \"$35000\"], rotation = 30, fontsize = 14)\nax[0].set_ylabel(f\"Borrower\\'s Income ($\\log_2$ scale)\", fontsize = 16, labelpad = 15)\nax[0].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19, 2**20, 2**21, 2**22, 2**23])\nax[0].set_yticklabels([\"&gt;$4000\", \"&gt;$8000\", \"&gt;$16000\", \"&gt;$32000\", \"&gt;$64000\", \"&gt;$128000\", \"&gt;$256000\", \"&gt;$512000\", \"&gt;$1024000\", \"&gt;$2048000\", \"&gt;$4096000\", \"&lt;$8192000\"], rotation = 15, fontsize = 14)\nax[0].set_title(\"Defaulted Loans\", fontsize = 18)\nax[0].text(27000, 12288, f\"     $R^2 = {rs1:.3f}$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(24000, 12288, \"\\u2013\", color = \"darkorange\", ha = \"left\", va = \"center\", fontsize = 15, fontweight = \"bold\")\n\n# Scatterplot and regression line for borrower income by loan amount of repaid loans\nax[1] = sns.scatterplot(data = repaid, x = \"loan_amnt\", y = \"person_income\", color = \"darkorange\", edgecolor = \"darkorange\", alpha = 0.5, ax = ax[1])\nsns.regplot(data = repaid, x = \"loan_amnt\", y = \"person_income\", scatter = False, line_kws={\"color\": \"purple\"}, ax = ax[1])\nax[1].set_yscale(\"log\", base = 2)\nax[1].set_xlabel(\"\")\nax[1].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[1].set_xticklabels([\"$0\", \"$5000\", \"$10000\", \"$15000\", \"$20000\", \"$25000\", \"$30000\", \"$35000\"], rotation=30, fontsize = 14)\nax[1].set_ylabel(\"\")\nax[1].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19, 2**20, 2**21, 2**22, 2**23])\nax[1].set_yticklabels(12 * [\"\"], rotation = 15)\nax[1].set_title(\"Repaid Loans\", fontsize = 18)\nax[1].text(27000, 12288, f\"     $R^2 = {rs2:.3f}$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(24000, 12288, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight = \"bold\")\n\nfig.suptitle(\"Borrower\\'s Income by Loan Amount Displayed by Loan Repayment Status\", fontsize = 20)\nfig.text(0.47, 0.025, \"Loan Amount\", fontsize = 16)\nplt.subplots_adjust(wspace = 0.1)\n\n\n\n\n\n\n\n\n\nFigure 1\nThe plots above display the relationship between a borrower’s income and the loan amount borrowed for both defaulted and fully repaid loans. To assist the visualization of the data points, the dependent variable person_income is adjusted using a \\(\\log_2\\) scale. With this scale in place and for both defaulted and fully repaid loans, there appears to be a transformed linear relationship between a borrower’s income and the loan amount borrowed. Additionally, this transformed linear relationship appears to be positive and moderately strong (given both \\(R^2\\) values &gt; 0.6). For both borrowers who defaulted on loans and borrowers who fully repaid their loans, it appears that as the loan amount increases, a borrower’s income increases (adjusted by a \\(\\log_2\\) scale). Considering this observed relationship, it is reasonable to assert that bigger loans are borrowed by individuals with higher income levels, regardless of whether or not those individuals defaulted or fully repaid their loans.\n\n\nCode\n# Subsetting data to the three most common loan intents\ncommon_loan_intents = train_viz.copy()\ncommon_loan_intents = train_viz[train_viz[\"loan_intent\"].isin([\"Education\", \"Medical\", \"Venture\"])].copy()\n\n# Creating Boxen Plot\nfig, ax = plt.subplots(1, 1, figsize = (10, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\np = sns.boxenplot(common_loan_intents, x = \"loan_intent\", y = \"person_age\", hue = \"loan_repayment\", palette = [\"darkorange\", \"purple\"])\np.set_xlabel(\"Intention for Loan\", fontsize = 14)\np.set_ylabel(\"Borrower\\'s Age\", fontsize = 14)\np.set_xticks([\"Education\", \"Medical\", \"Venture\"])\np.legend(title = \"Loan Status\", frameon = True)\np.set_title(\"Distribution of Borrower\\'s Age for Top Three Loan Intents\\nGrouped by Loan Repayment Status\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nFigure 2\nThe figure above shows an sns.boxenplot displaying the distribution of borrower’s age for the three most common loan intents across both defaulted and fully repaid loans.\nFor education loans: The median age of both borrowers who defaulted on loans and borrowers who fully repaid their loans is less than or equal to that of defaulting and repaying borrowers taking out medical and venture loans. Additionally, the median age of educational loan borrowers is lower for those who fully repaid their loans than it is for those who defaulted – Thus, a topic for another analysis could be to explore how the age of educational loan borrowers has an impact on such loans being repaid.\nFor medical loans: It appears that the median age of borrowers is greater than those taking out loans for education or venture. There is also very little visually observable difference in the median age of borrowers who defaulted and borrowers who fully repaid their medical loans.\nFor venture loans: The median age of borrowers who fully repaid their loans is greater than that of those who defaulted on their loans. Similarly to the topic posed for educational loan borrowers, it could be interesting to explore in a future study how the age of venture loan borrowers has an effect on such loans being repaid.\n\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.rename(columns = {\"loan_repayment\": \"Loan Repayment\", \"loan_amnt\": \"Loan Amount\", \"person_income\": \"Borrower\\'s Income\", \"loan_intent\": \"Loan Intent\", \"person_age\": \"Borrower\\'s Age\", \"loan_percent_income\": \"Loan Percent Income\"}).copy()\nsum_stats = sum_stats.groupby([\"Loan Repayment\", \"Loan Intent\"]).aggregate({\"Loan Amount\" : [\"mean\", \"std\", cv], \n                                                             \"Borrower\\'s Income\" : [\"mean\", \"std\", cv], \"Loan Percent Income\": [\"mean\", \"std\", cv], \n                                                             \"Borrower\\'s Age\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {\"mean\": \"Mean\", \"std\": \"STD\", \"cv\": \"CV (%)\"})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nLoan Amount\nBorrower's Income\nLoan Percent Income\nBorrower's Age\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nLoan Repayment\nLoan Intent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefaulted\nDebt Consolidation\n11283.45\n7357.29\n65.20\n54553.15\n37624.33\n68.97\n0.24\n0.13\n57.00\n27.76\n6.52\n23.49\n\n\nEducation\n10912.82\n6979.08\n63.95\n47283.67\n30264.34\n64.01\n0.26\n0.13\n51.90\n27.09\n6.10\n22.50\n\n\nHome Improvement\n10035.04\n7324.85\n72.99\n49794.13\n33062.93\n66.40\n0.22\n0.13\n57.24\n27.62\n6.04\n21.86\n\n\nMedical\n11438.49\n7190.60\n62.86\n52477.12\n44092.21\n84.02\n0.24\n0.13\n54.74\n27.70\n6.31\n22.78\n\n\nPersonal\n10459.89\n6884.86\n65.82\n46965.14\n39080.81\n83.21\n0.25\n0.13\n51.99\n27.24\n6.09\n22.37\n\n\nVenture\n11115.68\n6695.34\n60.23\n44439.34\n27743.83\n62.43\n0.28\n0.13\n47.39\n26.74\n5.45\n20.38\n\n\nPaid in Full\nDebt Consolidation\n9050.14\n5810.33\n64.20\n72388.92\n61644.36\n85.16\n0.14\n0.08\n58.11\n27.54\n5.66\n20.56\n\n\nEducation\n9206.44\n6010.44\n65.29\n67866.15\n41045.51\n60.48\n0.15\n0.09\n57.71\n26.43\n5.49\n20.79\n\n\nHome Improvement\n10518.51\n6398.11\n60.83\n82499.92\n50452.00\n61.15\n0.14\n0.09\n61.15\n29.47\n5.48\n18.60\n\n\nMedical\n8570.88\n5645.54\n65.87\n65116.70\n51476.94\n79.05\n0.15\n0.08\n56.46\n27.96\n6.17\n22.07\n\n\nPersonal\n9441.60\n6133.81\n64.97\n72343.94\n54121.45\n74.81\n0.15\n0.09\n57.83\n28.49\n7.42\n26.03\n\n\nVenture\n9307.47\n6064.40\n65.16\n70493.68\n58762.60\n83.36\n0.15\n0.09\n59.45\n27.74\n5.98\n21.57\n\n\n\n\n\n\n\nIn creating the table above, I did some brief research on CV to more easily interpret the STD and wrote the helper method\nTable 1\nThe table above presents some general summary statistics from the data. I was interested in examining the mean, STD, and CV for some of the primary quantitative features in the data (loan_amnt, person_income, loan_percent_income, person_age) across each loan intent for both defaulted and fully repaid loans.\nFor Defaulted Loans:\n\nMedical loans are greatest in size on average compared to the other loan intents.\n\nHome Improvement loans are the smallest in size on average.\n\nDebt Consolidation loans are taken out by borrowers with the greatest average income.\n\nVenture loans are taken out by borrowers with the smallest average income.\n\nVenture loans have the largest average loan-value-percent-income in borrowers\n\nHome improvement loans have the smallest average loan-value-percent-income among borrowers\n\nDebt Consolidation loans are taken out by borrowers with the largest age on average.\n\nVenture loans correspond to borrowers with the lowest age on average.\n\n\nFor Fully Repaid Loans:\n\nHome Improvement loans are greatest in size on average compared to the other loan intents.\n\nMedical loans are the smallest in size on average. (Interestingly, this is the complete opposite of defaulted loans)\n\nHome Improvement loans are taken out by borrowers with the greatest average income.\n\nMedical loans are taken out by borrowers with the smallest average income.\n\nMedical, venture, education, and personal loans share the largest average loan-value-percent-income in borrowers while home improvement and debt consolidation loans correspond to the smallest average loan-value-percent-income in borrowers.\n\nIn terms of the spread of data across the variables displayed in the table, all four features possess relatively high coefficient of variation (CV%) values. This suggests that there is a notable degree of variability in the distribution of each of these features. However, some features appear to vary more than others: Loan Amount, Borrower's Income, and Loan Percent Income all have average CV (%) values &gt; 50% while Borrower's Age has an average CV (%) \\(\\approx\\) 20%. Additionally, there appears to be no considerable difference in CV (%) across each of the recorded loan intents nor between defaulted and fully repaid loans in general."
  },
  {
    "objectID": "posts/post_2/index.html#exploring-the-data",
    "href": "posts/post_2/index.html#exploring-the-data",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "",
    "text": "Code\n# Data modification\ntrain_viz = train.copy()\nloan_status_recode = {0: \"Paid in Full\", 1: \"Defaulted\"}\nloan_intent_recode = {\"VENTURE\": \"Venture\", \"EDUCATION\": \"Education\", \"MEDICAL\": \"Medical\", \"HOMEIMPROVEMENT\": \"Home Improvement\", \"PERSONAL\": \"Personal\",\n \"DEBTCONSOLIDATION\" : \"Debt Consolidation\"}\ntrain_viz[\"loan_repayment\"] = train_viz[\"loan_status\"].map(loan_status_recode)\ntrain_viz[\"loan_intent\"] = train_viz[\"loan_intent\"].map(loan_intent_recode)\ntrain_viz.loc[train_viz[\"person_age\"] &gt;= 100, \"person_age\"] = None\ntrain_viz = train_viz.dropna()\n\n# Subsetting data by loan status\ndefaulted = train_viz[train_viz[\"loan_status\"] == 1].copy().dropna()\nrepaid = train_viz[train_viz[\"loan_status\"] == 0].copy().dropna()\n\n\nModifying training data for visualization\n\n\nCode\n# Creating linear regression models and calculating R^2 values\n## Defaulted\nc1 = np.polyfit(defaulted[\"loan_amnt\"], defaulted[\"person_income\"], 1)\np1 = np.polyval(c1, defaulted[\"loan_amnt\"])\nr1 = defaulted[\"person_income\"] - p1\nssr1 = np.sum(r1 ** 2)\nsst1 = np.sum((defaulted[\"person_income\"] - np.mean(defaulted[\"loan_amnt\"])) ** 2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Repaid\nc2 = np.polyfit(repaid[\"loan_amnt\"], repaid[\"person_income\"], 1)\np2 = np.polyval(c2, repaid[\"loan_amnt\"])\nr2 = repaid[\"person_income\"] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((repaid[\"person_income\"] - np.mean(repaid[\"loan_amnt\"]))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n\nCreating linear regression models and calculating R^2 values for subsets of defaulted and fully repaid loans\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (15, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Scatterplot and regression line for borrower income by loan amount of defaulted loans\nax[0] = sns.scatterplot(data = defaulted, x = \"loan_amnt\", y = \"person_income\", color = \"purple\", edgecolor = \"purple\", alpha = 0.25, ax = ax[0])\nsns.regplot(data = defaulted, x = \"loan_amnt\", y = \"person_income\", scatter = False, line_kws={\"color\": \"darkorange\"}, ax = ax[0])\nax[0].set_yscale(\"log\", base = 2)\nax[0].set_xlabel(\"\")\nax[0].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[0].set_xticklabels([\"$0\", \"$5000\", \"$10000\", \"$15000\", \"$20000\", \"$25000\", \"$30000\", \"$35000\"], rotation = 30, fontsize = 14)\nax[0].set_ylabel(f\"Borrower\\'s Income ($\\log_2$ scale)\", fontsize = 16, labelpad = 15)\nax[0].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19, 2**20, 2**21, 2**22, 2**23])\nax[0].set_yticklabels([\"&gt;$4000\", \"&gt;$8000\", \"&gt;$16000\", \"&gt;$32000\", \"&gt;$64000\", \"&gt;$128000\", \"&gt;$256000\", \"&gt;$512000\", \"&gt;$1024000\", \"&gt;$2048000\", \"&gt;$4096000\", \"&lt;$8192000\"], rotation = 15, fontsize = 14)\nax[0].set_title(\"Defaulted Loans\", fontsize = 18)\nax[0].text(27000, 12288, f\"     $R^2 = {rs1:.3f}$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(24000, 12288, \"\\u2013\", color = \"darkorange\", ha = \"left\", va = \"center\", fontsize = 15, fontweight = \"bold\")\n\n# Scatterplot and regression line for borrower income by loan amount of repaid loans\nax[1] = sns.scatterplot(data = repaid, x = \"loan_amnt\", y = \"person_income\", color = \"darkorange\", edgecolor = \"darkorange\", alpha = 0.5, ax = ax[1])\nsns.regplot(data = repaid, x = \"loan_amnt\", y = \"person_income\", scatter = False, line_kws={\"color\": \"purple\"}, ax = ax[1])\nax[1].set_yscale(\"log\", base = 2)\nax[1].set_xlabel(\"\")\nax[1].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[1].set_xticklabels([\"$0\", \"$5000\", \"$10000\", \"$15000\", \"$20000\", \"$25000\", \"$30000\", \"$35000\"], rotation=30, fontsize = 14)\nax[1].set_ylabel(\"\")\nax[1].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19, 2**20, 2**21, 2**22, 2**23])\nax[1].set_yticklabels(12 * [\"\"], rotation = 15)\nax[1].set_title(\"Repaid Loans\", fontsize = 18)\nax[1].text(27000, 12288, f\"     $R^2 = {rs2:.3f}$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(24000, 12288, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight = \"bold\")\n\nfig.suptitle(\"Borrower\\'s Income by Loan Amount Displayed by Loan Repayment Status\", fontsize = 20)\nfig.text(0.47, 0.025, \"Loan Amount\", fontsize = 16)\nplt.subplots_adjust(wspace = 0.1)\n\n\n\n\n\n\n\n\n\nFigure 1\nThe plots above display the relationship between a borrower’s income and the loan amount borrowed for both defaulted and fully repaid loans. To assist the visualization of the data points, the dependent variable person_income is adjusted using a \\(\\log_2\\) scale. With this scale in place and for both defaulted and fully repaid loans, there appears to be a transformed linear relationship between a borrower’s income and the loan amount borrowed. Additionally, this transformed linear relationship appears to be positive and moderately strong (given both \\(R^2\\) values &gt; 0.6). For both borrowers who defaulted on loans and borrowers who fully repaid their loans, it appears that as the loan amount increases, a borrower’s income increases (adjusted by a \\(\\log_2\\) scale). Considering this observed relationship, it is reasonable to assert that bigger loans are borrowed by individuals with higher income levels, regardless of whether or not those individuals defaulted or fully repaid their loans.\n\n\nCode\n# Subsetting data to the three most common loan intents\ncommon_loan_intents = train_viz.copy()\ncommon_loan_intents = train_viz[train_viz[\"loan_intent\"].isin([\"Education\", \"Medical\", \"Venture\"])].copy()\n\n# Creating Boxen Plot\nfig, ax = plt.subplots(1, 1, figsize = (10, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\np = sns.boxenplot(common_loan_intents, x = \"loan_intent\", y = \"person_age\", hue = \"loan_repayment\", palette = [\"darkorange\", \"purple\"])\np.set_xlabel(\"Intention for Loan\", fontsize = 14)\np.set_ylabel(\"Borrower\\'s Age\", fontsize = 14)\np.set_xticks([\"Education\", \"Medical\", \"Venture\"])\np.legend(title = \"Loan Status\", frameon = True)\np.set_title(\"Distribution of Borrower\\'s Age for Top Three Loan Intents\\nGrouped by Loan Repayment Status\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nFigure 2\nThe figure above shows an sns.boxenplot displaying the distribution of borrower’s age for the three most common loan intents across both defaulted and fully repaid loans.\nFor education loans: The median age of both borrowers who defaulted on loans and borrowers who fully repaid their loans is less than or equal to that of defaulting and repaying borrowers taking out medical and venture loans. Additionally, the median age of educational loan borrowers is lower for those who fully repaid their loans than it is for those who defaulted – Thus, a topic for another analysis could be to explore how the age of educational loan borrowers has an impact on such loans being repaid.\nFor medical loans: It appears that the median age of borrowers is greater than those taking out loans for education or venture. There is also very little visually observable difference in the median age of borrowers who defaulted and borrowers who fully repaid their medical loans.\nFor venture loans: The median age of borrowers who fully repaid their loans is greater than that of those who defaulted on their loans. Similarly to the topic posed for educational loan borrowers, it could be interesting to explore in a future study how the age of venture loan borrowers has an effect on such loans being repaid.\n\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.rename(columns = {\"loan_repayment\": \"Loan Repayment\", \"loan_amnt\": \"Loan Amount\", \"person_income\": \"Borrower\\'s Income\", \"loan_intent\": \"Loan Intent\", \"person_age\": \"Borrower\\'s Age\", \"loan_percent_income\": \"Loan Percent Income\"}).copy()\nsum_stats = sum_stats.groupby([\"Loan Repayment\", \"Loan Intent\"]).aggregate({\"Loan Amount\" : [\"mean\", \"std\", cv], \n                                                             \"Borrower\\'s Income\" : [\"mean\", \"std\", cv], \"Loan Percent Income\": [\"mean\", \"std\", cv], \n                                                             \"Borrower\\'s Age\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {\"mean\": \"Mean\", \"std\": \"STD\", \"cv\": \"CV (%)\"})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nLoan Amount\nBorrower's Income\nLoan Percent Income\nBorrower's Age\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nLoan Repayment\nLoan Intent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefaulted\nDebt Consolidation\n11283.45\n7357.29\n65.20\n54553.15\n37624.33\n68.97\n0.24\n0.13\n57.00\n27.76\n6.52\n23.49\n\n\nEducation\n10912.82\n6979.08\n63.95\n47283.67\n30264.34\n64.01\n0.26\n0.13\n51.90\n27.09\n6.10\n22.50\n\n\nHome Improvement\n10035.04\n7324.85\n72.99\n49794.13\n33062.93\n66.40\n0.22\n0.13\n57.24\n27.62\n6.04\n21.86\n\n\nMedical\n11438.49\n7190.60\n62.86\n52477.12\n44092.21\n84.02\n0.24\n0.13\n54.74\n27.70\n6.31\n22.78\n\n\nPersonal\n10459.89\n6884.86\n65.82\n46965.14\n39080.81\n83.21\n0.25\n0.13\n51.99\n27.24\n6.09\n22.37\n\n\nVenture\n11115.68\n6695.34\n60.23\n44439.34\n27743.83\n62.43\n0.28\n0.13\n47.39\n26.74\n5.45\n20.38\n\n\nPaid in Full\nDebt Consolidation\n9050.14\n5810.33\n64.20\n72388.92\n61644.36\n85.16\n0.14\n0.08\n58.11\n27.54\n5.66\n20.56\n\n\nEducation\n9206.44\n6010.44\n65.29\n67866.15\n41045.51\n60.48\n0.15\n0.09\n57.71\n26.43\n5.49\n20.79\n\n\nHome Improvement\n10518.51\n6398.11\n60.83\n82499.92\n50452.00\n61.15\n0.14\n0.09\n61.15\n29.47\n5.48\n18.60\n\n\nMedical\n8570.88\n5645.54\n65.87\n65116.70\n51476.94\n79.05\n0.15\n0.08\n56.46\n27.96\n6.17\n22.07\n\n\nPersonal\n9441.60\n6133.81\n64.97\n72343.94\n54121.45\n74.81\n0.15\n0.09\n57.83\n28.49\n7.42\n26.03\n\n\nVenture\n9307.47\n6064.40\n65.16\n70493.68\n58762.60\n83.36\n0.15\n0.09\n59.45\n27.74\n5.98\n21.57\n\n\n\n\n\n\n\nIn creating the table above, I did some brief research on CV to more easily interpret the STD and wrote the helper method\nTable 1\nThe table above presents some general summary statistics from the data. I was interested in examining the mean, STD, and CV for some of the primary quantitative features in the data (loan_amnt, person_income, loan_percent_income, person_age) across each loan intent for both defaulted and fully repaid loans.\nFor Defaulted Loans:\n\nMedical loans are greatest in size on average compared to the other loan intents.\n\nHome Improvement loans are the smallest in size on average.\n\nDebt Consolidation loans are taken out by borrowers with the greatest average income.\n\nVenture loans are taken out by borrowers with the smallest average income.\n\nVenture loans have the largest average loan-value-percent-income in borrowers\n\nHome improvement loans have the smallest average loan-value-percent-income among borrowers\n\nDebt Consolidation loans are taken out by borrowers with the largest age on average.\n\nVenture loans correspond to borrowers with the lowest age on average.\n\n\nFor Fully Repaid Loans:\n\nHome Improvement loans are greatest in size on average compared to the other loan intents.\n\nMedical loans are the smallest in size on average. (Interestingly, this is the complete opposite of defaulted loans)\n\nHome Improvement loans are taken out by borrowers with the greatest average income.\n\nMedical loans are taken out by borrowers with the smallest average income.\n\nMedical, venture, education, and personal loans share the largest average loan-value-percent-income in borrowers while home improvement and debt consolidation loans correspond to the smallest average loan-value-percent-income in borrowers.\n\nIn terms of the spread of data across the variables displayed in the table, all four features possess relatively high coefficient of variation (CV%) values. This suggests that there is a notable degree of variability in the distribution of each of these features. However, some features appear to vary more than others: Loan Amount, Borrower's Income, and Loan Percent Income all have average CV (%) values &gt; 50% while Borrower's Age has an average CV (%) \\(\\approx\\) 20%. Additionally, there appears to be no considerable difference in CV (%) across each of the recorded loan intents nor between defaulted and fully repaid loans in general."
  },
  {
    "objectID": "posts/post_2/index.html#feature-selection",
    "href": "posts/post_2/index.html#feature-selection",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Feature Selection",
    "text": "Feature Selection\n\n\nCode\n# Modifying the training data\nX = train.drop([\"loan_status\", \"loan_grade\"], axis = 1, errors = \"ignore\")\ny = train[\"loan_status\"]\n\n# Creating one-hot encodings for qualitative variables\nX = pd.get_dummies(X, drop_first = True)\n\n# Removing NAs from data while maintaining alignment\nclean = pd.concat([X, y], axis = 1)\nclean = clean.dropna()\nX_train = clean.drop(\"loan_status\", axis = 1, errors = \"ignore\").copy()\ny_train = clean[\"loan_status\"].copy()\n\n# Adding new columns to X_train\n## Ratio of employment length to credit history\nX_train[\"credit_hist_emp_len\"] =  X_train[\"person_emp_length\"] / X_train[\"cb_person_cred_hist_length\"]\n\n# Identifying quantitative and qualitative variables in the data\nquant_vars = [\n              \"person_age\", \n              \"person_income\", \n              \"person_emp_length\", \n              \"loan_amnt\", \n              \"loan_int_rate\", \n              \"loan_percent_income\", \n              \"cb_person_cred_hist_length\",\n              \"credit_hist_emp_len\"\n            ]\nqual_vars = [\n              \"person_home_ownership_OTHER\",\n              \"person_home_ownership_OWN\",\n              \"person_home_ownership_RENT\",\n              \"loan_intent_EDUCATION\",\n              \"loan_intent_HOMEIMPROVEMENT\",\n              \"loan_intent_MEDICAL\",\n              \"loan_intent_PERSONAL\",\n              \"loan_intent_VENTURE\",\n              \"cb_person_default_on_file_Y\"\n            ]\n\n# Combination of selected quant and qual variables\ncols = quant_vars + qual_vars\n\n# Toggle to run feature selection process\nif (False):\n\n  # Iterating through all possible subsets of cols, evaluating a model with each subset, to determine the optimal set of variables to use\n  best_vars = []\n  best_avg_score = 0\n\n  # Paramters to determine the size of tested subsets\n  lower_bound = 4\n  upper_bound = 5\n  for i in range(lower_bound, upper_bound):\n      \n      # Iterating through all subsets\n      for subset in itertools.combinations(cols, i):\n        curr_vars = list(subset)\n        # Fitting a model to each subset\n        LR = LogisticRegression(random_state = 69)\n        LR.fit(X_train[curr_vars], y_train)\n        curr_avg_score = cross_val_score(LR, X_train[curr_vars], y_train, cv = 5).mean()\n        \n        # Update the best average score and the best variables to use for the model\n        if (curr_avg_score &gt; best_avg_score):\n          best_avg_score = curr_avg_score\n          best_vars = curr_vars\n\n# These are the best 5 variables selected after the iterative feature selection process above\nbest_vars = [\"loan_percent_income\", \"cb_person_cred_hist_length\", \"person_home_ownership_OTHER\", \"person_home_ownership_RENT\", \"loan_intent_HOMEIMPROVEMENT\"]\n\n# Refined model\nLR = LogisticRegression(random_state = 69)\nLR.fit(X_train[best_vars], y_train)\nscore = LR.score(X_train[best_vars], y_train)\nprint(f\"Refined Model Accuracy: {score * 100: .3f}%\")\n\n# Setting the weights vector\nw = np.array(LR.coef_[0])\n\n\nRefined Model Accuracy:  85.096%\n\n\nCode above shows the iterative process of trying all combinations of certain sizes for all features and taking those that lead to the best cross-validated model performance\nTo begin the feature selection process, the training data was informally divided into its quantitative and qualitative variables. The feature selection process involved iterating through a subset of the power set (all possible subsets) of the training data. All combinations of 1 up to 5 (out of 17) features were evaluated (beyond 5 features was too computationally expensive). According to the feature selection above, the 5 best variables to train the model with are loan_percent_income, cb_person_cred_hist_length (length of borrower’s credit history), person_home_ownership_OTHER (borrowers with home ownership status as “OTHER”), person_home_ownership_RENT (borrowers who are renting a home), and loan_intent_HOMEIMPROVEMENT (borrowers who intend to use a loan for home improvement). With these features used, the LogisticRegression model achieved just over \\(85\\%\\) training accuracy. While there is certainly room to improve the model’s training accuracy, this is the highest score achieved using the variables provided by the data and without undertaking a massive computational load (i.e. super long run time to iterate through all elements of the variable power set). The weights used by the model were extracted and stored in a weights vector w to be used in the scoring function described below."
  },
  {
    "objectID": "posts/post_2/index.html#creating-a-scoring-function",
    "href": "posts/post_2/index.html#creating-a-scoring-function",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Creating a Scoring Function",
    "text": "Creating a Scoring Function\n\n\nCode\n# Function to compute the score for each observation\ndef lin_score(X, w):\n    return X@w\n\n# Computing scores of each training observation and observing confusion matrix for the training data\nscores = lin_score(X_train[best_vars], w)\n\n# Normalizing the scores\nscores = (scores - scores.min()) / (scores.max() - scores.min())\n\n# Establishing model predictions for the train data\ny_train_pred = LR.predict(X_train[best_vars])\nC = confusion_matrix(y_train, y_train_pred)\nloan_status = [\"Fully Repaid\", \"Defaulted\"]\n\n# Creating a heatmap for better confusion matrix visualization\nfig, ax = plt.subplots(1, 1, figsize = (7.5, 7.5))\nmask1 = np.zeros_like(C, dtype=bool)\nmask1[:, 1] = True\nmask2 = np.zeros_like(C, dtype=bool)\nmask2[:, 0] = True\npurples = LinearSegmentedColormap.from_list(\"purple_gradient\", [\"#ce93d8\", \"#4a148c\"])\ndarkoranges = LinearSegmentedColormap.from_list(\"darkorange_gradient\", [\"#FFD580\", \"darkorange\"])\n# Plot the first column with purple gradient\nax1 = sns.heatmap(C, annot=True, fmt=\"d\", cmap=purples, \n                mask=mask1, cbar=False, xticklabels=[\"Fully Repaid\", \"Defaulted\"],\n                yticklabels=loan_status)\n\n# Plot the second column with orange gradient\nax2 = sns.heatmap(C, annot=True, fmt=\"d\", cmap=darkoranges, \n                mask=mask2, cbar=False, xticklabels=[\"Fully Repaid\", \"Defaulted\"],\n                yticklabels=loan_status)\n\n# Setting labels and title\nplt.xlabel(\"Predicted Loan Status\")\nplt.ylabel(\"True Loan Status\")\nplt.title(\"Lending Data Classification Confusion Matrix\")\n\nplt.show()\n\n# Printing confusion matrix results\nprint(f\"There were {C[0, 0]} fully repaid loan(s) that were predicted to be fully repaid.\")\nprint(f\"There were {C[0, 1]} fully repaid loan(s) that were predicted to be defaulted.\")\nprint(f\"There were {C[1, 0]} defaulted loan(s) that were predicted to be fully repaid.\")\nprint(f\"There were {C[1, 1]} defaulted loan(s) that were predicted to be defaulted.\")\n\n\n\n\n\n\n\n\n\nThere were 17702 fully repaid loan(s) that were predicted to be fully repaid.\nThere were 279 fully repaid loan(s) that were predicted to be defaulted.\nThere were 3135 defaulted loan(s) that were predicted to be fully repaid.\nThere were 1791 defaulted loan(s) that were predicted to be defaulted.\n\n\nCode above shows the linear scoring function used to determine model predictions and evaluate model accuracy. The scores were normalized to ensure that all scores are within the interval [0, 1]\nFigure 3\nFor this analysis, a linear scoring function is used. Specifically, the linear scoring function computes the score of each data observation by taking the dot product of each observation with the weights vector w. To ensure that all scores are values on the interval [0, 1], the scores are normalized after they are calculated (i.e. the scores are updated to be the difference between each raw score and the minimum raw score divided by the range of raw scores). Additionally, the confusion matrix for the model’s performance is displayed above. The model’s false positive rate is approximately \\(1.55\\%\\) while the true positive rate is approximately \\(36.34\\%\\). Conversely, the model’s false negative rate is approximately \\(63.66\\%\\) while the true negative rate is approximately \\(98.45\\%\\). With this information, it appears that the model rarely misclassifies fully repaid loans as defaulted (low FPR). However, the model frequently (moderately high FNR) misclassifies defaulted loans as being fully repaid. In general, with a very high TNR, the model is very accurate at detecting truly fully repaid loans but much less accurate (low TPR) at recognizing truly defaulted loans. It is important to note here that the initial objective for this model was to accurately predict if a prospective borrower will default on a loan, thus suggesting that perhaps the model and or the scoring function should be slightly redesigned to increase the TPR. However, given the introductory nature of this brief study, the analysis will continue with the current model as is.\n\nPlotting Distribution of Scores\n\n\nCode\n# Distribution of Scores - Code Provided by Prof. Chodrow\nfig, ax = plt.subplots(1, 1, figsize = (7.5, 5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nhist = ax.hist(scores, bins = 50, color = \"darkorange\", alpha = 0.75, linewidth = 1, edgecolor = \"purple\")\nlabs = ax.set(xlabel = r\"Scores (Normalized)\", ylabel = \"Frequency\") \n\n# Percentage (the majority) of scores below 0.5\nmaj_scores = (scores &lt;= 0.5).mean()\n\n\n\n\n\n\n\n\n\nFigure 4\nAs observed in the distribution of normalized scores above, it appears that the strong majority (\\(\\approx 91.81\\%\\))of normalized scores are less than or equal to 0.5. This may indicate that a useful threshold value for maximizing model accuracy and or bank profit per borrower (as informed by the model) might be close to \\(t = 0.5\\)."
  },
  {
    "objectID": "posts/post_2/index.html#choosing-a-threshold",
    "href": "posts/post_2/index.html#choosing-a-threshold",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Choosing a Threshold",
    "text": "Choosing a Threshold\n\n\nCode\n# Threshold selection based on model accuracy\nbest_accuracy = 0\nbest_threshold = 0\n\n# Following code is adapted from Prof. Chodrow\nfig, ax = plt.subplots(1, 1, figsize = (7.5, 5))\nfor t in np.linspace(0, 1, 100): \n    y_pred = scores &gt;= t\n    acc = (y_pred == y_train).mean()\n    ax.scatter(t, acc, color = \"purple\", s = 12.5)\n    if acc &gt; best_accuracy: \n        best_accuracy = acc\n        best_threshold = t\nax.axvline(best_threshold, linestyle = \"--\", color = \"darkorange\", linewidth = 2.5, zorder = -10)\nlabs = ax.set(xlabel = r\"Threshold $t$\", ylabel = \"Model Accuracy\", title = \"Accuracy by Threshold\")\nax.text(0.75, 0.5, f\"Best Accuracy: {best_accuracy: .3f}\\n  At Threshold $t = ${best_threshold: .3f}\", ha = \"center\",\n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"grey\", boxstyle = \"round,pad=0.3\"))\nax.grid(False)\n\n\n\n\n\n\n\n\n\nFigure 5\nShown above is the trend in overall model accuracy as the threshold \\(t\\) increases from \\(0: 1\\). As outlined in the plot, the peak model accuracy (\\(\\approx 85\\%\\)) is achieved using a threshold of \\(t = 0.505\\). However, what is likely more interesting (especially for the bank) is how the profit-per-borrower can be maximized through selecting a value for \\(t\\). Below is an examination of thresholding for profit maximization.\n\n\nCode\n# Threshold selection based on profit for the bank created by the model\n\n# Updated variables\nbest_ppb = 0\nbest_threshold = 0\n\n# Following code is adapted from Prof. Chodrow\nfig, ax = plt.subplots(1, 1, figsize = (7.5, 5))\n\nfor t in np.linspace(0, 1, 100): \n    y_pred = scores &gt;= t\n    \n    # Determining whether each prediction is a a true or false negative to inform the amount of profit loss or gain for a given loan\n    X_train[\"TN\"] = ((y_pred == 0) & (y_train == 0)).astype(int)\n    X_train[\"FN\"] = ((y_pred == 0) & (y_train == 1)).astype(int)\n    \n    # Calculating the profit gain and loss for each borrower using the formulas provided by Prof. Chodrow\n    profit_gain = X_train[\"TN\"] * (X_train[\"loan_amnt\"] * ((1 + (0.25 * (X_train[\"loan_int_rate\"] / 100))) ** 10) - X_train[\"loan_amnt\"])\n    profit_loss = X_train[\"FN\"] * (X_train[\"loan_amnt\"] * ((1 + (0.25 * (X_train[\"loan_int_rate\"] / 100))) ** 3) - (1.7 * X_train[\"loan_amnt\"]))\n    \n    # Profit-per-borrower with the current threshold\n    ppb = (profit_gain + profit_loss).sum() / X_train.shape[0]\n    \n    # Ploting PPB point and updating variables\n    ax.scatter(t, ppb, color = \"purple\", s = 12.5)\n    if ppb &gt; best_ppb: \n        best_ppb = ppb\n        best_threshold = t\n\n# Plot styling\nax.axvline(best_threshold, linestyle = \"--\", color = \"darkorange\", linewidth = 2.5, zorder = -10)\nlabs = ax.set(xlabel = r\"Threshold $t$\", ylabel = \"Bank Profit (Per Borrower)\", title = \"Profit Per Borrower by Threshold\")\nax.text(0.75, 500, f\"Best Profit: ${best_ppb: .2f}\\n  At Threshold $t = ${best_threshold: .3f}\", ha = \"center\",\n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"grey\", boxstyle = \"round,pad=0.3\"))\nax.grid(False)\n\n\n\n\n\n\n\n\n\nIn the code above, the bank’s profit-per-borrower is plotted against the threshold \\(t\\). The profit per borrower is determined by calculating the profit gain and profit loss (using the formulas provided by Prof. Chordow) for each individual loan. The correct profit value (either gain or loss) is then added to the overall profit sum depending on whether or not the model correctly classified a given loan as a true negative or incorrectly classified a given loan as a false negative. The overall profit is then divided by the number of observations (borrowers) in the training data to yield the profit value per borrower.\nFigure 6\nAs depicted above, the bank’s profit-per-borrower is shown to increase as the threshold \\(t\\) increases before notably dropping and ultimately plateauing. The bank’s peak profit-per-borrower is approximately \\(\\$1450.00\\), corresponding to using a threshold value of \\(t = 0.495\\). Not surprisingly, both the model’s overall accuracy as well as the bank’s profit-per-borrower are maximized at very similar thresholds (about 0.5)."
  },
  {
    "objectID": "posts/post_2/index.html#perspective-of-the-bank",
    "href": "posts/post_2/index.html#perspective-of-the-bank",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Bank",
    "text": "Perspective of the Bank\n\n\nCode\n# Reading in and modifying the test data\ntest = pd.read_csv(\"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\")\ntest = test.dropna()\nXt = test.drop([\"loan_status\", \"loan_grade\"], axis = 1, errors = \"ignore\")\nyt = test[\"loan_status\"]\n\n# Creating one-hot encodings for qualitative variables\nXt = pd.get_dummies(Xt, drop_first = True)\n\n# Removing NAs from data while maintaining alignment\nclean = pd.concat([Xt, yt], axis = 1)\nclean = clean.dropna()\nX_test = clean.drop(\"loan_status\", axis = 1, errors = \"ignore\").copy()\ny_test = clean[\"loan_status\"].copy()\n\n# Computing and normalizing the test scores\ntest_scores = lin_score(X_test[best_vars], w)\n# Normalizing the scores\ntest_scores = (test_scores - scores.min()) / (test_scores.max() - test_scores.min())\n\n# Adding the model's calculated score for each observation in the testing data\ntest[\"score\"] = test_scores\ntest[\"score\"] = pd.to_numeric(test[\"score\"], errors = \"coerce\")\n\n# Determining predictions\ny_test_pred = test_scores &gt;= best_threshold\n\n# Calculating the profit-per-borrower for test data (copied from code chunk above)\n# Determining whether each prediction is a a true or false negative to inform the amount of profit loss or gain for a given loan\nX_test[\"TN\"] = ((y_test_pred == 0) & (y_test == 0)).astype(int)\nX_test[\"FN\"] = ((y_test_pred == 0) & (y_test == 1)).astype(int)\n\n# Calculating the profit gain and loss for each borrower using the foromulas provided by Prof. Chodrow\nprofit_gain_t = X_test[\"TN\"] * (X_test[\"loan_amnt\"] * ((1 + (0.25 * (X_test[\"loan_int_rate\"] / 100))) ** 10) - X_test[\"loan_amnt\"])\nprofit_loss_t = X_test[\"FN\"] * (X_test[\"loan_amnt\"] * ((1 + (0.25 * (X_test[\"loan_int_rate\"] / 100))) ** 3) - (1.7 * X_test[\"loan_amnt\"]))\n\n# Profit-per-borrower for test data using the best threshold\nppbt = (profit_gain_t + profit_loss_t).sum() / X_test.shape[0]\n\nprint(f\"The Bank's Profit-Per-Borrower from the test data: ${ppbt :.2f}\")\nprint(f\"(Test Data PPB to Training Data PPB Ratio: {((ppbt / best_ppb) * 100): .2f}%)\")\n\n\nThe Bank's Profit-Per-Borrower from the test data: $1326.67\n(Test Data PPB to Training Data PPB Ratio:  91.64%)\n\n\nIn the code above, the test data is processed the exact same way as the training data to ensure compatibility with the scoring function and profit-per-borrower calculations as previously done.\nAccording to the computation above, the bank’s expected profit-per-borrower on the test data is approximately \\(\\$1330.00\\). This value is roughly \\(92\\%\\) of (i.e. considerably similar to) the profit-per-borrower produced by the training data. Consider the most popular loan intent from the test data: Educational loans. According to the statistics provided by the Education Data Initiative, there were nearly 43 million student loan borrowers in the US in 2024. Additionally, MX Technologies reports there being about 4550 banks in the US. If the number of US educational loan borrowers is divided amongst the number of US banks, each US bank could have approximately 9450 educational loan borrowers in 2024. So suppose the hypothetical bank in this study has about 9450 educational loan borrowers. Thus, the bank’s profit (theoretically in 2024) from educational loans alone would be about $12.57 million. This is of course a wildly crude calculation that is ultimately not based on any reviewed methodology. But, it at least goes to show how large the hypothetical bank’s annual profit theoretically could be, even for only one type of loan."
  },
  {
    "objectID": "posts/post_2/index.html#perspective-of-the-borrower",
    "href": "posts/post_2/index.html#perspective-of-the-borrower",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Borrower",
    "text": "Perspective of the Borrower\n\nLoan Approval and Borrower Age\n\n\nCode\n# Function to convert numerical ages to age categories\ndef age_cat(age):\n    if (age &lt; 30):\n        return \"Young Adult\"\n    elif (age &lt; 60):\n        return \"Adult\"\n    else:\n        return \"Senior\"\n\ntest[\"age_cat\"] = test[\"person_age\"].apply(age_cat)\n\n# Independent and dependent variables for bar chart\nage_cats = np.array(test[\"age_cat\"].unique())\n\n# Avg. scores calculated using .groupby(...).aggregate(...)\nac_avg_scores = np.array([\n    test[test[\"age_cat\"] == \"Young Adult\"][\"score\"].mean(),\n    test[test[\"age_cat\"] == \"Adult\"][\"score\"].mean(),\n    test[test[\"age_cat\"] == \"Senior\"][\"score\"].mean(),\n    ])\nage_scores_df = pd.DataFrame({\"Age Cat\": age_cats, \"Avg Score\": ac_avg_scores})\n\n# Arrays of percentage of high scores and percentage of all scores above the threshold from each age cat\nnum_high_scores = (test[\"score\"] &gt;= best_threshold).sum()\n\n# Perc. of high scores among each age cat\nac_perc_high_scores_1 = np.array([(test[test[\"age_cat\"] == \"Young Adult\"][\"score\"] &gt;= best_threshold).mean() * 100, \n                           (test[test[\"age_cat\"] == \"Adult\"][\"score\"] &gt;= best_threshold).mean() * 100, \n                           (test[test[\"age_cat\"] == \"Senior\"][\"score\"] &gt;= best_threshold).mean() * 100])\n\n# Perc. of all high scores contributed by each age cat\nac_perc_high_scores_2 = np.array([(test[test[\"age_cat\"] == \"Young Adult\"][\"score\"] &gt;= best_threshold).sum(), \n                           (test[test[\"age_cat\"] == \"Adult\"][\"score\"] &gt;= best_threshold).sum(), \n                           (test[test[\"age_cat\"] == \"Senior\"][\"score\"] &gt;= best_threshold).sum()])\n\n# Displaying average model score for each age cat\nfig, ax = plt.subplots(2, 2, figsize = (15, 12.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Distribution of scores by age cat\nsns.boxenplot(test, x = \"age_cat\", y = \"score\", hue = \"age_cat\", legend = False, ax = ax[0, 0])\nax[0, 0].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[0, 0].set_title(\"Distribution of Model Scores\", fontsize = 18)\nax[0, 0].set_ylabel(\"Score (Normalized)\", fontsize = 16)\nax[0, 0].set_xticks([0, 1, 2])\nax[0, 0].set_xticklabels([\"Young Adult\\n(Early-Career)\", \"Adult\\n(Mid-Career)\", \"Senior\\n(Late-Career/Retired)\"])\nax[0, 0].set_xlabel(\"\")\nax[0, 0].text(1.75, 0.85, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0, 0].text(1.5, 0.85, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Average score by age cat\nsns.barplot(x = age_cats, y = ac_avg_scores, data = age_scores_df, hue = age_cats, legend = False, ax = ax[0, 1])\nax[0, 1].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[0, 1].set_title(\"Average Model Score\", fontsize = 18)\nax[0, 1].set_ylabel(\"Average Score (Normalized)\", fontsize = 16)\nax[0, 1].set_xticks([0, 1, 2])\nax[0, 1].set_xticklabels([\"Young Adult\\n(Early-Career)\", \"Adult\\n(Mid-Career)\", \"Senior\\n(Late-Career/Retired)\"])\nax[0, 1].text(1.75, 0.425, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0, 1].text(1.5, 0.425, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Percentage of high scores (above threshold) for each age cat\nsns.barplot(x = age_cats, y = ac_perc_high_scores_1, hue = age_cats, legend = False, ax = ax[1, 0])\nax[1, 0].set_title(\"Percentage of Model Scores\\nAbove Threshold \", fontsize = 18)\nax[1, 0].set_ylabel(\"% of Scores Above Threshold\", fontsize = 16)\nax[1, 0].set_xticks([0, 1, 2])\nax[1, 0].set_xticklabels([\"Young Adult\\n(Early-Career)\", \"Adult\\n(Mid-Career)\", \"Senior\\n(Late-Career/Retired)\"])\nax[1, 0].set_yticks([0, 2, 4, 6, 8, 10, 12])\nax[1, 0].set_yticklabels([\"0%\", \"2%\", \"4%\", \"6%\", \"8%\", \"10%\", \"12%\"])\n\n# Percentage of all high scores (above threshold) from each age cat\nsns.barplot(x = age_cats, y = ((ac_perc_high_scores_2 / num_high_scores) * 100), hue = age_cats, legend = False, ax = ax[1, 1])\nax[1, 1].set_title(\"Percentage of all Model Scores\\nAbove Threshold From each Age Category\", fontsize = 18)\nax[1, 1].set_ylabel(\"% of all Scores Above Threshold\", fontsize = 16)\nax[1, 1].set_xticks([0, 1, 2])\nax[1, 1].set_xticklabels([\"Young Adult\\n(Early-Career)\", \"Adult\\n(Mid-Career)\", \"Senior\\n(Late-Career/Retired)\"])\nax[1, 1].set_yticks([0, 10, 20, 30, 40, 50, 60, 70, 80])\nax[1, 1].set_yticklabels([\"0%\", \"10%\", \"20%\", \"30%\", \"40%\", \"50%\", \"60%\", \"70%\", \"80%\"])\n\nfig.text(0.5, 0.95, \"Model Score Metrics by Borrower Age category\", ha = \"center\", fontsize = 20)\nfig.text(0.5, 0.05, \"Borrower Age Category\", ha = \"center\", fontsize = 18)\nplt.subplots_adjust(wspace = 0.25, hspace = 0.3)\n\n\n\n\n\n\n\n\n\nCode above constructs 4 plots to observe how the model score varies across age category among borrowers. The top two plots simply display the distribution of model scores and the average score for each age category. The bottom two plots show the percentage of high model scores within each age category and the percentage of overall high model scores attributed to each age category (computed by taking the number of high model scores for each age category over the total number of high model scores).\nFigure 7\nAs displayed in the plots above, it appears that young adults and middle-aged borrowers receive lower scores than senior borrowers. Additionally, a smaller percentage of scores for both young adult and middle-aged borrowers are above the threshold than that of senior borrowers. Considering this, it is reasonable to hypothesize that the model makes it more difficult for older borrowers to be approved for loans than it is for younger borrowers. However, this is possibly a result of inconsistent age category sizes. That is, the percentage of all high scores (scores that advise the bank to deny a borrower a loan) attributed to young adults is much greater than that of middle-aged and senior borrowers. It is possible that the metrics found in this data are not truly representative of the population of senior borrowers.\n\n\nLoan Approval and Loan Intent\n\n\nCode\n# Independent and dependent variables for bar chart\ntest[\"loan_intent\"] = test[\"loan_intent\"].map(loan_intent_recode)\nloan_intents = np.array(test[\"loan_intent\"].unique())\nprint(loan_intents)\n\n# Avg. scores calculated using .groupby(...).aggregate(...)\nli_avg_scores = np.array([\n    test[test[\"loan_intent\"] == \"Venture\"][\"score\"].mean(),\n    test[test[\"loan_intent\"] == \"Debt Consolidation\"][\"score\"].mean(),\n    test[test[\"loan_intent\"] == \"Medical\"][\"score\"].mean(),\n    test[test[\"loan_intent\"] == \"Home Improvement\"][\"score\"].mean(),\n    test[test[\"loan_intent\"] == \"Education\"][\"score\"].mean(),\n    test[test[\"loan_intent\"] == \"Personal\"][\"score\"].mean()\n])\nli_scores_df = pd.DataFrame({\"Loan Intent\": loan_intents, \"Avg Score\": li_avg_scores})\n\n# Arrays of percentage of high scores and percentage of all scores above the threshold from each loan intent\nli_perc_high_scores_1 = np.zeros(0)\nli_perc_high_scores_2 = np.zeros(0)\n\nfor loan in loan_intents:\n    \n    # Calculating each metric\n    li_perc_high_score_1 = (test[test[\"loan_intent\"] == loan][\"score\"] &gt;= best_threshold).mean() * 100\n    li_perc_high_score_2 = ((test[test[\"loan_intent\"] == loan][\"score\"] &gt;= best_threshold).sum() / num_high_scores) * 100\n\n    # Adding each metric to corresponding array\n    li_perc_high_scores_1 = np.append(li_perc_high_scores_1, li_perc_high_score_1)\n    li_perc_high_scores_2 = np.append(li_perc_high_scores_2, li_perc_high_score_2)\n\n# Displaying average model score for each age cat\nfig, ax = plt.subplots(2, 2, figsize = (15, 12.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Distribution of scores by age cat\nsns.boxenplot(test, x = \"loan_intent\", y = \"score\", hue = \"loan_intent\", legend = False, ax = ax[0, 0])\nax[0, 0].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[0, 0].set_title(\"Distribution of Model Scores\", fontsize = 18)\nax[0, 0].set_ylabel(\"Score (Normalized)\", fontsize = 16)\nax[0, 0].set_xticks([0, 1, 2, 3, 4 ,5])\nax[0, 0].set_xticklabels(loan_intents, rotation = 20)\nax[0, 0].set_xlabel(\"\")\nax[0, 0].text(4, 0.9, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0, 0].text(3.5, 0.9, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Average score by age cat\nsns.barplot(x = loan_intents, y = li_avg_scores, data = li_scores_df, hue = loan_intents, legend = False, ax = ax[0, 1])\nax[0, 1].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[0, 1].set_title(\"Average Model Score\", fontsize = 18)\nax[0, 1].set_ylabel(\"Average Score (Normalized)\", fontsize = 16)\nax[0, 1].set_xticks([0, 1, 2, 3, 4, 5])\nax[0, 1].set_xticklabels(loan_intents, rotation = 20)\nax[0, 1].text(4, 0.45, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0, 1].text(3.5, 0.45, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Percentage of high scores (above threshold) for each age cat\nsns.barplot(x = loan_intents, y = li_perc_high_scores_1, hue = loan_intents, legend = False, ax = ax[1, 0])\nax[1, 0].set_title(\"Percentage of Model Scores\\nAbove Threshold \", fontsize = 18)\nax[1, 0].set_ylabel(\"% of Scores Above Threshold\", fontsize = 16)\nax[1, 0].set_xticks([0, 1, 2, 3, 4, 5])\nax[1, 0].set_xticklabels(loan_intents, rotation = 20)\nax[1, 0].set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8])\nax[1, 0].set_yticklabels([\"0%\", \"1%\", \"2%\", \"3%\", \"4%\", \"5%\", \"6%\", \"7%\", \"8%\"])\n\n# Percentage of all high scores (above threshold) from each age cat\nsns.barplot(x = loan_intents, y = li_perc_high_scores_2, hue = loan_intents, legend = False, ax = ax[1, 1])\nax[1, 1].set_title(\"Percentage of all Model Scores\\nAbove Threshold From each Age Category\", fontsize = 18)\nax[1, 1].set_ylabel(\"% of all Scores Above Threshold\", fontsize = 16)\nax[1, 1].set_xticks([0, 1, 2, 3, 4, 5])\nax[1, 1].set_xticklabels(loan_intents, rotation = 20)\nax[1, 1].set_yticks([0, 5, 10, 15, 20])\nax[1, 1].set_yticklabels([\"0%\", \"5%\", \"10%\", \"15%\", \"20%\"])\n\nfig.text(0.5, 0.95, \"Model Score Metrics by Loan Intent\", ha = \"center\", fontsize = 20)\nfig.text(0.5, 0.05, \"Loan Intent\", ha = \"center\", fontsize = 18)\nplt.subplots_adjust(wspace = 0.25, hspace = 0.35)\n\n\n# Computing true defualt rates for medical, venture, and educational loans\nm = test[test[\"loan_intent\"] == \"Medical\"].copy()\nv = test[test[\"loan_intent\"] == \"Venture\"].copy()\ne = test[test[\"loan_intent\"] == \"Education\"].copy()\nd = test[test[\"loan_intent\"] == \"Debt Consolidation\"].copy()\np = test[test[\"loan_intent\"] == \"Personal\"].copy()\nh = test[test[\"loan_intent\"] == \"Home Improvement\"].copy()\ntrue_default_rates = np.array([\n    (m[\"loan_status\"] == 1).mean(),\n    (v[\"loan_status\"] == 1).mean(),\n    (e[\"loan_status\"] == 1).mean(),\n    (d[\"loan_status\"] == 1).mean(),\n    (p[\"loan_status\"] == 1).mean(),\n    (h[\"loan_status\"] == 1).mean(),\n])\n\n\n['Venture' 'Debt Consolidation' 'Medical' 'Home Improvement' 'Education'\n 'Personal']\n\n\n\n\n\n\n\n\n\nCode above constructs 4 plots to observe how the model score varies across loan intent. The top two plots simply display the distribution of model scores and the average score for each loan intent. The bottom two plots show the percentage of high model scores within each loan intent and the percentage of overall high model scores attributed to each loan intent (computed by taking the number of high model scores for each loan intent over the total number of high model scores).\nFigure 8\nAs shown in the figures above, the the general distribution and average model scores across each loan intent are considerably similar. That is, it does not appear that any specific loan intents correspond to significantly high or low model scores. However, as shown in the bottom right plot, the largest percentage of all high model scores (scores that advise the bank to deny a borrower a loan), is attributed to medical loans. This may suggest that it is more difficult for borrowers to have medical loans approved. The actual rate of default for medical loans in the test data is about \\(30\\%\\), which is the second highest default rate (nearly equal to that of debt consolidation loans). Considering that medical loans make up the largest percentage of overall high model scores and have the highest true rate of default in the test data, it may be justified that the bank makes it more difficult for borrowers seeking these types of loans to be approved.\nAs for venture and educational loans, it appears that borrowers looking to take out these types of loans are similarly likely to be approved by the bank (they have very similar average model scores, percentage of high scores within themselves, and percentage makeups of the overall high model scores). Additionally, both venture loans and educational loans have similar default rates in the test data of about \\(15\\%\\) and \\(17\\%\\) respectively.\n\n\nLoan Approval and Borrower Income\n\n\nCode\n# Adding high/low score indicator col\ntest[\"high_score\"] = test[\"score\"] &gt;= best_threshold\ntest[\"low_inc\"] = (test[\"person_income\"] &lt;= 30000).astype(int)\ntest[\"high_inc\"] = (test[\"person_income\"] &gt;= 150000).astype(int)\ntest[\"person_inc_log\"] = np.log2(test[\"person_income\"])\n\nlow_inc = test[test[\"low_inc\"] == 1].copy()\nhigh_inc = test[test[\"high_inc\"] == 1].copy()\n\n# Plotting model score against borrower income\nfig, ax = plt.subplots(1, 3, figsize = (17.5, 10))\n\n# Score by income for low income borrowers\nsns.scatterplot(data = low_inc, x = \"person_income\", y = \"score\", hue = \"high_score\", palette = [\"darkorange\", \"purple\"], legend = False, ax = ax[0])\nax[0].set_title(\"Low Income\", fontsize = 16)\nax[0].set_ylabel(\"Score (Normalized)\", fontsize = 14)\nax[0].set_xlabel(\"\")\nax[0].set_xticks([5e3, 10e3, 15e3, 20e3, 25e3, 30e3])\nax[0].set_xticklabels([\"~$5000\", \"~$10000\", \"~$15000\", \"~$20000\", \"~$25000\", \"~$30000\"], rotation = 15)\nax[0].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[0].text(8000, 0.9, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(5000, 0.9, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Score by income for high income borrowers\nsns.scatterplot(data = high_inc, x = \"person_income\", y = \"score\", hue = \"high_score\", palette = [\"darkorange\", \"purple\"], legend = False, ax = ax[1])\nax[1].set_xscale(\"log\", base = 2)\nax[1].set_title(\"High Income\", fontsize = 16)\nax[1].set_ylabel(\"\")\nax[1].set_xlabel(\"\")\nax[1].set_xticks([2 ** 18, 2 ** 19, 2 ** 20])\nax[1].set_xticklabels([\"~$260000\", \"~$500000\", \"~$1M\"], rotation = 15)\nax[1].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[1].text(2 ** 17.75, 0.45, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(2 ** 17.325, 0.45, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\n# Score by income for all borrowers\nsns.scatterplot(data = test, x = \"person_income\", y = \"score\", hue = \"high_score\", palette = [\"darkorange\", \"purple\"], legend = False, ax = ax[2])\nax[2].set_xscale(\"log\", base = 2)\nax[2].set_title(\"All Borrowers\", fontsize = 16)\nax[2].set_ylabel(\"\")\nax[2].set_xlabel(\"\")\nax[2].set_xticks([2 ** 13, 2 ** 15, 2 ** 17, 2 ** 19, 2 ** 21])\nax[2].set_xticklabels([\"~$8000\", \"~$30000\", \"~$100000\", \"~$500000\", \"~$2M\"], rotation = 15)\nax[2].axhline(best_threshold, linestyle = \"--\", color = \"purple\", linewidth = 2.5)\nax[2].text(2 ** 18, 0.9, f\"     $t = 0.495$\", ha = \"center\", va = \"center\", fontsize = 10, \n        bbox = dict(facecolor = \"white\", alpha = 0.5, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[2].text(2 ** 17, 0.9, \"\\u2013\", color = \"purple\", ha = \"left\", va = \"center\", fontsize = 15, fontweight=\"bold\")\n\nfig.suptitle(\"Observing Model Score Against Borrower Income\", fontsize = 20)\nfig.text(0.5, 0.01, \"Borrower Income ($\\log_2$ scale on rightmost subplots)\", ha = \"center\", fontsize = 16)\n\nplt.show()\n\n# Calculating default rates for low and high income borrowers\ntrue_default_rates_inc = np.array([\n    (low_inc[\"loan_status\"] == 1).mean(),\n    (high_inc[\"loan_status\"] == 1).mean()\n])\n\n\n\n\n\n\n\n\n\nCode above constructs scatter plots observing model score by borrower income for low-income borrowers, high-income borrowers, and all borrowers. The threshold is included in each plot to depict where the score cutoff is.\nFigure 9\nAs depicted in the plots above, there seems to be a general trend between borrower income and their corresponding model score. That is, it appears that as a borrower’s income increases, their score decreases. This may suggest that the model makes it easier for higher-income individuals to be approved for loans than those at lower-income levels. This is supported by the fact that a considerable proportion of low-income borrowers (\\(\\leq \\$30000\\) annual earnings) were scored above the threshold (i.e. likely not approved) while none of the high-income borrowers (\\(\\geq \\$150000\\) annual earnings) were scored above the threshold. This may be sufficient evidence for the bank, but it is important to note that a borrower’s income is not actually one of the features the model was trained on. Thus, this observation may be due to other related factors."
  },
  {
    "objectID": "posts/post_1/index.html",
    "href": "posts/post_1/index.html",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "",
    "text": "In this blog post, I’m taking on an introductory-level machine learning classification task. This task, classifying penguin species, is a ternary classification problem as there are three species options for which I am trying to construct a classifier model to correctly identify. The data for this task comes from the Palmer Station and was collected by Dr. Kristen Gorman. The following analysis begins with some preliminary data visualizations and summary statistics interpretation. From the preliminary visualizations and statistics table, I’m able to make some initial observations about the difference in penguin features across each species. The next sections show the initial model and feature selection as well as model refinement to improve the chosen model. While completing this analysis, I experimented with several different models: a logistic regression model, a decision tree classifier, and a random forest classifier. I ultimately decided to choose proceed with the random forest classifier model (see the third section in this post). For feature selection, I initially took an exhaustive search approach. However, after running into many bugs and difficulties with this approach, I opted to incorporate the use of prebuilt feature selection tools (see second section in this post). Following a thorough feature selection and cross-validation/model refinement process, I was able to produce a model with nearly \\(100\\%\\) testing accuracy. That is, my model was able to correctly identify all but a single observation from unseen test data (i.e. it made 1 classification error). In the following sections of this post are more in-depth explanations and analyses of my steps taken in accomplishing this classification task.\n\n\n\n\nCode\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\n# Accessing training data\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n# Code below provided by Prof. Chodrow\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nThe prepare_data(...) function above was provided by Prof. Chodrow\n\n\nCode\n# Includuing all additional imports\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.colors import ListedColormap\nimport numpy as np\nimport seaborn as sns\n\n\nIncluding all additional imports\n\n\nCode\n# Creating a modified dataset for visualization and summary statistics\ntrain_viz = train[train[\"Sex\"] != \".\"].copy()\ntrain_viz[\"Culmen Ratio (L/D)\"] = train_viz[\"Culmen Length (mm)\"] / train_viz[\"Culmen Depth (mm)\"]\ntrain_viz.dropna()\n\n# Subsetting data by species to make regression plots for flipper length by body mass across each Species\nadelie = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\nadelie = adelie[adelie['Species'] == 'Adelie Penguin (Pygoscelis adeliae)']\nadelie = adelie.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\nchinstrap = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\nchinstrap = chinstrap[chinstrap['Species'] == 'Chinstrap penguin (Pygoscelis antarctica)']\nchinstrap = chinstrap.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\ngentoo = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\ngentoo = gentoo[gentoo['Species'] == 'Gentoo penguin (Pygoscelis papua)']\ngentoo = gentoo.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\n\n\nAbove, I’m creating a modified dataset for visualization and summary statistics and making three subsets of the visualization data set corresponding to eac penguin species with the specific visualization features selected. This is later used for linear regression modeling by species.\n\n\n\n\n\nCode\n# Creating linear regression models and calculating r^2 values\n\n## Adelie\nc1 = np.polyfit(adelie['Body Mass (g)'], adelie['Flipper Length (mm)'], 1)\np1 = np.polyval(c1, adelie['Body Mass (g)'])\nr1 = adelie['Flipper Length (mm)'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((adelie['Flipper Length (mm)'] - np.mean(adelie['Flipper Length (mm)']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Chinstrap\nc2 = np.polyfit(chinstrap['Body Mass (g)'], chinstrap['Flipper Length (mm)'], 1)\np2 = np.polyval(c2, chinstrap['Body Mass (g)'])\nr2 = chinstrap['Flipper Length (mm)'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((chinstrap['Flipper Length (mm)'] - np.mean(chinstrap['Flipper Length (mm)']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n## Gentoo\nc3 = np.polyfit(gentoo['Body Mass (g)'], gentoo['Flipper Length (mm)'], 1)\np3 = np.polyval(c3, gentoo['Body Mass (g)'])\nr3 = gentoo['Flipper Length (mm)'] - p3\nssr3 = np.sum(r3**2)\nsst3 = np.sum((gentoo['Flipper Length (mm)'] - np.mean(gentoo['Flipper Length (mm)']))**2)\nrs3 = 1 - (ssr3 / sst3)\n\n\nAbove, I’m creating a linear regression model of flipper length by body mass for each species (using np.polyfit). I’m also extracting the \\(R^2\\) values (using predictions from np.polyval to calculate residuals) for each regression model to include in my plots below. I searched online how to use these two functions.\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (10, 7))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Setting up the initial scatter plot\nax[0] = sns.scatterplot(data = train_viz, x = 'Body Mass (g)', y = 'Flipper Length (mm)', hue = 'Species', palette = ['#B85ED4', '#2A7A7A', '#F28234'], style = 'Species', s = 50, ax = ax[0])\n\n# Adding regression lines for each species\nsns.regplot(data = adelie, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#F28234'}, ax = ax[0])\nsns.regplot(data = chinstrap, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#B85ED4'}, ax = ax[0])\nsns.regplot(data = gentoo, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#2A7A7A'}, ax = ax[0])\n\n# Plot styling to make colors match up and the text boxes look nicer\nax[0].set_title(\"Penguin Flipper Length (mm) by Body Mass (g)\\nColored by Species\")\nax[0].legend(frameon = True, prop = {'size': 9})\nax[0].text(5200, 175.75, '           \\n', fontsize = 20, bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'grey', boxstyle = 'round, pad=0.3'))\nax[0].text(5555, 180, f'     $R^2 = {rs3:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 178, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 176, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5200, 180.1, '\\u2013', color='#2A7A7A', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 178.1, '\\u2013', color='#B85ED4', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 176.1, '\\u2013', color='#F28234', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Setting up the box plot and doing some simple styling\nax[1] = sns.boxplot(train_viz, x = \"Species\", y = \"Culmen Ratio (L/D)\", hue = \"Sex\", ax = ax[1])\nax[1].set_xticks([0, 1, 2])\nax[1].set_xticklabels([\"Chinstrap\", \"Gentoo\", \"Adelie\"])\nax[1].legend(prop = {'size': 10}, frameon = True)\nax[1].set_title(\"Penguin Culmen Ratio (L/D) by Species\\nGrouped by Sex\")\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.2)\n\n\n\n\n\n\n\n\n\nIn the figure to the left, the relationship between penguin flipper length (mm) and body mass (g) for each species of penguin is displayed. Visually, there appears to be a notable positive, linear relationship between flipper length and body mass in general. That is, it seems that as penguin body mass increases, the flipper length increases as well regardless of species.\nAdditionally, there appears to be some clustering by species shown in this relationship. Gentoo penguins appear to have both the largest flipper lengths and body masses. There is less of a visually obvious distinction between Chinstrap and Adelie penguins shown by the relationship between body mass and flipper length. However, I believe it is reasonable to hypothesize that Chinstrap penguins have a slightly greater average flipper length while Adelie penguins have a slightly greater body mass.\nFrom the \\(R^2\\) values for the regression lines corresponding to the relationship between body mass and flipper length for each penguin species, I feel that it’s reasonable to say the positive linear relationships between the two variables in question for each species range from weak/moderate to moderate in strength. Further, while I do not have the statistical knowledge to confirm nor deny this hypothesis, perhaps the clear visual difference observed across the three species-specific regression lines could provide useful insight into this classification task.\nIn general, this plot reveals some useful information about the differences observed across each penguin species from two relevant variables. While this plot likely does not provide highly convincing information pertaining to the species classification of penguins from certain features, it does highlight a relationship between two key quantitative variables that displays a preliminary approach to this classification task.\nThe figure to the right displays the general distribution of the Culmen Ratio (L/D) feature across penguin sex and penguin species. The Culmen Ratio (L/D) is the ratio of culmen length (mm) to culmen depth (mm). With no prior knowledge about culmen size and dimensions in penguins, I thought it would be interesting to compute the length-depth ratio for each penguin and see how this ratio differed by sex and across each species. Observing the comparison of the culmen ratio between male and female penguins, there does not appear to be as much visually obvious information. However, to me, there appears to be minimal distribution overlap in the culmen ratio across each species. I believe this suggests that the culmen ratio or related features (culmen length and culmen depth) could be useful in model construction to successfully complete this classification task.\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.groupby(['Species', 'Sex']).aggregate({\"Flipper Length (mm)\" : [\"mean\", \"std\", cv], \n                                                             \"Body Mass (g)\" : [\"mean\", \"std\", cv], \"Culmen Length (mm)\": [\"mean\", \"std\", cv], \n                                                             \"Culmen Depth (mm)\": [\"mean\", \"std\", cv], \"Culmen Ratio (L/D)\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {'mean': 'Mean', 'std': 'STD', 'cv': 'CV (%)'})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nBody Mass (g)\nCulmen Length (mm)\nCulmen Depth (mm)\nCulmen Ratio (L/D)\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\nFEMALE\n187.92\n5.43\n2.89\n3350.47\n262.87\n7.85\n37.43\n1.95\n5.20\n17.64\n0.92\n5.21\n2.13\n0.15\n6.96\n\n\nMALE\n192.33\n7.00\n3.64\n4052.87\n331.57\n8.18\n40.40\n2.37\n5.86\n19.08\n1.05\n5.48\n2.12\n0.17\n7.89\n\n\nChinstrap penguin (Pygoscelis antarctica)\nFEMALE\n192.06\n5.90\n3.07\n3523.39\n294.95\n8.37\n46.72\n3.17\n6.78\n17.61\n0.80\n4.55\n2.66\n0.19\n7.21\n\n\nMALE\n200.69\n6.29\n3.13\n4005.77\n368.53\n9.20\n51.33\n1.60\n3.13\n19.27\n0.77\n3.97\n2.67\n0.10\n3.93\n\n\nGentoo penguin (Pygoscelis papua)\nFEMALE\n212.84\n3.47\n1.63\n4684.69\n297.46\n6.35\n45.46\n1.97\n4.34\n14.21\n0.54\n3.78\n3.20\n0.14\n4.45\n\n\nMALE\n221.20\n5.22\n2.36\n5476.70\n301.32\n5.50\n49.01\n2.29\n4.68\n15.73\n0.79\n5.00\n3.12\n0.18\n5.77\n\n\n\n\n\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAbove is a general statistics table for the quantitative features present in the penguins data. Some noteworthy observations from this table are below.\nAdelie penguins:\n\nFemales\n\nSmallest average flipper length, body mass, culmen length, and culmen ratio\nLargest average culmen depth\n\nMales\n\nSmallest average flipper length, culmen length, and culmen ratio\n\n\nChinstrap penguins:\n\nFemales\n\nLargest average culmen length\n\nMales\n\nSmallest average body mass\nLargest average culmen length and culmen depth\n\n\nGentoo penguins:\n\nFemales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\nMales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\n\nRegarding the variability in the distribution of each feature represented in the table above, the coefficient of variation (as a percentage) is below 10% for all feature distributions. According to some brief research on CV, the CV values shown in the table above suggest that there is a relatively low degree of variability in the distributions of each feature."
  },
  {
    "objectID": "posts/post_1/index.html#summary-statistics-and-preliminary-visualizations",
    "href": "posts/post_1/index.html#summary-statistics-and-preliminary-visualizations",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "",
    "text": "Code\n# Creating linear regression models and calculating r^2 values\n\n## Adelie\nc1 = np.polyfit(adelie['Body Mass (g)'], adelie['Flipper Length (mm)'], 1)\np1 = np.polyval(c1, adelie['Body Mass (g)'])\nr1 = adelie['Flipper Length (mm)'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((adelie['Flipper Length (mm)'] - np.mean(adelie['Flipper Length (mm)']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Chinstrap\nc2 = np.polyfit(chinstrap['Body Mass (g)'], chinstrap['Flipper Length (mm)'], 1)\np2 = np.polyval(c2, chinstrap['Body Mass (g)'])\nr2 = chinstrap['Flipper Length (mm)'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((chinstrap['Flipper Length (mm)'] - np.mean(chinstrap['Flipper Length (mm)']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n## Gentoo\nc3 = np.polyfit(gentoo['Body Mass (g)'], gentoo['Flipper Length (mm)'], 1)\np3 = np.polyval(c3, gentoo['Body Mass (g)'])\nr3 = gentoo['Flipper Length (mm)'] - p3\nssr3 = np.sum(r3**2)\nsst3 = np.sum((gentoo['Flipper Length (mm)'] - np.mean(gentoo['Flipper Length (mm)']))**2)\nrs3 = 1 - (ssr3 / sst3)\n\n\nAbove, I’m creating a linear regression model of flipper length by body mass for each species (using np.polyfit). I’m also extracting the \\(R^2\\) values (using predictions from np.polyval to calculate residuals) for each regression model to include in my plots below. I searched online how to use these two functions.\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (10, 7))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Setting up the initial scatter plot\nax[0] = sns.scatterplot(data = train_viz, x = 'Body Mass (g)', y = 'Flipper Length (mm)', hue = 'Species', palette = ['#B85ED4', '#2A7A7A', '#F28234'], style = 'Species', s = 50, ax = ax[0])\n\n# Adding regression lines for each species\nsns.regplot(data = adelie, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#F28234'}, ax = ax[0])\nsns.regplot(data = chinstrap, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#B85ED4'}, ax = ax[0])\nsns.regplot(data = gentoo, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#2A7A7A'}, ax = ax[0])\n\n# Plot styling to make colors match up and the text boxes look nicer\nax[0].set_title(\"Penguin Flipper Length (mm) by Body Mass (g)\\nColored by Species\")\nax[0].legend(frameon = True, prop = {'size': 9})\nax[0].text(5200, 175.75, '           \\n', fontsize = 20, bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'grey', boxstyle = 'round, pad=0.3'))\nax[0].text(5555, 180, f'     $R^2 = {rs3:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 178, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 176, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5200, 180.1, '\\u2013', color='#2A7A7A', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 178.1, '\\u2013', color='#B85ED4', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 176.1, '\\u2013', color='#F28234', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Setting up the box plot and doing some simple styling\nax[1] = sns.boxplot(train_viz, x = \"Species\", y = \"Culmen Ratio (L/D)\", hue = \"Sex\", ax = ax[1])\nax[1].set_xticks([0, 1, 2])\nax[1].set_xticklabels([\"Chinstrap\", \"Gentoo\", \"Adelie\"])\nax[1].legend(prop = {'size': 10}, frameon = True)\nax[1].set_title(\"Penguin Culmen Ratio (L/D) by Species\\nGrouped by Sex\")\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.2)\n\n\n\n\n\n\n\n\n\nIn the figure to the left, the relationship between penguin flipper length (mm) and body mass (g) for each species of penguin is displayed. Visually, there appears to be a notable positive, linear relationship between flipper length and body mass in general. That is, it seems that as penguin body mass increases, the flipper length increases as well regardless of species.\nAdditionally, there appears to be some clustering by species shown in this relationship. Gentoo penguins appear to have both the largest flipper lengths and body masses. There is less of a visually obvious distinction between Chinstrap and Adelie penguins shown by the relationship between body mass and flipper length. However, I believe it is reasonable to hypothesize that Chinstrap penguins have a slightly greater average flipper length while Adelie penguins have a slightly greater body mass.\nFrom the \\(R^2\\) values for the regression lines corresponding to the relationship between body mass and flipper length for each penguin species, I feel that it’s reasonable to say the positive linear relationships between the two variables in question for each species range from weak/moderate to moderate in strength. Further, while I do not have the statistical knowledge to confirm nor deny this hypothesis, perhaps the clear visual difference observed across the three species-specific regression lines could provide useful insight into this classification task.\nIn general, this plot reveals some useful information about the differences observed across each penguin species from two relevant variables. While this plot likely does not provide highly convincing information pertaining to the species classification of penguins from certain features, it does highlight a relationship between two key quantitative variables that displays a preliminary approach to this classification task.\nThe figure to the right displays the general distribution of the Culmen Ratio (L/D) feature across penguin sex and penguin species. The Culmen Ratio (L/D) is the ratio of culmen length (mm) to culmen depth (mm). With no prior knowledge about culmen size and dimensions in penguins, I thought it would be interesting to compute the length-depth ratio for each penguin and see how this ratio differed by sex and across each species. Observing the comparison of the culmen ratio between male and female penguins, there does not appear to be as much visually obvious information. However, to me, there appears to be minimal distribution overlap in the culmen ratio across each species. I believe this suggests that the culmen ratio or related features (culmen length and culmen depth) could be useful in model construction to successfully complete this classification task.\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.groupby(['Species', 'Sex']).aggregate({\"Flipper Length (mm)\" : [\"mean\", \"std\", cv], \n                                                             \"Body Mass (g)\" : [\"mean\", \"std\", cv], \"Culmen Length (mm)\": [\"mean\", \"std\", cv], \n                                                             \"Culmen Depth (mm)\": [\"mean\", \"std\", cv], \"Culmen Ratio (L/D)\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {'mean': 'Mean', 'std': 'STD', 'cv': 'CV (%)'})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nBody Mass (g)\nCulmen Length (mm)\nCulmen Depth (mm)\nCulmen Ratio (L/D)\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\nFEMALE\n187.92\n5.43\n2.89\n3350.47\n262.87\n7.85\n37.43\n1.95\n5.20\n17.64\n0.92\n5.21\n2.13\n0.15\n6.96\n\n\nMALE\n192.33\n7.00\n3.64\n4052.87\n331.57\n8.18\n40.40\n2.37\n5.86\n19.08\n1.05\n5.48\n2.12\n0.17\n7.89\n\n\nChinstrap penguin (Pygoscelis antarctica)\nFEMALE\n192.06\n5.90\n3.07\n3523.39\n294.95\n8.37\n46.72\n3.17\n6.78\n17.61\n0.80\n4.55\n2.66\n0.19\n7.21\n\n\nMALE\n200.69\n6.29\n3.13\n4005.77\n368.53\n9.20\n51.33\n1.60\n3.13\n19.27\n0.77\n3.97\n2.67\n0.10\n3.93\n\n\nGentoo penguin (Pygoscelis papua)\nFEMALE\n212.84\n3.47\n1.63\n4684.69\n297.46\n6.35\n45.46\n1.97\n4.34\n14.21\n0.54\n3.78\n3.20\n0.14\n4.45\n\n\nMALE\n221.20\n5.22\n2.36\n5476.70\n301.32\n5.50\n49.01\n2.29\n4.68\n15.73\n0.79\n5.00\n3.12\n0.18\n5.77\n\n\n\n\n\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAbove is a general statistics table for the quantitative features present in the penguins data. Some noteworthy observations from this table are below.\nAdelie penguins:\n\nFemales\n\nSmallest average flipper length, body mass, culmen length, and culmen ratio\nLargest average culmen depth\n\nMales\n\nSmallest average flipper length, culmen length, and culmen ratio\n\n\nChinstrap penguins:\n\nFemales\n\nLargest average culmen length\n\nMales\n\nSmallest average body mass\nLargest average culmen length and culmen depth\n\n\nGentoo penguins:\n\nFemales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\nMales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\n\nRegarding the variability in the distribution of each feature represented in the table above, the coefficient of variation (as a percentage) is below 10% for all feature distributions. According to some brief research on CV, the CV values shown in the table above suggest that there is a relatively low degree of variability in the distributions of each feature."
  },
  {
    "objectID": "posts/post_1/index.html#testing-the-model",
    "href": "posts/post_1/index.html#testing-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Testing the Model",
    "text": "Testing the Model\nAfter refining my model, I then tested it on the testing data. To my excitement, the model dispayed a \\(98.529\\%\\) testing accuracy.\n\n\nCode\n# Accessing test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Testing the model!\nX_test, y_test = prepare_data(test)\ntest_score = rfc_refined.score(X_test[X_train_selected.columns], y_test)\nts2 = rfc_base.score(X_test[X_train_selected.columns], y_test)\nprint(f'Refined (cross-validated) Model Test Accuracy: {test_score * 100: .3f}%')\n\n\nRefined (cross-validated) Model Test Accuracy:  98.529%\n\n\nBelow are the decision regions determined by the model for both the training and testing data. Visually, the decision regions for the training and testing data appear to be extremely similar. Additionally, I feel that it is reasonable to state that the decision regions for both the training and testing data do not display a high degree of model-overfitting.\n\n\nCode\n# Decision region plotting - code provided by Prof. Chodrow\ndef plot_regions(model, X, y, type):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (10, 5))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      colors = ['#2A7A7A', '#B85ED4', '#F28234']\n      og = ['red', 'green', 'blue']\n      cmap = ListedColormap(colors)\n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = cmap, alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = cmap, vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i][7:] + \" Island\")\n      \n      patches = []\n      for color, spec in zip(['#F28234', '#B85ED4', '#2A7A7A'], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n\n      if (type):\n         fig.suptitle(\"Decision Regions for Training Data\")\n      else:\n         fig.suptitle(\"Decision Regions for Testing Data\")\n      \n      plt.tight_layout()\n\nplot_regions(rfc_refined, X_train_selected, y_train, 1)\nplot_regions(rfc_refined, X_test[X_train_selected.columns], y_test, 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI made some minor adjustments to the code above provided by Prof. Chodrow (primarily debugging, color changing, and adding titles)"
  },
  {
    "objectID": "posts/post_1/index.html#confusion-matrix-for-the-model",
    "href": "posts/post_1/index.html#confusion-matrix-for-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Confusion Matrix for the Model",
    "text": "Confusion Matrix for the Model\nBelow is the confusion matrix to evaluate the model’s testing performance. As expected with \\(&lt; 100\\%\\) (\\(98.529\\%\\)) testing accuracy, the confusion matrix has at least some (in this case exactly 1) non-zero entries off the diagonal. This indicates that the model made 1 misclassification. That is, all Adelie penguins and Chinstrap penguins were correctly classified, but there was one Gentoo penguin who was misclassified as an Adelie penguin (shucks).\n\n\nCode\n# Establishing model predictions for the test data\ny_test_pred = rfc_refined.predict(X_test[X_train_selected.columns])\nC = confusion_matrix(y_test, y_test_pred)\nspecies = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\n# Creating a heatmap for better confusion matrix visualization\nplt.figure(figsize=(6, 5))\nsns.heatmap(C, annot = True, fmt = \"d\", cmap = 'Greens', cbar = False, xticklabels = species, yticklabels = species)\n\n# Setting labels and title\nplt.xlabel(\"Predicted Species Classification\")\nplt.ylabel(\"True Species Classification\")\nplt.title(\"Palmer Penguins Classification Confusion Matrix\")\n\nplt.show()\n\n# Printing confusion matrix results\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\n\n\n\n\n\n\n\n\nThere were 31 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 11 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 1 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 25 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSCI 0451A Blog - Spring 2025",
    "section": "",
    "text": "Post 4 - Auditing Bias in Machine Learning Models\n\n\n\n\n\nAn introductory examination racial gender bias in a predictive ML model (predicting employment).\n\n\n\n\n\nMar 12, 2025\n\n\nCol McDermott\n\n\n\n\n\n\n\n\n\n\n\n\nPost 3 - Replication Study: Dissecting Racial Bias in Algorithms\n\n\n\n\n\nAn introductory replication study of an investigating racial bias in an algorithm applied to manage population health.\n\n\n\n\n\nMar 12, 2025\n\n\nCol McDermott\n\n\n\n\n\n\n\n\n\n\n\n\nPost 2 - Exploring Automated Decision Models\n\n\n\n\n\nAn introductory analysis of an automated decision model in the context of credit-risk prediction\n\n\n\n\n\nMar 4, 2025\n\n\nCol McDermott\n\n\n\n\n\n\n\n\n\n\n\n\nPost 1 - Classifying Palmer Penguins\n\n\n\n\n\nA ternary classification of penguin species: Gentoo, Adelie, and Chinstrap\n\n\n\n\n\nFeb 17, 2025\n\n\nCol McDermott\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post_3/index.html",
    "href": "posts/post_3/index.html",
    "title": "Post 3 - Replication Study: Dissecting Racial Bias in Algorithms",
    "section": "",
    "text": "The following replication study aims to replicate elements of this original study while following these guidelines\n\n\nCode\n# Includuing all additional imports\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport itertools\n\n# Reading in population health data\nhd = pd.read_csv(\"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\")\n\n\nIncluding all additional imports\nExplanation of data source and features.\n\n\n\nCode Description\nFigure 1 (Reproduced)\nAnalysis of reproducing Figure 1.\n\n\n\nCode Description\nFigure 3 (Reproduced)\nAnalysis of reproducing Figure 3.\n\n\n\n\n\nCode Description\nAnalysis of data preparation.\n\n\n\nCode Description\nAnalysis of modeling."
  },
  {
    "objectID": "posts/post_3/index.html#accessing-the-data",
    "href": "posts/post_3/index.html#accessing-the-data",
    "title": "Post 3 - Replication Study: Dissecting Racial Bias in Algorithms",
    "section": "",
    "text": "The following replication study aims to replicate elements of this original study while following these guidelines\n\n\nCode\n# Includuing all additional imports\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport itertools\n\n# Reading in population health data\nhd = pd.read_csv(\"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\")\n\n\nIncluding all additional imports\nExplanation of data source and features."
  },
  {
    "objectID": "posts/post_3/index.html#reproducing-figure-1",
    "href": "posts/post_3/index.html#reproducing-figure-1",
    "title": "Post 3 - Replication Study: Dissecting Racial Bias in Algorithms",
    "section": "",
    "text": "Code Description\nFigure 1 (Reproduced)\nAnalysis of reproducing Figure 1."
  },
  {
    "objectID": "posts/post_3/index.html#reproducing-figure-3",
    "href": "posts/post_3/index.html#reproducing-figure-3",
    "title": "Post 3 - Replication Study: Dissecting Racial Bias in Algorithms",
    "section": "",
    "text": "Code Description\nFigure 3 (Reproduced)\nAnalysis of reproducing Figure 3."
  },
  {
    "objectID": "posts/post_3/index.html#modeling-cost-disparity",
    "href": "posts/post_3/index.html#modeling-cost-disparity",
    "title": "Post 3 - Replication Study: Dissecting Racial Bias in Algorithms",
    "section": "",
    "text": "Code Description\nAnalysis of data preparation.\n\n\n\nCode Description\nAnalysis of modeling."
  },
  {
    "objectID": "posts/post_4/index.html",
    "href": "posts/post_4/index.html",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code\n# Includuing all additional imports\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom folktables import ACSDataSource, BasicProblem\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import make_pipeline\nfrom matplotlib import pyplot as plt\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport itertools\n\n# Downloading ACS PUMS data for the state of Massachusetts - Code provided by Prof. Chodrow\nSTATE = \"MA\"\nds = ACSDataSource(survey_year = \"2018\", \n                            horizon = \"1-Year\", \n                            survey = \"person\")\nma = ds.get_data(states = [STATE], download = True)\n\n\nIncluding all additional imports\nThe data for this study comes from an ACS (American Community Survey) data set. Specifically, the data is from a 2018 PUMS (Public Use Microdata Sample) survey for the state of Massachusetts. Each observation from this data set is an individual massachusetts resident who completed the 2018 PUMS survey. The data is downloaded using the ACSDataSource class from the folktables package.\n\n\n\n\nCode\nvars = [\"AGEP\", \"SCHL\", \"MAR\", \"RELP\", \"DIS\", \"ESP\", \"CIT\", \"MIG\", \"MIL\", \"ANC\", \"NATIVITY\", \"DEAR\", \"DEYE\", \"DREM\", \"SEX\", \"RAC1P\", \"ESR\"]\n\n\nUntouched, the data contains nearly 300 different features. However, for this study, I will only be using a subset of the columns:\n\nAGEP: Age (Range 0 - 99)\nSCHL: Educational Attainment (Range 1 - 24)\nMAR: Marital Status (Range 1 - 5)\nRELP: Relationship to Householder (Range 1 - 17)\nDIS: Disability Present (Binary)\nESP: Employment Status of Parents (Range 1 - 8)\nCIT: Citizenship Status (Range 1 - 5)\nMIG: Mobility Status - Lived in Specified Location 1 Year Ago (Range 1 - 3)\nMIL: Military Service (Range 1 - 5)\nANC: Ancestry (Range 1 - 4, 8)\nNATIVITY: Nativity (Binary)\nDEAR: Hearing Difficulty (Binary)\nDEYE: Vision Difficulty (Binary)\nDREM: Cognitive Difficulty (Binary)\nSEX: Sex (Binary)\nRAC1P: Race (Range 1 - 9)\nESR: Employment Status (Range 1 - 6)\nPINCP: Total Person Income (Integer Range of Income in US Dollars: -19997 - 4209995)\n\n\n\n\n\n\n\n\n\nCode\n# Filtering out employment status (target) and race variables\nvars1 = [v for v in vars if v not in [\"ESR\", \"RAC1P\"]]\n\n# Defining the predictive modeling task - Code provided by Prof. Chodrow\nEmploymentProblem = BasicProblem(\n    features = vars1,\n    target = \"ESR\",\n    target_transform = lambda x: x == 1,\n    group = \"RAC1P\",\n    preprocess = lambda x: x,\n    postprocess = lambda x: np.nan_to_num(x, -1),\n)\nfeatures, label, group = EmploymentProblem.df_to_numpy(ma)\n\n# Test, train split procedure\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(features, label, group, test_size = 0.2, random_state = 69)\n\n\nCode above defines the predictive modeling task and constructs the training data for the employment prediction model.\nBefore constructing the first predictive model, the predictive modeling task is defined. Afterwards, a test-train-split procedure is conducted on the data to prepare it for model fitting.\n\n\n\n\n\nCode\n# Observing some general descriptives in the training data\ntrain = pd.DataFrame(X_train, columns = vars1)\ntrain[\"emp_status\"] = y_train.astype(int)\ntrain[\"race\"] = group_train\ntrain.dropna(inplace = True)\n\n# Total number of individuals in the training data\nn = train.shape[0]\n\n# Proportion of employed individuals in the training data\nemp_prop = train[\"emp_status\"].mean()\n\n# Proportion of employed individuals of each race\ntot_emp = (train[\"emp_status\"] == 1).sum()\nrace_prop_emp_tot = (train.groupby(\"race\")[\"emp_status\"].sum() / tot_emp) * 100\n\n# Proportion of employed individuals within each race\nrace_prop_emp = (train.groupby(\"race\")[\"emp_status\"].mean()) * 100\n\n# Plotting proportion of employed individuals (total)\n## Creating dataframe for plotting\nemp_prop_tot = pd.DataFrame({\n    \"emp\": ['Unemployed', 'Employed'],\n    \"prop\": [1 - emp_prop, emp_prop]\n})\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(emp_prop_tot, x = \"prop\", y = \"emp\", hue = \"prop\", palette = [\"#D8BFD8\", \"#5D3A6D\"], legend = False, width = 0.6, ax = ax)\nax.set_title(\"Overall Proportion of Employed Individuals\", fontsize = 16)\nax.set_yticks([0, 1])\nax.set_yticklabels([\"Unemployed\", \"Employed\"], fontsize = 12, rotation = 60)\nax.set_xlim(0.25, 0.55)\nax.set_xticks([i / 10 for i in range(3, 6)])\nax.set_xticklabels([f\"{i * 10}%\" for i in range(3, 6)], fontsize = 12)\nax.set_xlabel(\"Proportion to all Individuals\", fontsize = 14)\nax.set_ylabel(\"Employment Status\", fontsize = 14)\nax.text((1 - emp_prop) + 0.01, 0, f\"{round((1 - emp_prop) * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\", rotation = 60)\nax.text(emp_prop + 0.01, 1, f\"{round( emp_prop * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\", rotation = 60)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates three proportions of employed individuals in the data: 1. General proportion of employment across all individuals 2. Proportion of each race in all employed individuals 3. Proportion of employed individuals within each race.\nFigure 1\nPrior to constructing and fitting the predictive model, it’s useful to explore some general descriptives of the data. In total, there are 56104 individuals in the training data. Approximately \\(50\\%\\) of individuals from the data are employed (as of their filling out the survey in 2018).\n\n\nCode\n# Plotting proportion of employed individuals across each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nsns.countplot(train[train[\"emp_status\"] == 1], x = \"emp_status\", stat = \"proportion\", hue = \"race\", palette = sns.color_palette()[:-1], width = 0.9, dodge = True, ax = ax)\n\n# Adding space between bars\nfor patch in ax.patches:\n    patch.set_width(patch.get_width() * 0.8)\nax.set_yscale(\"log\", base = 10)\nax.legend(title = \"Race\", labels = [\"White\", \"Black or\\nAfrican American\", \"American Indian\", \"Alaska Native\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian &\\nOther Pacific Islander\", \"Other Race\", \"Two or more Races\"], ncol = 3, frameon = True, fontsize = 8, title_fontsize = 8)\nax.set_title(\"Proportion of Each Race Category in All Employed Individuals\", fontsize = 16)\nax.set_xticks([0])\nax.set_xticklabels([\"\"], fontsize = 12)\nax.set_xlabel(\"Employed Individuals\", fontsize = 14)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above plots the proportions calculated above\nFigure 2\nOf the employed individuals:\n\nAbout \\(83\\%\\) are white alone\nAbout \\(5.5\\%\\) are black or African American alone\nAbout \\(0.01\\%\\) are American Indian alone\nAbout \\(0.004\\%\\) are Alaska Native alone\n\\(^1\\) About \\(0.06\\%\\) are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races\nAbout \\(6.6\\%\\) are Asian alone\nAbout \\(0.039\\%\\) are Native Hawaiian and Other Pacific Islander alone\nAbout \\(2.87\\%\\) are some other race alone\nAbout \\(2.1\\%\\) are two or more races\n\n\n\nCode\n# Plotting proportion of employed individuals within each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nsns.countplot(train, x = \"race\", hue = \"emp_status\", stat = \"proportion\", palette = [\"#D8BFD8\", \"#5D3A6D\"], ax = ax)\nax.set_title(\"Proportion of Employed Individuals Within Each Race Category\", fontsize = 16)\nax.set_yscale(\"log\", base = 10)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\nax.legend(title = \"Employment Status\", labels = [\"Unemployed\", \"Employed\"], frameon = True, fontsize = 12, title_fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above plots the proportions calculated above\nFigure 3\nWithin each race, the proportions of employed individuals are:\n\nAbout \\(51.5\\%\\) of white alone individuals are employed\nAbout \\(46.1\\%\\) of black or African American alone individuals are employed\nAbout \\(47\\%\\) of American Indian alone individuals are employed\n\\(100\\%\\) of Alaska Native alone individuals are employed (there is a single Alaska Native alone individual in the data)\n\\(^1\\) About \\(47.1\\%\\) of individuals who are – with American Indian and Alaska Native tribes specified, or are American Indian or Alaska Native, or are not specified and are of no other races – are employed\nAbout \\(50.2\\%\\) of Asian alone individuals are employed\nAbout \\(61.1\\%\\) of Native Hawaiian and Other Pacific Islander alone individuals are employed\nAbout \\(47.3\\%\\) individuals of some other race alone are employed\nAbout \\(37.6\\%\\) of individuals of two or more races are employed\n\n\n\nCode\n# Examining the intersection of race and gender as it relates to employment\nemp = train[train[\"emp_status\"] == 1]\n\n# Array to store proportions of employed male and female individuals for each race\nixn_data = []\nfor race in emp[\"race\"].unique():\n    curr_race = emp[emp[\"race\"] == race]\n    m_emp_prop = curr_race[curr_race[\"SEX\"] == 1.0].shape[0] / emp.shape[0]\n    f_emp_prop = curr_race[curr_race[\"SEX\"] == 2.0].shape[0] / emp.shape[0]\n    ixn_data.append({\"Race\": race, \"Sex\": \"Male\", \"Emp_prop\": m_emp_prop})\n    ixn_data.append({\"Race\": race, \"Sex\": \"Female\", \"Emp_prop\": f_emp_prop})\nixn_data = pd.DataFrame(ixn_data)\nixn_data.head()\n\n# Barplot to display the intersection of race and gender in employment status\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(ixn_data, x = \"Race\", y = \"Emp_prop\", hue = \"Sex\", palette = [\"#FFDAB9\", \"darkorange\"], ax = ax)\nax.set_yscale(\"log\", base = 10)\nax.set_title(\"Proportion of Employed Individuals for Each Race Category by Sex\", fontsize = 16)\nax.set_ylabel(\"Proportion of Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(1, 5))], fontsize = 12)\nax.legend(frameon = True, fontsize = 12, title = \"Sex\", title_fontsize = 14)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates and plots the proportions of employment (of all employed individuals) for each race by sex.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nFigure 4\nThe figure above displays the possible intersectionality between race and sex among employed individuals. However, for none of the nine race categories found in this data set, does there appear to be a significant difference in employment rates between males and females. Therefore, based on this figure, there does not appear to be a significant intersectional effect of race and sex on employment rates. Please note that this finding does not dismiss the presence of intersectional biases and systemic injustices that may impact certain individuals from this data set. The existence of such intersectionality may very well be present in the data and but just not captured by this figure. Observing the intersectionality of race and gender relating to employment may be more clearly observed through other statistical processes.\n\n\nCode\n# Examining the intersection of race and disability as it relates to employment\n## Array to store proportions of employed visually impaired and non-visually impaired individuals for each race\nixn_data = []\nfor race in emp[\"race\"].unique():\n    curr_race = emp[emp[\"race\"] == race]\n    d_emp_prop = curr_race[curr_race[\"DIS\"] == 1.0].shape[0] / emp.shape[0]\n    nd_emp_prop = curr_race[curr_race[\"DIS\"] == 2.0].shape[0] / emp.shape[0]\n    ixn_data.append({\"Race\": race, \"Disability Present\": \"Yes\", \"Emp_prop\": d_emp_prop})\n    ixn_data.append({\"Race\": race, \"Disability Present\": \"No\", \"Emp_prop\": nd_emp_prop})\nixn_data = pd.DataFrame(ixn_data)\nixn_data.head()\n\n# Barplot to display the intersection of race and gender in employment status\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(ixn_data, x = \"Race\", y = \"Emp_prop\", hue = \"Disability Present\", palette = [\"lightgreen\", \"darkgreen\"], ax = ax)\nax.set_yscale(\"log\", base = 10)\nax.set_title(\"Proportion of Employed Individuals for Each Race Category by Presence of a Disability\", fontsize = 16)\nax.set_ylabel(\"Proportion of Employed Individuals ($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\nax.legend(frameon = True, fontsize = 12, title = \"Disability Present\", title_fontsize = 14)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates and plots the proportions of employment (of all employed individuals) for each race by disability presence.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nFigure 5\nThe figure above displays the possible intersectionality between race and disability among employed individuals. Unlike the apparent lack of intersectionality between race and sex, in all of the nine race categories found in this data set, there appears to be a significant difference in employment rates between individuals with and without disabilities present. Specifically, it seems that the lowest overall proportions of employed individuals are found at the combination of low-employment racial groups and when a disability is present. Thus, based on this figure, I believe that it is reasonable to identify an observable intersectional effect of race and disability on employment rates.\n\n\n\n\n\nCode\n# Constructing and fitting the model\nmodel = make_pipeline(StandardScaler(), DecisionTreeClassifier())\nmodel.fit(X_train, y_train)\n\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('decisiontreeclassifier', DecisionTreeClassifier())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('standardscaler', StandardScaler()),\n                ('decisiontreeclassifier', DecisionTreeClassifier())]) StandardScaler?Documentation for StandardScalerStandardScaler() DecisionTreeClassifier?Documentation for DecisionTreeClassifierDecisionTreeClassifier() \n\n\n\n\nCode\n# Refining the model\n## Identifying the optimal max_depth value - Model Complexity parameter for DecisionTreeCLassifier model - though iterative process\n# #Updated variables\nbest_max_depth = None\nbest_avg_score = 0\nfor md in np.random.randint(1, 1001, size = 10):\n    model.set_params(decisiontreeclassifier__max_depth = md)\n    avg_score = cross_val_score(model, X_train, y_train, cv = 5).mean()\n    if avg_score &gt; best_avg_score:\n        best_avg_score = avg_score\n        best_max_depth = md\n\n# Fitting the model with the optimal max_depth value\ndtc_refined = model.set_params(decisiontreeclassifier__max_depth = best_max_depth)\ndtc_refined.fit(X_train, y_train)\ngen_score = dtc_refined.score(X_train, y_train)\nprint(f\"Refined Model Overall Accuracy: {gen_score * 100: .3f}%\")\n\n\nRefined Model Overall Accuracy:  92.658%\n\n\nCode above uses the make_pipeline method from the sklearn package, the training data is first standardized and then used to fit a DecisionTreeClassifier model (also from sklearn). The max_depth parameter for the model is tuned iteratively with corss-validation to set the tree depth that maximizes overall accuracy while mitigating model over-fitting.\nTo refine the model, an iterative process tuning the model complexity (using the max_depth parameter) with cross-validation is conducted. This process aims at model maximizing trining accuracy while reducing the presence of model over-fitting. Following this tuning procedure, the model has an overall accuracy of approximately \\(92.658\\%\\) – as an initial metric, this indicates a considerable accurate model.\n\n\n\n\n\nCode\n# Calculating various accuracy metrics\n## Overall Training data accuracy\ny_preds_tr = dtc_refined.predict(X_train)\nacc_tr = (y_preds_tr == y_train).mean()\n\n# Confusion matrix for refined model\nC = confusion_matrix(y_train, y_preds_tr)\nemp_status = [\"Unemployed\", \"Employed\"]\n\n# Creating a heatmap for better confusion matrix visualization\nfig, ax = plt.subplots(1, 1, figsize = (5, 5))\nsns.heatmap(C, annot = True, annot_kws = {\"size\": 12}, fmt = \"d\", cmap = \"Reds\", cbar = False, ax = ax)\n\n# Plot styling\nax.set_xlabel(\"Predicted Employment Status\", fontsize = 14)\nax.set_ylabel(\"True Employment Status\", fontsize = 14)\nax.set_xticklabels(emp_status, fontsize = 12)\nax.set_yticklabels(emp_status, fontsize = 12)\nax.set_title(\"Employment Status Classification Confusion Matrix\", fontsize = 16)\n\nplt.show()\n\n# Printing confusion matrix results\nprint(f\"There were {C[0, 0]} unemployed individuals that were predicted to be unemployed.\")\nprint(f\"There were {C[0, 1]} unemployed individuals that were predicted to be employed.\")\nprint(f\"There were {C[1, 0]} employed individuals that were predicted to be unemployed.\")\nprint(f\"There were {C[1, 1]} unemployed individuals that were predicted to be employed.\")\n\n# Calculating various accuracies and error rates\ng_fnr = C[1, 0] / (C[1, 0] + C[1, 1])\ng_tnr = C[0, 0] / (C[0, 0] + C[0, 1])\ng_fpr = 1 - g_tnr\ng_tpr = 1 - g_fnr\ng_ppv = C[1, 1] / (C[1, 1] + C[0, 1])\ng_npv = C[0, 0] / (C[0, 0] + C[1, 0])\n\n\n\n\n\n\n\n\n\nThere were 25792 unemployed individuals that were predicted to be unemployed.\nThere were 1943 unemployed individuals that were predicted to be employed.\nThere were 2176 employed individuals that were predicted to be unemployed.\nThere were 26193 unemployed individuals that were predicted to be employed.\n\n\nCode above constructs the general confusion matrix for the refined model and calculates the typical accuracy/error rates: FPR, FNR, TPR, TNR, PPV, and NPV\nFigure 6\nSome key overall accuracy and error rates of the refined model are:\n\nFNR: About \\(~8\\%\\) of truly employed individuals were misclassified as unemployed.\nTNR: About \\(~93\\%\\) of truly unemployed individuals were correctly classified as unemployed.\nFPR: About \\(7\\%\\) of truly unemployed individuals were misclassified as employed.\nTPR: About \\(92\\%\\) of truly employed individuals were correctly classified as employed\nPPV: About \\(93\\%\\) of “employed” model predictions are correct while only about \\(7\\%\\) are incorrect.\nNPV: About \\(92\\%\\) of “unemployed” model predictions are correct while only about \\(8\\%\\) are incorrect.\n\nThe general accuracy and error rates outlines above indicate that the refined model is approximately equally accurate in predicting that truly unemployed individuals are unemployed and in predicting that truly employed individuals are employed. Additionally, the refined misclassifies truly unemployed individuals and truly employed individuals at nearly the same rate. The refined model yields a PPV and NPV that are nearly equal. This suggests that, for any given individual, the refined model is generally just as good at predicting if this individual is employed as it is at predicting if this individual is unemployed.\nWhile the overall accuracy of the refined model is appears considerably high, it is crucial to investigate the same accuracy rates across different groups of observations found in the data. In this context, the prediction task is to identify if an individual is employed or not. In the data, the race of each individual is provided, and not only is race undoubtedly related to employment in the US but race is also a factor by which systemic biases and systematic discrimination occurs in the American workforce. Although the model was not trained using this variable (race), there is no guarantee that the model does not rely on variables highly related to race or that could stand as proxies for race. Thus, it is critically important to examine if the model perpetuates systemic biases and past injustices effecting certain individuals differently on the bases of racial identity.\n\n\n\n\n\n\n\n\nCode\n# Adding a column for indicating correct predictions\ntrain[\"pred\"] = y_preds_tr\ntrain[\"correct_pred\"] = (y_preds_tr == y_train).astype(int)\n\n# Recoding race variable for easier visualization\nrace_recode = {\n    1.0: \"White\",\n    2.0: \"Black or African American\",\n    3.0: \"American Indian\",\n    4.0: \"Alaska Native\",\n    5.0: f\"A.I./A.N. Tribe Specified\\u00B9\",\n    6.0: \"Asian\",\n    7.0: \" Native Hawaiian and Other Pacific Islander\",\n    8.0: \"Some Other Race\",\n    9.0: \" Two or More Races\"\n}\ntrain[\"Racial Group (Abbreviated Categories)\"] = train[\"race\"].map(race_recode)\n\n# Helper functions to calculate various accuracy and error rate metrics\ndef acc(x):\n    return str(round(x[\"correct_pred\"].mean() * 100, 1)) + \" %\"\n\ndef prop(x):\n    return str(round((x.shape[0] / train.shape[0]) * 100, 1)) + \" %\"\n\ndef fpr(x):\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    if ((fp + tn) == 0):\n        return \"NA\"\n    fpr = fp / (fp + tn)\n    \n    return str(round(fpr * 100, 1)) + \" %\"\n\ndef fnr(x):\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    if ((fn + tp) == 0):\n        return \"NA\"\n    fnr = fn / (fn + tp)\n\n    return str(round(fnr * 100, 1)) + \" %\"\n\ndef tpr(x):\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    if ((fn + tp) == 0):\n        return \"NA\"\n    tpr = tp / (fn + tp)\n\n    return str(round(tpr * 100, 1)) + \" %\"\n\ndef tnr(x):\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    if ((fp + tn) == 0):\n        return \"NA\"\n    tnr = tn / (fp + tn)\n    \n    return str(round(tnr * 100, 1)) + \" %\"\n\ndef ppv(x):\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    if ((tp + fp) == 0):\n        return \"NA\"\n    ppv = tp / (tp + fp)\n    \n    return str(round(ppv * 100, 1)) + \" %\"\n\ndef npv(x):\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    if ((tn + fn) == 0):\n        return \"NA\"\n    npv = tn / (tn + fn)\n\n    return str(round(npv * 100, 1)) + \" %\"\n\n# Initializing data frame to visualize model accuracy and error rates for each race\nrace_acc = pd.DataFrame(index = range(1, 10), columns = [\"Racial Group (Abbr. Cats.)\", \"Model Accuracy\", \"Proportion to Tot. (Aprx.)\", \"FPR\", \"FNR\", \"TPR\", \"TNR\", \"PPV\", \"NPV\"])\n\n# Subsetting training data into each race category\nr1 = train[train[\"race\"] == 1.0]\nr2 = train[train[\"race\"] == 2.0]\nr3 = train[train[\"race\"] == 3.0]\nr4 = train[train[\"race\"] == 4.0]\nr5 = train[train[\"race\"] == 5.0]\nr6 = train[train[\"race\"] == 6.0]\nr7 = train[train[\"race\"] == 7.0]\nr8 = train[train[\"race\"] == 8.0]\nr9 = train[train[\"race\"] == 9.0]\n\n# Populating the accuracy/error rates table\nrace_acc.loc[1] = [race_recode.get(1.0), acc(r1), prop(r1), fpr(r1), fnr(r1), tpr(r1), tnr(r1), ppv(r1), npv(r1)]\nrace_acc.loc[3] = [race_recode.get(2.0), acc(r2), prop(r2), fpr(r2), fnr(r2), tpr(r2), tnr(r2), ppv(r2), npv(r2)]\nrace_acc.loc[2] = [race_recode.get(3.0), acc(r3), prop(r3), fpr(r3), fnr(r3), tpr(r3), tnr(r3), ppv(r3), npv(r3)]\nrace_acc.loc[4] = [race_recode.get(4.0), acc(r4), prop(r4), fpr(r4), fnr(r4), tpr(r4), tnr(r4), ppv(r4), npv(r4)]\nrace_acc.loc[5] = [race_recode.get(5.0), acc(r5), prop(r5), fpr(r5), fnr(r5), tpr(r5), tnr(r5), ppv(r5), npv(r5)]\nrace_acc.loc[6] = [race_recode.get(6.0), acc(r6), prop(r6), fpr(r6), fnr(r6), tpr(r6), tnr(r6), ppv(r6), npv(r6)]\nrace_acc.loc[7] = [race_recode.get(7.0), acc(r7), prop(r7), fpr(r7), fnr(r7), tpr(r7), tnr(r7), ppv(r7), npv(r7)]\nrace_acc.loc[8] = [race_recode.get(8.0), acc(r8), prop(r8), fpr(r8), fnr(r8), tpr(r8), tnr(r8), ppv(r8), npv(r8)]\nrace_acc.loc[9] = [race_recode.get(9.0), acc(r9), prop(r9), fpr(r9), fnr(r9), tpr(r9), tnr(r9), ppv(r9), npv(r9)]\nrace_acc\n\n\n\n\n\n\n\n\n\nRacial Group (Abbr. Cats.)\nModel Accuracy\nProportion to Tot. (Aprx.)\nFPR\nFNR\nTPR\nTNR\nPPV\nNPV\n\n\n\n\n1\nWhite\n92.2 %\n81.3 %\n7.7 %\n7.9 %\n92.1 %\n92.3 %\n92.7 %\n91.7 %\n\n\n2\nAmerican Indian\n90.9 %\n0.1 %\n11.4 %\n6.5 %\n93.5 %\n88.6 %\n87.9 %\n93.9 %\n\n\n3\nBlack or African American\n94.9 %\n6.0 %\n3.2 %\n7.2 %\n92.8 %\n96.8 %\n96.1 %\n94.0 %\n\n\n4\nAlaska Native\n100.0 %\n0.0 %\nNA\n0.0 %\n100.0 %\nNA\n100.0 %\nNA\n\n\n5\nA.I./A.N. Tribe Specified¹\n85.3 %\n0.1 %\n0.0 %\n31.2 %\n68.8 %\n100.0 %\n100.0 %\n78.3 %\n\n\n6\nAsian\n93.9 %\n6.7 %\n6.0 %\n6.2 %\n93.8 %\n94.0 %\n94.0 %\n93.7 %\n\n\n7\nNative Hawaiian and Other Pacific Islander\n94.4 %\n0.0 %\n0.0 %\n9.1 %\n90.9 %\n100.0 %\n100.0 %\n87.5 %\n\n\n8\nSome Other Race\n95.9 %\n3.1 %\n2.9 %\n5.4 %\n94.6 %\n97.1 %\n96.7 %\n95.2 %\n\n\n9\nTwo or More Races\n94.7 %\n2.8 %\n4.5 %\n6.6 %\n93.4 %\n95.5 %\n92.6 %\n96.0 %\n\n\n\n\n\n\n\nCode above subsets the training data into each race category and creates a table displaying the model’s accuracy and error rates in employment/unemployment predictions for each racial group.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nTable 1\nThe table above depicts the refined model’s accuracy and error rates for employment prediction of individuals across each racial group in the training data. The general accuracies for each racial group are all largely similar – with values ranging from around \\(82\\%\\) to \\(90\\%\\) accuracy. The FPR and FNR for each race are slightly less equal across all racial groups (FPR range from roughly \\(0\\%\\) to \\(11\\%\\) and FNR range from \\(0\\%\\) to \\(10\\%\\)), but these error rates do not differ dramatically (with the exception of the “American Indian and Alaska Native tribes specified” group with a FNR: \\(31.2\\%\\)). The same trend is generally observable for TPR and TNR across each racial group (TPR range from about \\(90\\%\\) to \\(100\\%\\) and TNR range from about \\(88\\%\\) to \\(100\\%\\)) - (with the exception of the “American Indian and Alaska Native tribes specified” group with a TPR: \\(68.8\\%\\)). Further, the PPV and NPV for each racial group are also approximately equal – with PPV values ranging from approximately \\(88\\%\\) to \\(100\\%\\) and NPV values ranging from approximately \\(80\\%\\) to \\(96\\%\\).\n\n\nCode\n# Changing column types for easier visualization\n## Saving a data frame for late use\nerb = race_acc.copy()\nfor col in race_acc.columns[1:]:\n    if (race_acc[col].dtype == \"object\"):\n        race_acc[col] = pd.to_numeric(race_acc[col].str.replace(\"%\", \"\").replace(\"NA\", np.nan))\n\n# Plotting the information described in the table above for easier visualization\nfig, ax = plt.subplots(1, 2, figsize = (20, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Accuracy by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"Model Accuracy\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[0])\nax[0].axhline(gen_score * 100, color = \"black\", linestyle = \"--\")\nax[0].set_ylim(40, 104)\nax[0].set_title(\"Model Accuracy\", fontsize = 16)\nax[0].set_xlabel(\"\")\nax[0].set_ylabel(\"Model Accuracy\", fontsize = 14)\nax[0].set_xticks(range(9))\nax[0].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[0].set_yticks([(20 * i) for i in range(3, 6)])\nax[0].set_yticklabels([f\"{20 * i}%\" for i in range(3, 6)], fontsize = 12)\nax[0].text(6.15, 99.5, f\"\\u2013 Overall Model Accuracy: {gen_score * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\n\n# FPR & FNR by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"FPR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[1])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"FNR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[1], edgecolor = \"black\")\nax[1].axhline(g_fpr * 100, color = \"purple\", linestyle = \"--\")\nax[1].axhline(g_fnr * 100, color = \"black\", linestyle = \"--\")\nax[1].set_title(\"FPR & FNR\", fontsize = 16)\nax[1].set_xlabel(\"\")\nax[1].set_ylabel(\"FPR & FNR\", fontsize = 14)\nax[1].set_xticks(range(9))\nax[1].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[1].set_yticks([i for i in range(0, 35, 5)])\nax[1].set_yticklabels([f\"{i}%\" for i in range(0, 35, 5)], fontsize = 12)\nax[1].text(6.5, 29.5, f\"\\u2013 Overall Model FNR: {g_fnr * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(6.5, 29, f\"   Overall Model FPR: {g_fpr * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[1].text(5.3, 29, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[1].text(1.5, 29.5, f\"   : FNR\\n   : FPR\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(1.25, 29.9, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[1].text(1.25, 29.2, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nfig.suptitle(\"Model Accuracy and FPR/FNR by Racial Group\", fontsize = 20)\nfig.text(0.5, 0.005, \"Racial Group (Abbreviated Category Names)\", ha = \"center\", va = \"center\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above uses the data frame constructed in the previous chunk to plot the overall model accuracy and FPR/FNR by racial group\nFigure 7\nThe plots above provide a visual accompaniment to the information displayed in Table 1. As shown in overall accuracy plot (left), the model’s accuracy for the majority of racial groups is actually higher than the general accuracy. The largest disparity in general accuracy to the accuracy for a specific racial group is found for individuals identifying as A.I./A.N. Tribe Specified \\(^1\\) and the difference in general accuracy to the accuracy of this racial group is \\(&lt;10\\%\\). While the differences are subtle, the racial groups with FPR and or FNR above the general FPR and FNR tend to have slightly lower-then-the-general-accuracy (as expected). Additionally, we can see that the FPR and FNR for most racial group hover close to or below the general FPR and FNR. This trend is clearly not observed for all racial groups though, and raises reasonable concerns about the model’s accuracy and error rates across the different racial groups.\n\n\nCode\nfig, ax = plt.subplots(1, 2, figsize = (20, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# TPR & TNR by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"TPR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[0])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"TNR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[0], edgecolor = \"black\")\nax[0].axhline(g_tpr * 100, color = \"purple\", linestyle = \"--\")\nax[0].axhline(g_tnr * 100, color = \"black\", linestyle = \"--\")\nax[0].set_ylim(60, 105)\nax[0].set_title(\"TPR & TNR\", fontsize = 16)\nax[0].set_xlabel(\"\")\nax[0].set_ylabel(\"TPR & TNR\", fontsize = 14)\nax[0].set_xticks(range(9))\nax[0].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[0].set_yticks(range(0, 110, 10)[6:])\nax[0].set_yticklabels([f\"{i}%\" for i in (range(0, 110, 10)[6:])], fontsize = 12)\nax[0].text(6.427, 102.5, f\"\\u2013 Overall Model TNR: {g_tnr * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(6.427, 102, f\"   Overall Model TPR: {g_tpr * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[0].text(5.17, 102, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[0].text(1.5, 102.5, f\"   : TNR\\n   : TPR\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(1.25, 103.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[0].text(1.25, 102.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\n# PPV & NPV by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"PPV\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[1])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"NPV\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[1], edgecolor = \"black\")\nax[1].axhline(g_npv * 100, color = \"purple\", linestyle = \"--\")\nax[1].axhline(g_ppv * 100, color = \"black\", linestyle = \"--\")\nax[1].set_ylim(60, 105)\nax[1].set_title(\"PPV & NPV\", fontsize = 16)\nax[1].set_xlabel(\"\")\nax[1].set_ylabel(\"PPV & NPV\", fontsize = 14)\nax[1].set_xticks(range(9))\nax[1].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[1].set_yticks(range(0, 110, 10)[6:])\nax[1].set_yticklabels([f\"{i}%\" for i in (range(0, 110, 10)[6:])], fontsize = 12)\nax[1].text(6.427, 102.5, f\"\\u2013 Overall Model PPV: {g_ppv * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(6.427, 102, f\"   Overall Model NPV: {g_npv * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[1].text(5.17, 102, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[1].text(1.5, 102.5, f\"   : NPV\\n   : PPV\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(1.25, 103.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[1].text(1.25, 102.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nfig.suptitle(\"Model Accuracy and Error Rates by Racial Group\", fontsize = 20)\nfig.text(0.5, 0.005, \"Racial Group (Abbreviated Category Names)\", ha = \"center\", va = \"center\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above uses the data frame constructed in the previous chunk to plot the and TPR/TNR and PPV/NPV by racial group\nFigure 8\nThe plots above provide additional visual accompaniment for the accuracy rates and predictive values displayed in Table 1. As shown in the plot of TPR/TNR for each racial group, most groups have a TPR and TNR hovering close to the general TPR and TNR. The biggest exception to this trend is the A.I./A.N. Tribe Specified \\(^1\\) group, which has a TPR that is significantly lower than the general TPR. The plot of PPV/NPV for each racial group shows that the PPV and NPV for most groups hover close the general PPV and NPV. For individuals identifying as A.I./A.N. Tribe Specified \\(^1\\) or Native Hawaiian & Other Pacific Islander, the NPV of these racial groups are considerably lower lower than the general NPV. The same follows for the PPV of black or African American individuals.\nBased on the information depicted in the Table 1 and the plots from Figure 7 and Figure 8, it is clear that the model’s accuracy and error rates are not entirely consistent across all racial groups. This inconsistency is particularly concerning for individuals identifying as A.I./A.N. Tribe Specified \\(^1\\), black or African American, or Native Hawaiian & Other Pacific Islander. That is, for individuals associating with these racial groups, it appears that the model is not as good at making accurate predictions of employment status as it is for predicting the employment status of other racial groups. This analysis suggests that the model may be perpetuating (through the cost of its misclassifications) systemic biases and past injustices that effect certain individuals differently on the bases of racial identity.\n\n\n\n\n\n\n\nCode\n# Examining the calibration of the model\n## Calculating the probability that a prediction is positive for each racial group\ncalibration = train.groupby(\"race\").aggregate({\"pred\": \"mean\"})\ncalibration[\"pred\"] = calibration[\"pred\"] * 100\ncalibration[\"pred_prob_diff\"] = np.abs(calibration[\"pred\"] - ((train[\"pred\"]).mean() * 100))\ncalibration[\"emp_status_rate\"] = train.groupby(\"race\").aggregate({\"emp_status\": \"mean\"}) * 100\n\n# Plotting these probabilities for each racial group\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(calibration, x = \"race\", y = \"pred\", hue = \"race\", palette = sns.color_palette()[:-1], ax = ax, legend = False)\nsns.barplot(calibration, x = \"race\", y = \"emp_status_rate\", hue = \"race\", palette = sns.color_palette()[:-1], ax = ax, legend = False, alpha = 0.5, edgecolor = \"black\")\nax.set_title(\"Model Calibration by Racial Group\", fontsize = 16)\nax.set_xlabel(\"Racial Group (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax.set_ylabel(\"Probability of Positive Prediction\", fontsize = 14)\nax.set_yticks([20 * i for i in range(6)])\nax.set_yticklabels([f\"{20 * i}%\" for i in range(6)], fontsize = 12)\nax.text(0, 95, f\"   : Prob. Pos. Outcome\\n   : Prob. Pos. Pred.\", ha = \"left\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax.text(0.075, 97, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax.text(0.075, 93.5, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above calculates the probability of the model predicting an individual to be employed for each racial group and plots these probabilities together.\nFigure 9\nAs shown in the calibration plot above, the model is generally well-calibrated for the majority of racial groups. The model’s predicted probabilities of employment are generally equal to the actual probability of employment irrespective of racial group in that for most groups. However, for some racial groups, such as A.I./A.N.Specified \\(^1\\) and Native Hawaiian & Other Pacific Islander, the probability of a positive prediction is notably different from the probability of employment for these groups respectively. This suggests that the model is well calibrated for most racial groups (for individuals identifying as white, black or African American, American Indian, Alaska Native, Asian, some other race, or two or more races), but not necessarily well-calibrated across all racial groups.\n\n\n\n\n\nCode\n# Comparing FPR and TPR across each racial group\nerb[[\"Racial Group (Abbr. Cats.)\", \"FPR\", \"TPR\"]]\n\n\n\n\n\n\n\n\n\nRacial Group (Abbr. Cats.)\nFPR\nTPR\n\n\n\n\n1\nWhite\n7.7 %\n92.1 %\n\n\n2\nAmerican Indian\n11.4 %\n93.5 %\n\n\n3\nBlack or African American\n3.2 %\n92.8 %\n\n\n4\nAlaska Native\nNA\n100.0 %\n\n\n5\nA.I./A.N. Tribe Specified¹\n0.0 %\n68.8 %\n\n\n6\nAsian\n6.0 %\n93.8 %\n\n\n7\nNative Hawaiian and Other Pacific Islander\n0.0 %\n90.9 %\n\n\n8\nSome Other Race\n2.9 %\n94.6 %\n\n\n9\nTwo or More Races\n4.5 %\n93.4 %\n\n\n\n\n\n\n\nTable 2\nThe table above revisits a subset of information presented in Table 1. As depicted in this table, the FPR for the majority of racial groups (white, black or African American, American Indian, Asian, some other race, two or more races) are generally similar values with the largest disparity being \\(&lt; 10\\%\\). The same general property can be observed in TPR across racial groups. However, while for a majority of racial groups, the FPR and TPR appear to be mostly balanced, this is certainly not the case for FPR anf TPR across all racial groups. E.G, the TPR for for individuals of the A.I./A.N. Tribe Specified \\(^1\\) group is significantly lower than for all other groups, suggesting that the model correctly predicts A.I./A.N. Tribe Specified \\(^1\\) as employed with less accuracy than for other groups. That is, this model does not strictly satisfy true error-rate balance.\n\n\n\n\n\nCode\n# Calculating the absolute difference of the probabilities of a positive prediction for each racial group to assess statistical parity\nspd = calibration[\"pred\"].max() - calibration[\"pred\"].min()\nprint(f\"Statistical Parity (ABS.) Difference: {spd: .2f}%\")\n\n# Calculating an adjusted SPD (excluding the group with a 100% positive prediction probability)\nspd_adj = calibration[calibration[\"pred\"] &lt; 100][\"pred\"].max() - calibration[calibration[\"pred\"] &lt; 100][\"pred\"].min()\nprint(f\"Adjusted Statistical Parity (ABS.) Difference: {spd_adj: .2f}%\")\n\n\nStatistical Parity (ABS.) Difference:  67.65%\nAdjusted Statistical Parity (ABS.) Difference:  23.20%\n\n\nTo assess statistical parity, the absolute difference between the maximum probability of a positive prediction and the minimum probability of a positive prediction across all racial groups is calculated. The model’s statistical parity difference for each racial group is roughly \\(23\\%\\). This metric lies above the generally accepted \\(5\\%\\) SPD threshold, indicating that the model likely exhibits biases in its predictions across racial groups and therefore does not satisfy statistical parity.\n\n\n\n\n\nCode\n# Defining FPR as linear function of FNR when PPV and P are held constant for white and black or African American individuals in the data\n## Calculating P for white and black or African American individuals in the data\np_w = train[train[\"race\"] == 1.0][\"emp_status\"].sum() / train[train[\"race\"] == 1.0].shape[0]\np_b = train[train[\"race\"] == 2.0][\"emp_status\"].sum() / train[train[\"race\"] == 2.0].shape[0]\n\n# Pulling PPV for white and black or African American individuals from Table 1\nppv_min = min((race_acc[\"PPV\"].iloc[0] / 100), (race_acc[\"PPV\"].iloc[2] / 100))\n\n# Storing the relevant information in a data frame\nfpr_by_fnr = pd.DataFrame(columns = [\"FNRW\", \"FPRW\", \"FNRB\", \"FPRB\"])\nfpr_by_fnr[\"FNRB\"] = np.linspace(0, 1, 100)\nfpr_by_fnr[\"FNRW\"] = np.linspace(0, 1, 100)\nfpr_by_fnr[\"FPRB\"] = (p_b / (1 - p_b)) * ((1 - ppv_min) / ppv_min) * (1 - fpr_by_fnr[\"FNRB\"])\nfpr_by_fnr[\"FPRW\"] = (p_w / (1 - p_w)) * ((1 - ppv_min) / ppv_min) * (1 - fpr_by_fnr[\"FNRW\"])\n\n# # Plotting the FPR as a linear function of FNR\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\nsns.lineplot(fpr_by_fnr, x = fpr_by_fnr[\"FNRW\"], y = fpr_by_fnr[\"FPRW\"], ax = ax, color = \"darkorange\", label = \"White Individuals\")\nsns.lineplot(fpr_by_fnr, x = fpr_by_fnr[\"FNRB\"], y = fpr_by_fnr[\"FPRB\"], ax = ax, color = \"darkgrey\", label = \"Black or African American Individuals\")\nax.scatter(race_acc[\"FNR\"].iloc[2] / 100, race_acc[\"FPR\"].iloc[2] / 100, color = \"darkgray\", s = 100)\nax.scatter(race_acc[\"FNR\"].iloc[0] / 100, race_acc[\"FPR\"].iloc[0] / 100, color = \"darkorange\", s = 100)\nax.set_title(\"Feasible (FNR, FPR) Combinations\", fontsize = 16)\nax.set_xlabel(\"False Negative Rate\", fontsize = 14)\nax.set_ylabel(\"False Positive Rate\", fontsize = 14)\nax.set_xticks([(.25 * i) for i in range(5)])\n\nplt.tight_layout()\n\nprint(race_acc[\"FNR\"].iloc[0])\n\n\n7.9\n\n\n\n\n\n\n\n\n\nCode above plots FPR as a function of FNR, PPV, and prevalence for individuals identifying as white and those identifying as black or African American.\nFigure 10\nThe plot above is a reproduction of Figure 5 from Chouldechova’s 2017 publication “Fair prediction with disparate impact: A study of bias in recidivism prediction instruments”. For white and black or African American individuals in the data, the plot displays the model’s FPR as a linear function of FNR when the prevalence \\(p\\) and PPV are held constant. Based on this figure, to tune the refined model to yield equal FPR values for white and black or African American individuals, the model’s FNR for white individuals would need to be increased by over 50 percentage points (increasing from about \\(8\\%\\) to about \\(62.5\\%\\)). This indicates that equalizing FPR values for white and black or African American individuals would require a significant decrease in the model’s accuracy for white individuals."
  },
  {
    "objectID": "posts/post_4/index.html#accessing-the-data",
    "href": "posts/post_4/index.html#accessing-the-data",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code\n# Includuing all additional imports\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom folktables import ACSDataSource, BasicProblem\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.pipeline import make_pipeline\nfrom matplotlib import pyplot as plt\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport itertools\n\n# Downloading ACS PUMS data for the state of Massachusetts - Code provided by Prof. Chodrow\nSTATE = \"MA\"\nds = ACSDataSource(survey_year = \"2018\", \n                            horizon = \"1-Year\", \n                            survey = \"person\")\nma = ds.get_data(states = [STATE], download = True)\n\n\nIncluding all additional imports\nThe data for this study comes from an ACS (American Community Survey) data set. Specifically, the data is from a 2018 PUMS (Public Use Microdata Sample) survey for the state of Massachusetts. Each observation from this data set is an individual massachusetts resident who completed the 2018 PUMS survey. The data is downloaded using the ACSDataSource class from the folktables package.\n\n\n\n\nCode\nvars = [\"AGEP\", \"SCHL\", \"MAR\", \"RELP\", \"DIS\", \"ESP\", \"CIT\", \"MIG\", \"MIL\", \"ANC\", \"NATIVITY\", \"DEAR\", \"DEYE\", \"DREM\", \"SEX\", \"RAC1P\", \"ESR\"]\n\n\nUntouched, the data contains nearly 300 different features. However, for this study, I will only be using a subset of the columns:\n\nAGEP: Age (Range 0 - 99)\nSCHL: Educational Attainment (Range 1 - 24)\nMAR: Marital Status (Range 1 - 5)\nRELP: Relationship to Householder (Range 1 - 17)\nDIS: Disability Present (Binary)\nESP: Employment Status of Parents (Range 1 - 8)\nCIT: Citizenship Status (Range 1 - 5)\nMIG: Mobility Status - Lived in Specified Location 1 Year Ago (Range 1 - 3)\nMIL: Military Service (Range 1 - 5)\nANC: Ancestry (Range 1 - 4, 8)\nNATIVITY: Nativity (Binary)\nDEAR: Hearing Difficulty (Binary)\nDEYE: Vision Difficulty (Binary)\nDREM: Cognitive Difficulty (Binary)\nSEX: Sex (Binary)\nRAC1P: Race (Range 1 - 9)\nESR: Employment Status (Range 1 - 6)\nPINCP: Total Person Income (Integer Range of Income in US Dollars: -19997 - 4209995)"
  },
  {
    "objectID": "posts/post_4/index.html#reproducing-figure-1",
    "href": "posts/post_4/index.html#reproducing-figure-1",
    "title": "Post 4 - Auditing Bias in Machine Learning Moedels",
    "section": "",
    "text": "Code Description\nFigure 1 (Reproduced)\nAnalysis of reproducing Figure 1."
  },
  {
    "objectID": "posts/post_4/index.html#reproducing-figure-3",
    "href": "posts/post_4/index.html#reproducing-figure-3",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code Description\nFigure 3 (Reproduced)\nAnalysis of reproducing Figure 3."
  },
  {
    "objectID": "posts/post_4/index.html#modeling-cost-disparity",
    "href": "posts/post_4/index.html#modeling-cost-disparity",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code Description\nAnalysis of data preparation.\n\n\n\nCode Description\nAnalysis of modeling."
  },
  {
    "objectID": "posts/post_4/index.html#model-1---predicting-employment-status",
    "href": "posts/post_4/index.html#model-1---predicting-employment-status",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code\n# Filtering out employment status (target) and race variables\nvars1 = [v for v in vars if v not in [\"ESR\", \"RAC1P\"]]\n\n# Defining the predictive modeling task - Code provided by Prof. Chodrow\nEmploymentProblem = BasicProblem(\n    features = vars1,\n    target = \"ESR\",\n    target_transform = lambda x: x == 1,\n    group = \"RAC1P\",\n    preprocess = lambda x: x,\n    postprocess = lambda x: np.nan_to_num(x, -1),\n)\nfeatures, label, group = EmploymentProblem.df_to_numpy(ma)\n\n# Test, train split procedure\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(features, label, group, test_size = 0.2, random_state = 69)\n\n\nCode above defines the predictive modeling task and constructs the training data for the employment prediction model.\nBefore constructing the first predictive model, the predictive modeling task is defined. Afterwards, a test-train-split procedure is conducted on the data to prepare it for model fitting.\n\n\n\n\n\nCode\n# Observing some general descriptives in the training data\ntrain = pd.DataFrame(X_train, columns = vars1)\ntrain[\"emp_status\"] = y_train.astype(int)\ntrain[\"race\"] = group_train\ntrain.dropna(inplace = True)\n\n# Total number of individuals in the training data\nn = train.shape[0]\n\n# Proportion of employed individuals in the training data\nemp_prop = train[\"emp_status\"].mean()\n\n# Proportion of employed individuals of each race\ntot_emp = (train[\"emp_status\"] == 1).sum()\nrace_prop_emp_tot = (train.groupby(\"race\")[\"emp_status\"].sum() / tot_emp) * 100\n\n# Proportion of employed individuals within each race\nrace_prop_emp = (train.groupby(\"race\")[\"emp_status\"].mean()) * 100\n\n# Plotting proportion of employed individuals (total)\n## Creating dataframe for plotting\nemp_prop_tot = pd.DataFrame({\n    \"emp\": ['Unemployed', 'Employed'],\n    \"prop\": [1 - emp_prop, emp_prop]\n})\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(emp_prop_tot, x = \"prop\", y = \"emp\", hue = \"prop\", palette = [\"#D8BFD8\", \"#5D3A6D\"], legend = False, width = 0.6, ax = ax)\nax.set_title(\"Overall Proportion of Employed Individuals\", fontsize = 16)\nax.set_yticks([0, 1])\nax.set_yticklabels([\"Unemployed\", \"Employed\"], fontsize = 12, rotation = 60)\nax.set_xlim(0.25, 0.55)\nax.set_xticks([i / 10 for i in range(3, 6)])\nax.set_xticklabels([f\"{i * 10}%\" for i in range(3, 6)], fontsize = 12)\nax.set_xlabel(\"Proportion to all Individuals\", fontsize = 14)\nax.set_ylabel(\"Employment Status\", fontsize = 14)\nax.text((1 - emp_prop) + 0.01, 0, f\"{round((1 - emp_prop) * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\", rotation = 60)\nax.text(emp_prop + 0.01, 1, f\"{round( emp_prop * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\", rotation = 60)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates three proportions of employed individuals in the data: 1. General proportion of employment across all individuals 2. Proportion of each race in all employed individuals 3. Proportion of employed individuals within each race.\nFigure 1\nPrior to constructing and fitting the predictive model, it’s useful to explore some general descriptives of the data. In total, there are 56104 individuals in the training data. Approximately \\(50\\%\\) of individuals from the data are employed (as of their filling out the survey in 2018).\n\n\nCode\n# Plotting proportion of employed individuals across each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nsns.countplot(train[train[\"emp_status\"] == 1], x = \"emp_status\", stat = \"proportion\", hue = \"race\", palette = sns.color_palette()[:-1], width = 0.9, dodge = True, ax = ax)\n\n# Adding space between bars\nfor patch in ax.patches:\n    patch.set_width(patch.get_width() * 0.8)\nax.set_yscale(\"log\", base = 10)\nax.legend(title = \"Race\", labels = [\"White\", \"Black or\\nAfrican American\", \"American Indian\", \"Alaska Native\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian &\\nOther Pacific Islander\", \"Other Race\", \"Two or more Races\"], ncol = 3, frameon = True, fontsize = 8, title_fontsize = 8)\nax.set_title(\"Proportion of Each Race Category in All Employed Individuals\", fontsize = 16)\nax.set_xticks([0])\nax.set_xticklabels([\"\"], fontsize = 12)\nax.set_xlabel(\"Employed Individuals\", fontsize = 14)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above plots the proportions calculated above\nFigure 2\nOf the employed individuals:\n\nAbout \\(83\\%\\) are white alone\nAbout \\(5.5\\%\\) are black or African American alone\nAbout \\(0.01\\%\\) are American Indian alone\nAbout \\(0.004\\%\\) are Alaska Native alone\n\\(^1\\) About \\(0.06\\%\\) are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races\nAbout \\(6.6\\%\\) are Asian alone\nAbout \\(0.039\\%\\) are Native Hawaiian and Other Pacific Islander alone\nAbout \\(2.87\\%\\) are some other race alone\nAbout \\(2.1\\%\\) are two or more races\n\n\n\nCode\n# Plotting proportion of employed individuals within each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nsns.countplot(train, x = \"race\", hue = \"emp_status\", stat = \"proportion\", palette = [\"#D8BFD8\", \"#5D3A6D\"], ax = ax)\nax.set_title(\"Proportion of Employed Individuals Within Each Race Category\", fontsize = 16)\nax.set_yscale(\"log\", base = 10)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\nax.legend(title = \"Employment Status\", labels = [\"Unemployed\", \"Employed\"], frameon = True, fontsize = 12, title_fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above plots the proportions calculated above\nFigure 3\nWithin each race, the proportions of employed individuals are:\n\nAbout \\(51.5\\%\\) of white alone individuals are employed\nAbout \\(46.1\\%\\) of black or African American alone individuals are employed\nAbout \\(47\\%\\) of American Indian alone individuals are employed\n\\(100\\%\\) of Alaska Native alone individuals are employed (there is a single Alaska Native alone individual in the data)\n\\(^1\\) About \\(47.1\\%\\) of individuals who are – with American Indian and Alaska Native tribes specified, or are American Indian or Alaska Native, or are not specified and are of no other races – are employed\nAbout \\(50.2\\%\\) of Asian alone individuals are employed\nAbout \\(61.1\\%\\) of Native Hawaiian and Other Pacific Islander alone individuals are employed\nAbout \\(47.3\\%\\) individuals of some other race alone are employed\nAbout \\(37.6\\%\\) of individuals of two or more races are employed\n\n\n\nCode\n# Examining the intersection of race and gender as it relates to employment\nemp = train[train[\"emp_status\"] == 1]\n\n# Array to store proportions of employed male and female individuals for each race\nixn_data = []\nfor race in emp[\"race\"].unique():\n    curr_race = emp[emp[\"race\"] == race]\n    m_emp_prop = curr_race[curr_race[\"SEX\"] == 1.0].shape[0] / emp.shape[0]\n    f_emp_prop = curr_race[curr_race[\"SEX\"] == 2.0].shape[0] / emp.shape[0]\n    ixn_data.append({\"Race\": race, \"Sex\": \"Male\", \"Emp_prop\": m_emp_prop})\n    ixn_data.append({\"Race\": race, \"Sex\": \"Female\", \"Emp_prop\": f_emp_prop})\nixn_data = pd.DataFrame(ixn_data)\nixn_data.head()\n\n# Barplot to display the intersection of race and gender in employment status\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(ixn_data, x = \"Race\", y = \"Emp_prop\", hue = \"Sex\", palette = [\"#FFDAB9\", \"darkorange\"], ax = ax)\nax.set_yscale(\"log\", base = 10)\nax.set_title(\"Proportion of Employed Individuals for Each Race Category by Sex\", fontsize = 16)\nax.set_ylabel(\"Proportion of Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(1, 5))], fontsize = 12)\nax.legend(frameon = True, fontsize = 12, title = \"Sex\", title_fontsize = 14)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates and plots the proportions of employment (of all employed individuals) for each race by sex.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nFigure 4\nThe figure above displays the possible intersectionality between race and sex among employed individuals. However, for none of the nine race categories found in this data set, does there appear to be a significant difference in employment rates between males and females. Therefore, based on this figure, there does not appear to be a significant intersectional effect of race and sex on employment rates. Please note that this finding does not dismiss the presence of intersectional biases and systemic injustices that may impact certain individuals from this data set. The existence of such intersectionality may very well be present in the data and but just not captured by this figure. Observing the intersectionality of race and gender relating to employment may be more clearly observed through other statistical processes.\n\n\nCode\n# Examining the intersection of race and disability as it relates to employment\n## Array to store proportions of employed visually impaired and non-visually impaired individuals for each race\nixn_data = []\nfor race in emp[\"race\"].unique():\n    curr_race = emp[emp[\"race\"] == race]\n    d_emp_prop = curr_race[curr_race[\"DIS\"] == 1.0].shape[0] / emp.shape[0]\n    nd_emp_prop = curr_race[curr_race[\"DIS\"] == 2.0].shape[0] / emp.shape[0]\n    ixn_data.append({\"Race\": race, \"Disability Present\": \"Yes\", \"Emp_prop\": d_emp_prop})\n    ixn_data.append({\"Race\": race, \"Disability Present\": \"No\", \"Emp_prop\": nd_emp_prop})\nixn_data = pd.DataFrame(ixn_data)\nixn_data.head()\n\n# Barplot to display the intersection of race and gender in employment status\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(ixn_data, x = \"Race\", y = \"Emp_prop\", hue = \"Disability Present\", palette = [\"lightgreen\", \"darkgreen\"], ax = ax)\nax.set_yscale(\"log\", base = 10)\nax.set_title(\"Proportion of Employed Individuals for Each Race Category by Presence of a Disability\", fontsize = 16)\nax.set_ylabel(\"Proportion of Employed Individuals ($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], \n                   fontsize = 12, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\nax.legend(frameon = True, fontsize = 12, title = \"Disability Present\", title_fontsize = 14)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode above calculates and plots the proportions of employment (of all employed individuals) for each race by disability presence.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nFigure 5\nThe figure above displays the possible intersectionality between race and disability among employed individuals. Unlike the apparent lack of intersectionality between race and sex, in all of the nine race categories found in this data set, there appears to be a significant difference in employment rates between individuals with and without disabilities present. Specifically, it seems that the lowest overall proportions of employed individuals are found at the combination of low-employment racial groups and when a disability is present. Thus, based on this figure, I believe that it is reasonable to identify an observable intersectional effect of race and disability on employment rates.\n\n\n\n\n\nCode\n# Constructing and fitting the model\nmodel = make_pipeline(StandardScaler(), DecisionTreeClassifier())\nmodel.fit(X_train, y_train)\n\n\nPipeline(steps=[('standardscaler', StandardScaler()),\n                ('decisiontreeclassifier', DecisionTreeClassifier())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('standardscaler', StandardScaler()),\n                ('decisiontreeclassifier', DecisionTreeClassifier())]) StandardScaler?Documentation for StandardScalerStandardScaler() DecisionTreeClassifier?Documentation for DecisionTreeClassifierDecisionTreeClassifier() \n\n\n\n\nCode\n# Refining the model\n## Identifying the optimal max_depth value - Model Complexity parameter for DecisionTreeCLassifier model - though iterative process\n# #Updated variables\nbest_max_depth = None\nbest_avg_score = 0\nfor md in np.random.randint(1, 1001, size = 10):\n    model.set_params(decisiontreeclassifier__max_depth = md)\n    avg_score = cross_val_score(model, X_train, y_train, cv = 5).mean()\n    if avg_score &gt; best_avg_score:\n        best_avg_score = avg_score\n        best_max_depth = md\n\n# Fitting the model with the optimal max_depth value\ndtc_refined = model.set_params(decisiontreeclassifier__max_depth = best_max_depth)\ndtc_refined.fit(X_train, y_train)\ngen_score = dtc_refined.score(X_train, y_train)\nprint(f\"Refined Model Overall Accuracy: {gen_score * 100: .3f}%\")\n\n\nRefined Model Overall Accuracy:  92.658%\n\n\nCode above uses the make_pipeline method from the sklearn package, the training data is first standardized and then used to fit a DecisionTreeClassifier model (also from sklearn). The max_depth parameter for the model is tuned iteratively with corss-validation to set the tree depth that maximizes overall accuracy while mitigating model over-fitting.\nTo refine the model, an iterative process tuning the model complexity (using the max_depth parameter) with cross-validation is conducted. This process aims at model maximizing trining accuracy while reducing the presence of model over-fitting. Following this tuning procedure, the model has an overall accuracy of approximately \\(92.658\\%\\) – as an initial metric, this indicates a considerable accurate model.\n\n\n\n\n\nCode\n# Calculating various accuracy metrics\n## Overall Training data accuracy\ny_preds_tr = dtc_refined.predict(X_train)\nacc_tr = (y_preds_tr == y_train).mean()\n\n# Confusion matrix for refined model\nC = confusion_matrix(y_train, y_preds_tr)\nemp_status = [\"Unemployed\", \"Employed\"]\n\n# Creating a heatmap for better confusion matrix visualization\nfig, ax = plt.subplots(1, 1, figsize = (5, 5))\nsns.heatmap(C, annot = True, annot_kws = {\"size\": 12}, fmt = \"d\", cmap = \"Reds\", cbar = False, ax = ax)\n\n# Plot styling\nax.set_xlabel(\"Predicted Employment Status\", fontsize = 14)\nax.set_ylabel(\"True Employment Status\", fontsize = 14)\nax.set_xticklabels(emp_status, fontsize = 12)\nax.set_yticklabels(emp_status, fontsize = 12)\nax.set_title(\"Employment Status Classification Confusion Matrix\", fontsize = 16)\n\nplt.show()\n\n# Printing confusion matrix results\nprint(f\"There were {C[0, 0]} unemployed individuals that were predicted to be unemployed.\")\nprint(f\"There were {C[0, 1]} unemployed individuals that were predicted to be employed.\")\nprint(f\"There were {C[1, 0]} employed individuals that were predicted to be unemployed.\")\nprint(f\"There were {C[1, 1]} unemployed individuals that were predicted to be employed.\")\n\n# Calculating various accuracies and error rates\ng_fnr = C[1, 0] / (C[1, 0] + C[1, 1])\ng_tnr = C[0, 0] / (C[0, 0] + C[0, 1])\ng_fpr = 1 - g_tnr\ng_tpr = 1 - g_fnr\ng_ppv = C[1, 1] / (C[1, 1] + C[0, 1])\ng_npv = C[0, 0] / (C[0, 0] + C[1, 0])\n\n\n\n\n\n\n\n\n\nThere were 25792 unemployed individuals that were predicted to be unemployed.\nThere were 1943 unemployed individuals that were predicted to be employed.\nThere were 2176 employed individuals that were predicted to be unemployed.\nThere were 26193 unemployed individuals that were predicted to be employed.\n\n\nCode above constructs the general confusion matrix for the refined model and calculates the typical accuracy/error rates: FPR, FNR, TPR, TNR, PPV, and NPV\nFigure 6\nSome key overall accuracy and error rates of the refined model are:\n\nFNR: About \\(~8\\%\\) of truly employed individuals were misclassified as unemployed.\nTNR: About \\(~93\\%\\) of truly unemployed individuals were correctly classified as unemployed.\nFPR: About \\(7\\%\\) of truly unemployed individuals were misclassified as employed.\nTPR: About \\(92\\%\\) of truly employed individuals were correctly classified as employed\nPPV: About \\(93\\%\\) of “employed” model predictions are correct while only about \\(7\\%\\) are incorrect.\nNPV: About \\(92\\%\\) of “unemployed” model predictions are correct while only about \\(8\\%\\) are incorrect.\n\nThe general accuracy and error rates outlines above indicate that the refined model is approximately equally accurate in predicting that truly unemployed individuals are unemployed and in predicting that truly employed individuals are employed. Additionally, the refined misclassifies truly unemployed individuals and truly employed individuals at nearly the same rate. The refined model yields a PPV and NPV that are nearly equal. This suggests that, for any given individual, the refined model is generally just as good at predicting if this individual is employed as it is at predicting if this individual is unemployed.\nWhile the overall accuracy of the refined model is appears considerably high, it is crucial to investigate the same accuracy rates across different groups of observations found in the data. In this context, the prediction task is to identify if an individual is employed or not. In the data, the race of each individual is provided, and not only is race undoubtedly related to employment in the US but race is also a factor by which systemic biases and systematic discrimination occurs in the American workforce. Although the model was not trained using this variable (race), there is no guarantee that the model does not rely on variables highly related to race or that could stand as proxies for race. Thus, it is critically important to examine if the model perpetuates systemic biases and past injustices effecting certain individuals differently on the bases of racial identity."
  },
  {
    "objectID": "posts/post_4/index.html#model-1---predicting-income-level",
    "href": "posts/post_4/index.html#model-1---predicting-income-level",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code\n# Filtering out employment status (target) and race variables\nvars1 = [v for v in vars if v not in [\"ESR\", \"RAC1P\"]]\n\n# Defining the predictive modeling task\nEmploymentProblem = BasicProblem(\n    features = vars1,\n    target = \"ESR\",\n    target_transform = lambda x: x == 1,\n    group = \"RAC1P\",\n    preprocess = lambda x: x,\n    postprocess = lambda x: np.nan_to_num(x, -1),\n)\nfeatures, label, group = EmploymentProblem.df_to_numpy(ma)\n\n# Test, train split procedure\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(features, label, group, test_size = 0.2, random_state = 69)\n\n\nCode above defines the predictive modeling task and constructs the training data for the employment prediction model.\nBefore constructing the first predictive model, the predictive modeling task is defined. Afterwards, a test-train-split procedure is conducted on the data to prepare it for model fitting.\n\n\n\n\n\nCode\n# Observing some general descriptives in the training data\ntrain = pd.DataFrame(X_train, columns = vars1)\ntrain[\"emp_status\"] = y_train.astype(int)\ntrain[\"race\"] = group_train\ntrain.dropna(inplace = True)\n\n# Total number of individuals in the training data\nn = train.shape[0]\n\n# Proportion of employed individuals in the training data\nemp_prop = train[\"emp_status\"].mean()\n\n# Proportion of employed individuals of each race\ntot_emp = (train[\"emp_status\"] == 1).sum()\nrace_prop_emp_tot = (train.groupby(\"race\")[\"emp_status\"].sum() / tot_emp) * 100\n\n# Proportion of employed individuals within each race\nrace_prop_emp = (train.groupby(\"race\")[\"emp_status\"].mean()) * 100\n\n# Plotting proportion of employed individuals (total)\nfig, ax = plt.subplots(1, 1, figsize = (5, 5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.countplot(train, x = \"emp_status\", stat = \"proportion\", hue = \"emp_status\", palette = [\"#D8BFD8\", \"#5D3A6D\"], legend = False, ax = ax)\nax.set_title(\"Overall Proportion of Employed Individuals\", fontsize = 16)\nax.set_xticks([0, 1])\nax.set_xticklabels([\"Unemployed\", \"Employed\"], fontsize = 12)\nax.set_ylim(0.25, 0.55)\nax.set_yticks([i / 10 for i in range(3, 6)])\nax.set_yticklabels([f\"{i * 10}%\" for i in range(3, 6)], fontsize = 12)\nax.set_ylabel(\"Proportion to all Individuals\", fontsize = 14)\nax.set_xlabel(\"Employment Status\", fontsize = 14)\nax.text(0, 0.505, f\"{round((1 - emp_prop) * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\")\nax.text(1, 0.515, f\"{round( emp_prop * 100, 2)}%\", ha = \"center\", va = \"center\", fontsize = 12, color = \"black\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nPrior to constructing and fitting the predictive model, it’s useful to explore some general descriptives of the data. In total, there are 56104 individuals in the training data. Approximately \\(50\\%\\) of individuals from the data are employed (as of their filling out the survey in 2018).\n\n\nCode\n# Plotting proportion of employed individuals across each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 5))\nsns.countplot(train[train[\"emp_status\"] == 1], x = \"emp_status\", stat = \"proportion\", hue = \"race\", palette = sns.color_palette()[:-1], width = 0.9, dodge = True, ax = ax)\nfor patch in ax.patches:\n    patch.set_width(patch.get_width() * 0.8)\nax.set_yscale(\"log\", base = 10)\nax.legend(title = \"Race$^1$\", ncol = 3, frameon = True, fontsize = 8, title_fontsize = 8)\nax.set_title(\"Proportion of Employed Individuals\\nAcross Each Race Category\", fontsize = 16)\nax.set_xticks([0])\nax.set_xticklabels([\"\"], fontsize = 12)\nax.set_xlabel(\"Employed Individuals\", fontsize = 14)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nOf the employed individuals:\n\nAbout \\(83\\%\\) are white alone\nAbout \\(5.5\\%\\) are black or African American alone\nAbout \\(0.01\\%\\) are American Indian alone\nAbout \\(0.004\\%\\) are Alaska Native alone\nAbout \\(0.06\\%\\) are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and no other races\nAbout \\(6.6\\%\\) are Asian alone\nAbout \\(0.039\\%\\) are Native Hawaiian and Other Pacific Islander alone\nAbout \\(2.87\\%\\) are some other race alone\nAbout \\(2.1\\%\\) are two or more races\n\n\n\nCode\n# Plotting proportion of employed individuals within each race\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 5))\nsns.countplot(train, x = \"race\", hue = \"emp_status\", stat = \"proportion\", palette = [\"#D8BFD8\", \"#5D3A6D\"], ax = ax)\nax.set_title(\"Proportion of Employed Individuals\\nWithin Each Race Category\", fontsize = 16)\nax.set_yscale(\"log\", base = 10)\nax.set_ylabel(\"Proportion to Employed Individuals\\n($log_{10}$ scale)\", fontsize = 14)\nax.set_xlabel(\"Race (Abbreviated Category Names)\", fontsize = 12)\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or\\nAfrican American\", \"American Indian\", \"Alaska Native\", \"A.I./A.N.\\nTribe Specified$^*$\", \"Asian\", \"Native Hawaiian and\\nOther Pacific Islander\", \"Other Race\", \"Two or more Races\"], \n                   fontsize = 10, rotation = 15)\nax.set_yticks([10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1.0])\nax.set_yticklabels([f\"{(10 ** -i) * 100}%\" for i in reversed(range(5))], fontsize = 12)\nax.legend(title = \"Employment Status\", labels = [\"Unemployed\", \"Employed\"], frameon = True, fontsize = 8, title_fontsize = 8)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThe proportions of employed individuals within each race are:\n\nAbout \\(51.5\\%\\) of white alone individuals are employed\nAbout \\(46.1\\%\\) of black or African American alone individuals are employed\nAbout \\(47\\%\\) of American Indian alone individuals are employed\n\\(100\\%\\) of Alaska Native alone individuals are employed (there is a single Alaska Native alone individual in the data)\nAbout \\(47.1\\%\\) of individuals who are – with American Indian and Alaska Native tribes specified, or are American Indian or Alaska Native, or are not specified and are of no other races – are employed\nAbout \\(50.2\\%\\) of Asian alone individuals are employed\nAbout \\(61.1\\%\\) of Native Hawaiian and Other Pacific Islander alone individuals are employed\nAbout \\(47.3\\%\\) individuals of some other race alone are employed\nAbout \\(37.6\\%\\) of individuals of two or more races are employed\n\n\n\nCode\n# Examining the intersection of race and gender as it relates to employment\nemp = train[train[\"emp_status\"] == 1]\n\n## Array to store proportions of employed male and female individuals for each race\nixn_data = []\nfor race in emp[\"race\"].unique():\n    curr_race = emp[emp[\"race\"] == race]\n    m_emp_prop = curr_race[curr_race[\"SEX\"] == 1.0].shape[0] / emp.shape[0]\n    f_emp_prop = curr_race[curr_race[\"SEX\"] == 2.0].shape[0] / emp.shape[0]\n    ixn_data.append({\"Race\": race, \"Sex\": \"Male\", \"Emp_prop\": m_emp_prop})\n    ixn_data.append({\"Race\": race, \"Sex\": \"Female\", \"Emp_prop\": f_emp_prop})\nixn_data = pd.DataFrame(ixn_data)\nixn_data.head()\n\n# Barplot to display the intersection of race and gender in employment status\nfig, ax = plt.subplots(1, 1, figsize = (10, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(ixn_data, x = \"Race\", y = \"Emp_prop\", hue = \"Sex\", palette = [\"#D8BFD8\", \"#5D3A6D\"], ax = ax)\nax.set_yscale(\"log\", base = 10)\nax.set_ylabel(\"Proportion of Employed Individuals ($log_{10}$ scale)\")\nax.set_xlabel(\"Race (Abbreviated Category Names)\")\nax.set_xticks(range(0, 9))\nax.set_xticklabels([\"White\", \"Black or African American\", \"American Indian\", \"Alaska Native\", \"A.I./A.N.\\nTribe Specified$^*$\", \"Asian\", \"Native Hawaiian and\\nOther Pacific Islander\", \"Other Race\", \"Two or more Races\"], \n                   fontsize = 10, rotation = 15)\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Constructing and fitting the model\n# model = make_pipeline(StandardScaler(), SVC())\n# model.fit(X_train, y_train)\n\n\nCode above uses the make_pipeline method from the sklearn package, the training data is first standardized and then used to fit a LogisticRegression model (also from sklearn)."
  },
  {
    "objectID": "posts/post_4/index.html#auditing-the-model-for-racial-bias",
    "href": "posts/post_4/index.html#auditing-the-model-for-racial-bias",
    "title": "Post 4 - Auditing Bias in Machine Learning Models",
    "section": "",
    "text": "Code\n# Adding a column for indicating correct predictions\ntrain[\"pred\"] = y_preds_tr\ntrain[\"correct_pred\"] = (y_preds_tr == y_train).astype(int)\n\n# Recoding race variable for easier visualization\nrace_recode = {\n    1.0: \"White\",\n    2.0: \"Black or African American\",\n    3.0: \"American Indian\",\n    4.0: \"Alaska Native\",\n    5.0: f\"A.I./A.N. Tribe Specified\\u00B9\",\n    6.0: \"Asian\",\n    7.0: \" Native Hawaiian and Other Pacific Islander\",\n    8.0: \"Some Other Race\",\n    9.0: \" Two or More Races\"\n}\ntrain[\"Racial Group (Abbreviated Categories)\"] = train[\"race\"].map(race_recode)\n\n# Helper functions to calculate various accuracy and error rate metrics\ndef acc(x):\n    return str(round(x[\"correct_pred\"].mean() * 100, 1)) + \" %\"\n\ndef prop(x):\n    return str(round((x.shape[0] / train.shape[0]) * 100, 1)) + \" %\"\n\ndef fpr(x):\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    if ((fp + tn) == 0):\n        return \"NA\"\n    fpr = fp / (fp + tn)\n    \n    return str(round(fpr * 100, 1)) + \" %\"\n\ndef fnr(x):\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    if ((fn + tp) == 0):\n        return \"NA\"\n    fnr = fn / (fn + tp)\n\n    return str(round(fnr * 100, 1)) + \" %\"\n\ndef tpr(x):\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    if ((fn + tp) == 0):\n        return \"NA\"\n    tpr = tp / (fn + tp)\n\n    return str(round(tpr * 100, 1)) + \" %\"\n\ndef tnr(x):\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    if ((fp + tn) == 0):\n        return \"NA\"\n    tnr = tn / (fp + tn)\n    \n    return str(round(tnr * 100, 1)) + \" %\"\n\ndef ppv(x):\n    tp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 1)).sum()\n    fp = ((x[\"pred\"] == 1) & (x[\"emp_status\"] == 0)).sum()\n    if ((tp + fp) == 0):\n        return \"NA\"\n    ppv = tp / (tp + fp)\n    \n    return str(round(ppv * 100, 1)) + \" %\"\n\ndef npv(x):\n    tn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 0)).sum()\n    fn = ((x[\"pred\"] == 0) & (x[\"emp_status\"] == 1)).sum()\n    if ((tn + fn) == 0):\n        return \"NA\"\n    npv = tn / (tn + fn)\n\n    return str(round(npv * 100, 1)) + \" %\"\n\n# Initializing data frame to visualize model accuracy and error rates for each race\nrace_acc = pd.DataFrame(index = range(1, 10), columns = [\"Racial Group (Abbr. Cats.)\", \"Model Accuracy\", \"Proportion to Tot. (Aprx.)\", \"FPR\", \"FNR\", \"TPR\", \"TNR\", \"PPV\", \"NPV\"])\n\n# Subsetting training data into each race category\nr1 = train[train[\"race\"] == 1.0]\nr2 = train[train[\"race\"] == 2.0]\nr3 = train[train[\"race\"] == 3.0]\nr4 = train[train[\"race\"] == 4.0]\nr5 = train[train[\"race\"] == 5.0]\nr6 = train[train[\"race\"] == 6.0]\nr7 = train[train[\"race\"] == 7.0]\nr8 = train[train[\"race\"] == 8.0]\nr9 = train[train[\"race\"] == 9.0]\n\n# Populating the accuracy/error rates table\nrace_acc.loc[1] = [race_recode.get(1.0), acc(r1), prop(r1), fpr(r1), fnr(r1), tpr(r1), tnr(r1), ppv(r1), npv(r1)]\nrace_acc.loc[3] = [race_recode.get(2.0), acc(r2), prop(r2), fpr(r2), fnr(r2), tpr(r2), tnr(r2), ppv(r2), npv(r2)]\nrace_acc.loc[2] = [race_recode.get(3.0), acc(r3), prop(r3), fpr(r3), fnr(r3), tpr(r3), tnr(r3), ppv(r3), npv(r3)]\nrace_acc.loc[4] = [race_recode.get(4.0), acc(r4), prop(r4), fpr(r4), fnr(r4), tpr(r4), tnr(r4), ppv(r4), npv(r4)]\nrace_acc.loc[5] = [race_recode.get(5.0), acc(r5), prop(r5), fpr(r5), fnr(r5), tpr(r5), tnr(r5), ppv(r5), npv(r5)]\nrace_acc.loc[6] = [race_recode.get(6.0), acc(r6), prop(r6), fpr(r6), fnr(r6), tpr(r6), tnr(r6), ppv(r6), npv(r6)]\nrace_acc.loc[7] = [race_recode.get(7.0), acc(r7), prop(r7), fpr(r7), fnr(r7), tpr(r7), tnr(r7), ppv(r7), npv(r7)]\nrace_acc.loc[8] = [race_recode.get(8.0), acc(r8), prop(r8), fpr(r8), fnr(r8), tpr(r8), tnr(r8), ppv(r8), npv(r8)]\nrace_acc.loc[9] = [race_recode.get(9.0), acc(r9), prop(r9), fpr(r9), fnr(r9), tpr(r9), tnr(r9), ppv(r9), npv(r9)]\nrace_acc\n\n\n\n\n\n\n\n\n\nRacial Group (Abbr. Cats.)\nModel Accuracy\nProportion to Tot. (Aprx.)\nFPR\nFNR\nTPR\nTNR\nPPV\nNPV\n\n\n\n\n1\nWhite\n92.2 %\n81.3 %\n7.7 %\n7.9 %\n92.1 %\n92.3 %\n92.7 %\n91.7 %\n\n\n2\nAmerican Indian\n90.9 %\n0.1 %\n11.4 %\n6.5 %\n93.5 %\n88.6 %\n87.9 %\n93.9 %\n\n\n3\nBlack or African American\n94.9 %\n6.0 %\n3.2 %\n7.2 %\n92.8 %\n96.8 %\n96.1 %\n94.0 %\n\n\n4\nAlaska Native\n100.0 %\n0.0 %\nNA\n0.0 %\n100.0 %\nNA\n100.0 %\nNA\n\n\n5\nA.I./A.N. Tribe Specified¹\n85.3 %\n0.1 %\n0.0 %\n31.2 %\n68.8 %\n100.0 %\n100.0 %\n78.3 %\n\n\n6\nAsian\n93.9 %\n6.7 %\n6.0 %\n6.2 %\n93.8 %\n94.0 %\n94.0 %\n93.7 %\n\n\n7\nNative Hawaiian and Other Pacific Islander\n94.4 %\n0.0 %\n0.0 %\n9.1 %\n90.9 %\n100.0 %\n100.0 %\n87.5 %\n\n\n8\nSome Other Race\n95.9 %\n3.1 %\n2.9 %\n5.4 %\n94.6 %\n97.1 %\n96.7 %\n95.2 %\n\n\n9\nTwo or More Races\n94.7 %\n2.8 %\n4.5 %\n6.6 %\n93.4 %\n95.5 %\n92.6 %\n96.0 %\n\n\n\n\n\n\n\nCode above subsets the training data into each race category and creates a table displaying the model’s accuracy and error rates in employment/unemployment predictions for each racial group.\n\\(^1\\)“A.I./A.N.Specified”: Individuals who are American Indian and Alaska Native tribes specified, or American Indian or Alaska Native, or not specified and of no other races.\nTable 1\nThe table above depicts the refined model’s accuracy and error rates for employment prediction of individuals across each racial group in the training data. The general accuracies for each racial group are all largely similar – with values ranging from around \\(82\\%\\) to \\(90\\%\\) accuracy. The FPR and FNR for each race are slightly less equal across all racial groups (FPR range from roughly \\(0\\%\\) to \\(11\\%\\) and FNR range from \\(0\\%\\) to \\(10\\%\\)), but these error rates do not differ dramatically (with the exception of the “American Indian and Alaska Native tribes specified” group with a FNR: \\(31.2\\%\\)). The same trend is generally observable for TPR and TNR across each racial group (TPR range from about \\(90\\%\\) to \\(100\\%\\) and TNR range from about \\(88\\%\\) to \\(100\\%\\)) - (with the exception of the “American Indian and Alaska Native tribes specified” group with a TPR: \\(68.8\\%\\)). Further, the PPV and NPV for each racial group are also approximately equal – with PPV values ranging from approximately \\(88\\%\\) to \\(100\\%\\) and NPV values ranging from approximately \\(80\\%\\) to \\(96\\%\\).\n\n\nCode\n# Changing column types for easier visualization\n## Saving a data frame for late use\nerb = race_acc.copy()\nfor col in race_acc.columns[1:]:\n    if (race_acc[col].dtype == \"object\"):\n        race_acc[col] = pd.to_numeric(race_acc[col].str.replace(\"%\", \"\").replace(\"NA\", np.nan))\n\n# Plotting the information described in the table above for easier visualization\nfig, ax = plt.subplots(1, 2, figsize = (20, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Accuracy by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"Model Accuracy\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[0])\nax[0].axhline(gen_score * 100, color = \"black\", linestyle = \"--\")\nax[0].set_ylim(40, 104)\nax[0].set_title(\"Model Accuracy\", fontsize = 16)\nax[0].set_xlabel(\"\")\nax[0].set_ylabel(\"Model Accuracy\", fontsize = 14)\nax[0].set_xticks(range(9))\nax[0].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[0].set_yticks([(20 * i) for i in range(3, 6)])\nax[0].set_yticklabels([f\"{20 * i}%\" for i in range(3, 6)], fontsize = 12)\nax[0].text(6.15, 99.5, f\"\\u2013 Overall Model Accuracy: {gen_score * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\n\n# FPR & FNR by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"FPR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[1])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"FNR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[1], edgecolor = \"black\")\nax[1].axhline(g_fpr * 100, color = \"purple\", linestyle = \"--\")\nax[1].axhline(g_fnr * 100, color = \"black\", linestyle = \"--\")\nax[1].set_title(\"FPR & FNR\", fontsize = 16)\nax[1].set_xlabel(\"\")\nax[1].set_ylabel(\"FPR & FNR\", fontsize = 14)\nax[1].set_xticks(range(9))\nax[1].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[1].set_yticks([i for i in range(0, 35, 5)])\nax[1].set_yticklabels([f\"{i}%\" for i in range(0, 35, 5)], fontsize = 12)\nax[1].text(6.5, 29.5, f\"\\u2013 Overall Model FNR: {g_fnr * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(6.5, 29, f\"   Overall Model FPR: {g_fpr * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[1].text(5.3, 29, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[1].text(1.5, 29.5, f\"   : FNR\\n   : FPR\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(1.25, 29.9, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[1].text(1.25, 29.2, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nfig.suptitle(\"Model Accuracy and FPR/FNR by Racial Group\", fontsize = 20)\nfig.text(0.5, 0.005, \"Racial Group (Abbreviated Category Names)\", ha = \"center\", va = \"center\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above uses the data frame constructed in the previous chunk to plot the overall model accuracy and FPR/FNR by racial group\nFigure 7\nThe plots above provide a visual accompaniment to the information displayed in Table 1. As shown in overall accuracy plot (left), the model’s accuracy for the majority of racial groups is actually higher than the general accuracy. The largest disparity in general accuracy to the accuracy for a specific racial group is found for individuals identifying as A.I./A.N. Tribe Specified \\(^1\\) and the difference in general accuracy to the accuracy of this racial group is \\(&lt;10\\%\\). While the differences are subtle, the racial groups with FPR and or FNR above the general FPR and FNR tend to have slightly lower-then-the-general-accuracy (as expected). Additionally, we can see that the FPR and FNR for most racial group hover close to or below the general FPR and FNR. This trend is clearly not observed for all racial groups though, and raises reasonable concerns about the model’s accuracy and error rates across the different racial groups.\n\n\nCode\nfig, ax = plt.subplots(1, 2, figsize = (20, 10))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# TPR & TNR by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"TPR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[0])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"TNR\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[0], edgecolor = \"black\")\nax[0].axhline(g_tpr * 100, color = \"purple\", linestyle = \"--\")\nax[0].axhline(g_tnr * 100, color = \"black\", linestyle = \"--\")\nax[0].set_ylim(60, 105)\nax[0].set_title(\"TPR & TNR\", fontsize = 16)\nax[0].set_xlabel(\"\")\nax[0].set_ylabel(\"TPR & TNR\", fontsize = 14)\nax[0].set_xticks(range(9))\nax[0].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[0].set_yticks(range(0, 110, 10)[6:])\nax[0].set_yticklabels([f\"{i}%\" for i in (range(0, 110, 10)[6:])], fontsize = 12)\nax[0].text(6.427, 102.5, f\"\\u2013 Overall Model TNR: {g_tnr * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(6.427, 102, f\"   Overall Model TPR: {g_tpr * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[0].text(5.17, 102, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[0].text(1.5, 102.5, f\"   : TNR\\n   : TPR\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[0].text(1.25, 103.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[0].text(1.25, 102.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\n# PPV & NPV by Race\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"PPV\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], ax = ax[1])\nsns.barplot(race_acc, x = \"Racial Group (Abbr. Cats.)\", y = \"NPV\", hue = \"Racial Group (Abbr. Cats.)\", palette = sns.color_palette()[:-1], alpha = 0.5, ax = ax[1], edgecolor = \"black\")\nax[1].axhline(g_npv * 100, color = \"purple\", linestyle = \"--\")\nax[1].axhline(g_ppv * 100, color = \"black\", linestyle = \"--\")\nax[1].set_ylim(60, 105)\nax[1].set_title(\"PPV & NPV\", fontsize = 16)\nax[1].set_xlabel(\"\")\nax[1].set_ylabel(\"PPV & NPV\", fontsize = 14)\nax[1].set_xticks(range(9))\nax[1].set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax[1].set_yticks(range(0, 110, 10)[6:])\nax[1].set_yticklabels([f\"{i}%\" for i in (range(0, 110, 10)[6:])], fontsize = 12)\nax[1].text(6.427, 102.5, f\"\\u2013 Overall Model PPV: {g_ppv * 100: .2f}%\\n\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(6.427, 102, f\"   Overall Model NPV: {g_npv * 100: .2f}%\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\")\nax[1].text(5.17, 102, \"\\u2013\", ha = \"center\", va = \"center\", fontsize = 14, color = \"purple\")\nax[1].text(1.5, 102.5, f\"   : NPV\\n   : PPV\", ha = \"center\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax[1].text(1.25, 103.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax[1].text(1.25, 102.1, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nfig.suptitle(\"Model Accuracy and Error Rates by Racial Group\", fontsize = 20)\nfig.text(0.5, 0.005, \"Racial Group (Abbreviated Category Names)\", ha = \"center\", va = \"center\", fontsize = 18)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above uses the data frame constructed in the previous chunk to plot the and TPR/TNR and PPV/NPV by racial group\nFigure 8\nThe plots above provide additional visual accompaniment for the accuracy rates and predictive values displayed in Table 1. As shown in the plot of TPR/TNR for each racial group, most groups have a TPR and TNR hovering close to the general TPR and TNR. The biggest exception to this trend is the A.I./A.N. Tribe Specified \\(^1\\) group, which has a TPR that is significantly lower than the general TPR. The plot of PPV/NPV for each racial group shows that the PPV and NPV for most groups hover close the general PPV and NPV. For individuals identifying as A.I./A.N. Tribe Specified \\(^1\\) or Native Hawaiian & Other Pacific Islander, the NPV of these racial groups are considerably lower lower than the general NPV. The same follows for the PPV of black or African American individuals.\nBased on the information depicted in the Table 1 and the plots from Figure 7 and Figure 8, it is clear that the model’s accuracy and error rates are not entirely consistent across all racial groups. This inconsistency is particularly concerning for individuals identifying as A.I./A.N. Tribe Specified \\(^1\\), black or African American, or Native Hawaiian & Other Pacific Islander. That is, for individuals associating with these racial groups, it appears that the model is not as good at making accurate predictions of employment status as it is for predicting the employment status of other racial groups. This analysis suggests that the model may be perpetuating (through the cost of its misclassifications) systemic biases and past injustices that effect certain individuals differently on the bases of racial identity.\n\n\n\n\n\n\n\nCode\n# Examining the calibration of the model\n## Calculating the probability that a prediction is positive for each racial group\ncalibration = train.groupby(\"race\").aggregate({\"pred\": \"mean\"})\ncalibration[\"pred\"] = calibration[\"pred\"] * 100\ncalibration[\"pred_prob_diff\"] = np.abs(calibration[\"pred\"] - ((train[\"pred\"]).mean() * 100))\ncalibration[\"emp_status_rate\"] = train.groupby(\"race\").aggregate({\"emp_status\": \"mean\"}) * 100\n\n# Plotting these probabilities for each racial group\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nsns.barplot(calibration, x = \"race\", y = \"pred\", hue = \"race\", palette = sns.color_palette()[:-1], ax = ax, legend = False)\nsns.barplot(calibration, x = \"race\", y = \"emp_status_rate\", hue = \"race\", palette = sns.color_palette()[:-1], ax = ax, legend = False, alpha = 0.5, edgecolor = \"black\")\nax.set_title(\"Model Calibration by Racial Group\", fontsize = 16)\nax.set_xlabel(\"Racial Group (Abbreviated Category Names)\", fontsize = 14)\nax.set_xticks(range(9))\nax.set_xticklabels([\"White\", \"Black or African\\nAmerican\", \"American\\nIndian\", \"Alaska\\nNative\", \"A.I./A.N.\\nTribe Specified$^1$\", \"Asian\", \"Native Hawaiian\\n& Other Pacific\\nIslander\", \"Other\\nRace\", \"Two or more\\nRaces\"], fontsize = 12, rotation = 15)\nax.set_ylabel(\"Probability of Positive Prediction\", fontsize = 14)\nax.set_yticks([20 * i for i in range(6)])\nax.set_yticklabels([f\"{20 * i}%\" for i in range(6)], fontsize = 12)\nax.text(0, 95, f\"   : Prob. Pos. Outcome\\n   : Prob. Pos. Pred.\", ha = \"left\", va = \"center\", fontsize = 14, color = \"black\", bbox = dict(facecolor = \"white\", alpha = 0.75, edgecolor = \"gray\", boxstyle = \"round,pad=0.3\"))\nax.text(0.075, 97, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\", alpha = 0.5)\nax.text(0.075, 93.5, \"\\u25A0\", ha = \"center\", va = \"center\", fontsize = 16, color = \"red\")\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nCode above calculates the probability of the model predicting an individual to be employed for each racial group and plots these probabilities together.\nFigure 9\nAs shown in the calibration plot above, the model is generally well-calibrated for the majority of racial groups. The model’s predicted probabilities of employment are generally equal to the actual probability of employment irrespective of racial group in that for most groups. However, for some racial groups, such as A.I./A.N.Specified \\(^1\\) and Native Hawaiian & Other Pacific Islander, the probability of a positive prediction is notably different from the probability of employment for these groups respectively. This suggests that the model is well calibrated for most racial groups (for individuals identifying as white, black or African American, American Indian, Alaska Native, Asian, some other race, or two or more races), but not necessarily well-calibrated across all racial groups.\n\n\n\n\n\nCode\n# Comparing FPR and TPR across each racial group\nerb[[\"Racial Group (Abbr. Cats.)\", \"FPR\", \"TPR\"]]\n\n\n\n\n\n\n\n\n\nRacial Group (Abbr. Cats.)\nFPR\nTPR\n\n\n\n\n1\nWhite\n7.7 %\n92.1 %\n\n\n2\nAmerican Indian\n11.4 %\n93.5 %\n\n\n3\nBlack or African American\n3.2 %\n92.8 %\n\n\n4\nAlaska Native\nNA\n100.0 %\n\n\n5\nA.I./A.N. Tribe Specified¹\n0.0 %\n68.8 %\n\n\n6\nAsian\n6.0 %\n93.8 %\n\n\n7\nNative Hawaiian and Other Pacific Islander\n0.0 %\n90.9 %\n\n\n8\nSome Other Race\n2.9 %\n94.6 %\n\n\n9\nTwo or More Races\n4.5 %\n93.4 %\n\n\n\n\n\n\n\nTable 2\nThe table above revisits a subset of information presented in Table 1. As depicted in this table, the FPR for the majority of racial groups (white, black or African American, American Indian, Asian, some other race, two or more races) are generally similar values with the largest disparity being \\(&lt; 10\\%\\). The same general property can be observed in TPR across racial groups. However, while for a majority of racial groups, the FPR and TPR appear to be mostly balanced, this is certainly not the case for FPR anf TPR across all racial groups. E.G, the TPR for for individuals of the A.I./A.N. Tribe Specified \\(^1\\) group is significantly lower than for all other groups, suggesting that the model correctly predicts A.I./A.N. Tribe Specified \\(^1\\) as employed with less accuracy than for other groups. That is, this model does not strictly satisfy true error-rate balance.\n\n\n\n\n\nCode\n# Calculating the absolute difference of the probabilities of a positive prediction for each racial group to assess statistical parity\nspd = calibration[\"pred\"].max() - calibration[\"pred\"].min()\nprint(f\"Statistical Parity (ABS.) Difference: {spd: .2f}%\")\n\n# Calculating an adjusted SPD (excluding the group with a 100% positive prediction probability)\nspd_adj = calibration[calibration[\"pred\"] &lt; 100][\"pred\"].max() - calibration[calibration[\"pred\"] &lt; 100][\"pred\"].min()\nprint(f\"Adjusted Statistical Parity (ABS.) Difference: {spd_adj: .2f}%\")\n\n\nStatistical Parity (ABS.) Difference:  67.65%\nAdjusted Statistical Parity (ABS.) Difference:  23.20%\n\n\nTo assess statistical parity, the absolute difference between the maximum probability of a positive prediction and the minimum probability of a positive prediction across all racial groups is calculated. The model’s statistical parity difference for each racial group is roughly \\(23\\%\\). This metric lies above the generally accepted \\(5\\%\\) SPD threshold, indicating that the model likely exhibits biases in its predictions across racial groups and therefore does not satisfy statistical parity.\n\n\n\n\n\nCode\n# Defining FPR as linear function of FNR when PPV and P are held constant for white and black or African American individuals in the data\n## Calculating P for white and black or African American individuals in the data\np_w = train[train[\"race\"] == 1.0][\"emp_status\"].sum() / train[train[\"race\"] == 1.0].shape[0]\np_b = train[train[\"race\"] == 2.0][\"emp_status\"].sum() / train[train[\"race\"] == 2.0].shape[0]\n\n# Pulling PPV for white and black or African American individuals from Table 1\nppv_min = min((race_acc[\"PPV\"].iloc[0] / 100), (race_acc[\"PPV\"].iloc[2] / 100))\n\n# Storing the relevant information in a data frame\nfpr_by_fnr = pd.DataFrame(columns = [\"FNRW\", \"FPRW\", \"FNRB\", \"FPRB\"])\nfpr_by_fnr[\"FNRB\"] = np.linspace(0, 1, 100)\nfpr_by_fnr[\"FNRW\"] = np.linspace(0, 1, 100)\nfpr_by_fnr[\"FPRB\"] = (p_b / (1 - p_b)) * ((1 - ppv_min) / ppv_min) * (1 - fpr_by_fnr[\"FNRB\"])\nfpr_by_fnr[\"FPRW\"] = (p_w / (1 - p_w)) * ((1 - ppv_min) / ppv_min) * (1 - fpr_by_fnr[\"FNRW\"])\n\n# # Plotting the FPR as a linear function of FNR\nfig, ax = plt.subplots(1, 1, figsize = (12.5, 7.5))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\nsns.lineplot(fpr_by_fnr, x = fpr_by_fnr[\"FNRW\"], y = fpr_by_fnr[\"FPRW\"], ax = ax, color = \"darkorange\", label = \"White Individuals\")\nsns.lineplot(fpr_by_fnr, x = fpr_by_fnr[\"FNRB\"], y = fpr_by_fnr[\"FPRB\"], ax = ax, color = \"darkgrey\", label = \"Black or African American Individuals\")\nax.scatter(race_acc[\"FNR\"].iloc[2] / 100, race_acc[\"FPR\"].iloc[2] / 100, color = \"darkgray\", s = 100)\nax.scatter(race_acc[\"FNR\"].iloc[0] / 100, race_acc[\"FPR\"].iloc[0] / 100, color = \"darkorange\", s = 100)\nax.set_title(\"Feasible (FNR, FPR) Combinations\", fontsize = 16)\nax.set_xlabel(\"False Negative Rate\", fontsize = 14)\nax.set_ylabel(\"False Positive Rate\", fontsize = 14)\nax.set_xticks([(.25 * i) for i in range(5)])\n\nplt.tight_layout()\n\nprint(race_acc[\"FNR\"].iloc[0])\n\n\n7.9\n\n\n\n\n\n\n\n\n\nCode above plots FPR as a function of FNR, PPV, and prevalence for individuals identifying as white and those identifying as black or African American.\nFigure 10\nThe plot above is a reproduction of Figure 5 from Chouldechova’s 2017 publication “Fair prediction with disparate impact: A study of bias in recidivism prediction instruments”. For white and black or African American individuals in the data, the plot displays the model’s FPR as a linear function of FNR when the prevalence \\(p\\) and PPV are held constant. Based on this figure, to tune the refined model to yield equal FPR values for white and black or African American individuals, the model’s FNR for white individuals would need to be increased by over 50 percentage points (increasing from about \\(8\\%\\) to about \\(62.5\\%\\)). This indicates that equalizing FPR values for white and black or African American individuals would require a significant decrease in the model’s accuracy for white individuals."
  }
]