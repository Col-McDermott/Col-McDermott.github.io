[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Blog Info",
    "section": "",
    "text": "Middlebury College CSCI 0451A Blog - Col McDermott\n\n\n\nCheck out my completed assignments from\n\n\nCSCI 0451 Machine Learning\n\n\nwith Professor Phil Chodrow"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/post_1/index.html",
    "href": "posts/post_1/index.html",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "",
    "text": "In this blog post, I’m taking on an introductory-level machine learning classification task. This task, classifying penguin species, is a ternary classification problem as there are three species options for which I am trying to construct a classifier model to correctly identify. The data for this task comes from the Palmer Station and was collected by Dr. Kristen Gorman. The following analysis begins with some preliminary data visualizations and summary statistics interpretation. From the preliminary visualizations and statistics table, I’m able to make some initial observations about the difference in penguin features across each species. The next sections show the initial model and feature selection as well as model refinement to improve the chosen model. While completing this analysis, I experimented with several different models: a logistic regression model, a decision tree classifier, and a random forest classifier. I ultimately decided to choose proceed with the random forest classifier model (see the third section in this post). For feature selection, I initially took an exhaustive search approach. However, after running into many bugs and difficulties with this approach, I opted to incorporate the use of prebuilt feature selection tools (see second section in this post). Following a thorough feature selection and cross-validation/model refinement process, I was able to produce a model with nearly \\(100\\%\\) testing accuracy. That is, my model was able to correctly identify all but a single observation from unseen test data (i.e. it made 1 classification error). In the following sections of this post are more in-depth explanations and analyses of my steps taken in accomplishing this classification task.\n\n\n\n\nCode\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\n# Accessing training data\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n# Code below provided by Prof. Chodrow\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nThe prepare_data(...) function above was provided by Prof. Chodrow\n\n\nCode\n# Includuing all additional imports\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.colors import ListedColormap\nimport numpy as np\nimport seaborn as sns\n\n\nIncluding all additional imports\n\n\nCode\n# Creating a modified dataset for visualization and summary statistics\ntrain_viz = train[train[\"Sex\"] != \".\"].copy()\ntrain_viz[\"Culmen Ratio (L/D)\"] = train_viz[\"Culmen Length (mm)\"] / train_viz[\"Culmen Depth (mm)\"]\ntrain_viz.dropna()\n\n# Subsetting data by species to make regression plots for flipper length by body mass across each Species\nadelie = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\nadelie = adelie[adelie['Species'] == 'Adelie Penguin (Pygoscelis adeliae)']\nadelie = adelie.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\nchinstrap = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\nchinstrap = chinstrap[chinstrap['Species'] == 'Chinstrap penguin (Pygoscelis antarctica)']\nchinstrap = chinstrap.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\ngentoo = train_viz[['Species', 'Flipper Length (mm)', 'Body Mass (g)']]\ngentoo = gentoo[gentoo['Species'] == 'Gentoo penguin (Pygoscelis papua)']\ngentoo = gentoo.dropna(subset = ['Species', 'Flipper Length (mm)', 'Body Mass (g)'])\n\n\nAbove, I’m creating a modified dataset for visualization and summary statistics and making three subsets of the visualization data set corresponding to eac penguin species with the specific visualization features selected. This is later used for linear regression modeling by species.\n\n\n\n\n\nCode\n# Creating linear regression models and calculating r^2 values\n\n## Adelie\nc1 = np.polyfit(adelie['Body Mass (g)'], adelie['Flipper Length (mm)'], 1)\np1 = np.polyval(c1, adelie['Body Mass (g)'])\nr1 = adelie['Flipper Length (mm)'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((adelie['Flipper Length (mm)'] - np.mean(adelie['Flipper Length (mm)']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Chinstrap\nc2 = np.polyfit(chinstrap['Body Mass (g)'], chinstrap['Flipper Length (mm)'], 1)\np2 = np.polyval(c2, chinstrap['Body Mass (g)'])\nr2 = chinstrap['Flipper Length (mm)'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((chinstrap['Flipper Length (mm)'] - np.mean(chinstrap['Flipper Length (mm)']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n## Gentoo\nc3 = np.polyfit(gentoo['Body Mass (g)'], gentoo['Flipper Length (mm)'], 1)\np3 = np.polyval(c3, gentoo['Body Mass (g)'])\nr3 = gentoo['Flipper Length (mm)'] - p3\nssr3 = np.sum(r3**2)\nsst3 = np.sum((gentoo['Flipper Length (mm)'] - np.mean(gentoo['Flipper Length (mm)']))**2)\nrs3 = 1 - (ssr3 / sst3)\n\n\nAbove, I’m creating a linear regression model of flipper length by body mass for each species (using np.polyfit). I’m also extracting the \\(R^2\\) values (using predictions from np.polyval to calculate residuals) for each regression model to include in my plots below. I searched online how to use these two functions.\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (10, 7))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Setting up the initial scatter plot\nax[0] = sns.scatterplot(data = train_viz, x = 'Body Mass (g)', y = 'Flipper Length (mm)', hue = 'Species', palette = ['#B85ED4', '#2A7A7A', '#F28234'], style = 'Species', s = 50, ax = ax[0])\n\n# Adding regression lines for each species\nsns.regplot(data = adelie, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#F28234'}, ax = ax[0])\nsns.regplot(data = chinstrap, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#B85ED4'}, ax = ax[0])\nsns.regplot(data = gentoo, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#2A7A7A'}, ax = ax[0])\n\n# Plot styling to make colors match up and the text boxes look nicer\nax[0].set_title(\"Penguin Flipper Length (mm) by Body Mass (g)\\nColored by Species\")\nax[0].legend(frameon = True, prop = {'size': 9})\nax[0].text(5200, 175.75, '           \\n', fontsize = 20, bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'grey', boxstyle = 'round, pad=0.3'))\nax[0].text(5555, 180, f'     $R^2 = {rs3:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 178, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 176, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5200, 180.1, '\\u2013', color='#2A7A7A', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 178.1, '\\u2013', color='#B85ED4', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 176.1, '\\u2013', color='#F28234', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Setting up the box plot and doing some simple styling\nax[1] = sns.boxplot(train_viz, x = \"Species\", y = \"Culmen Ratio (L/D)\", hue = \"Sex\", ax = ax[1])\nax[1].set_xticks([0, 1, 2])\nax[1].set_xticklabels([\"Chinstrap\", \"Gentoo\", \"Adelie\"])\nax[1].legend(prop = {'size': 10}, frameon = True)\nax[1].set_title(\"Penguin Culmen Ratio (L/D) by Species\\nGrouped by Sex\")\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.2)\n\n\n\n\n\n\n\n\n\nIn the figure to the left, the relationship between penguin flipper length (mm) and body mass (g) for each species of penguin is displayed. Visually, there appears to be a notable positive, linear relationship between flipper length and body mass in general. That is, it seems that as penguin body mass increases, the flipper length increases as well regardless of species.\nAdditionally, there appears to be some clustering by species shown in this relationship. Gentoo penguins appear to have both the largest flipper lengths and body masses. There is less of a visually obvious distinction between Chinstrap and Adelie penguins shown by the relationship between body mass and flipper length. However, I believe it is reasonable to hypothesize that Chinstrap penguins have a slightly greater average flipper length while Adelie penguins have a slightly greater body mass.\nFrom the \\(R^2\\) values for the regression lines corresponding to the relationship between body mass and flipper length for each penguin species, I feel that it’s reasonable to say the positive linear relationships between the two variables in question for each species range from weak/moderate to moderate in strength. Further, while I do not have the statistical knowledge to confirm nor deny this hypothesis, perhaps the clear visual difference observed across the three species-specific regression lines could provide useful insight into this classification task.\nIn general, this plot reveals some useful information about the differences observed across each penguin species from two relevant variables. While this plot likely does not provide highly convincing information pertaining to the species classification of penguins from certain features, it does highlight a relationship between two key quantitative variables that displays a preliminary approach to this classification task.\nThe figure to the right displays the general distribution of the Culmen Ratio (L/D) feature across penguin sex and penguin species. The Culmen Ratio (L/D) is the ratio of culmen length (mm) to culmen depth (mm). With no prior knowledge about culmen size and dimensions in penguins, I thought it would be interesting to compute the length-depth ratio for each penguin and see how this ratio differed by sex and across each species. Observing the comparison of the culmen ratio between male and female penguins, there does not appear to be as much visually obvious information. However, to me, there appears to be minimal distribution overlap in the culmen ratio across each species. I believe this suggests that the culmen ratio or related features (culmen length and culmen depth) could be useful in model construction to successfully complete this classification task.\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.groupby(['Species', 'Sex']).aggregate({\"Flipper Length (mm)\" : [\"mean\", \"std\", cv], \n                                                             \"Body Mass (g)\" : [\"mean\", \"std\", cv], \"Culmen Length (mm)\": [\"mean\", \"std\", cv], \n                                                             \"Culmen Depth (mm)\": [\"mean\", \"std\", cv], \"Culmen Ratio (L/D)\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {'mean': 'Mean', 'std': 'STD', 'cv': 'CV (%)'})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nBody Mass (g)\nCulmen Length (mm)\nCulmen Depth (mm)\nCulmen Ratio (L/D)\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\nFEMALE\n187.92\n5.43\n2.89\n3350.47\n262.87\n7.85\n37.43\n1.95\n5.20\n17.64\n0.92\n5.21\n2.13\n0.15\n6.96\n\n\nMALE\n192.33\n7.00\n3.64\n4052.87\n331.57\n8.18\n40.40\n2.37\n5.86\n19.08\n1.05\n5.48\n2.12\n0.17\n7.89\n\n\nChinstrap penguin (Pygoscelis antarctica)\nFEMALE\n192.06\n5.90\n3.07\n3523.39\n294.95\n8.37\n46.72\n3.17\n6.78\n17.61\n0.80\n4.55\n2.66\n0.19\n7.21\n\n\nMALE\n200.69\n6.29\n3.13\n4005.77\n368.53\n9.20\n51.33\n1.60\n3.13\n19.27\n0.77\n3.97\n2.67\n0.10\n3.93\n\n\nGentoo penguin (Pygoscelis papua)\nFEMALE\n212.84\n3.47\n1.63\n4684.69\n297.46\n6.35\n45.46\n1.97\n4.34\n14.21\n0.54\n3.78\n3.20\n0.14\n4.45\n\n\nMALE\n221.20\n5.22\n2.36\n5476.70\n301.32\n5.50\n49.01\n2.29\n4.68\n15.73\n0.79\n5.00\n3.12\n0.18\n5.77\n\n\n\n\n\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAbove is a general statistics table for the quantitative features present in the penguins data. Some noteworthy observations from this table are below.\nAdelie penguins:\n\nFemales\n\nSmallest average flipper length, body mass, culmen length, and culmen ratio\nLargest average culmen depth\n\nMales\n\nSmallest average flipper length, culmen length, and culmen ratio\n\n\nChinstrap penguins:\n\nFemales\n\nLargest average culmen length\n\nMales\n\nSmallest average body mass\nLargest average culmen length and culmen depth\n\n\nGentoo penguins:\n\nFemales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\nMales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\n\nRegarding the variability in the distribution of each feature represented in the table above, the coefficient of variation (as a percentage) is below 10% for all feature distributions. According to some brief research on CV, the CV values shown in the table above suggest that there is a relatively low degree of variability in the distributions of each feature."
  },
  {
    "objectID": "posts/post_1/index.html#summary-statistics-and-preliminary-visualizations",
    "href": "posts/post_1/index.html#summary-statistics-and-preliminary-visualizations",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "",
    "text": "Code\n# Creating linear regression models and calculating r^2 values\n\n## Adelie\nc1 = np.polyfit(adelie['Body Mass (g)'], adelie['Flipper Length (mm)'], 1)\np1 = np.polyval(c1, adelie['Body Mass (g)'])\nr1 = adelie['Flipper Length (mm)'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((adelie['Flipper Length (mm)'] - np.mean(adelie['Flipper Length (mm)']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Chinstrap\nc2 = np.polyfit(chinstrap['Body Mass (g)'], chinstrap['Flipper Length (mm)'], 1)\np2 = np.polyval(c2, chinstrap['Body Mass (g)'])\nr2 = chinstrap['Flipper Length (mm)'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((chinstrap['Flipper Length (mm)'] - np.mean(chinstrap['Flipper Length (mm)']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n## Gentoo\nc3 = np.polyfit(gentoo['Body Mass (g)'], gentoo['Flipper Length (mm)'], 1)\np3 = np.polyval(c3, gentoo['Body Mass (g)'])\nr3 = gentoo['Flipper Length (mm)'] - p3\nssr3 = np.sum(r3**2)\nsst3 = np.sum((gentoo['Flipper Length (mm)'] - np.mean(gentoo['Flipper Length (mm)']))**2)\nrs3 = 1 - (ssr3 / sst3)\n\n\nAbove, I’m creating a linear regression model of flipper length by body mass for each species (using np.polyfit). I’m also extracting the \\(R^2\\) values (using predictions from np.polyval to calculate residuals) for each regression model to include in my plots below. I searched online how to use these two functions.\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (10, 7))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Setting up the initial scatter plot\nax[0] = sns.scatterplot(data = train_viz, x = 'Body Mass (g)', y = 'Flipper Length (mm)', hue = 'Species', palette = ['#B85ED4', '#2A7A7A', '#F28234'], style = 'Species', s = 50, ax = ax[0])\n\n# Adding regression lines for each species\nsns.regplot(data = adelie, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#F28234'}, ax = ax[0])\nsns.regplot(data = chinstrap, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#B85ED4'}, ax = ax[0])\nsns.regplot(data = gentoo, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#2A7A7A'}, ax = ax[0])\n\n# Plot styling to make colors match up and the text boxes look nicer\nax[0].set_title(\"Penguin Flipper Length (mm) by Body Mass (g)\\nColored by Species\")\nax[0].legend(frameon = True, prop = {'size': 9})\nax[0].text(5200, 175.75, '           \\n', fontsize = 20, bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'grey', boxstyle = 'round, pad=0.3'))\nax[0].text(5555, 180, f'     $R^2 = {rs3:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 178, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 176, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5200, 180.1, '\\u2013', color='#2A7A7A', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 178.1, '\\u2013', color='#B85ED4', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 176.1, '\\u2013', color='#F28234', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Setting up the box plot and doing some simple styling\nax[1] = sns.boxplot(train_viz, x = \"Species\", y = \"Culmen Ratio (L/D)\", hue = \"Sex\", ax = ax[1])\nax[1].set_xticks([0, 1, 2])\nax[1].set_xticklabels([\"Chinstrap\", \"Gentoo\", \"Adelie\"])\nax[1].legend(prop = {'size': 10}, frameon = True)\nax[1].set_title(\"Penguin Culmen Ratio (L/D) by Species\\nGrouped by Sex\")\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.2)\n\n\n\n\n\n\n\n\n\nIn the figure to the left, the relationship between penguin flipper length (mm) and body mass (g) for each species of penguin is displayed. Visually, there appears to be a notable positive, linear relationship between flipper length and body mass in general. That is, it seems that as penguin body mass increases, the flipper length increases as well regardless of species.\nAdditionally, there appears to be some clustering by species shown in this relationship. Gentoo penguins appear to have both the largest flipper lengths and body masses. There is less of a visually obvious distinction between Chinstrap and Adelie penguins shown by the relationship between body mass and flipper length. However, I believe it is reasonable to hypothesize that Chinstrap penguins have a slightly greater average flipper length while Adelie penguins have a slightly greater body mass.\nFrom the \\(R^2\\) values for the regression lines corresponding to the relationship between body mass and flipper length for each penguin species, I feel that it’s reasonable to say the positive linear relationships between the two variables in question for each species range from weak/moderate to moderate in strength. Further, while I do not have the statistical knowledge to confirm nor deny this hypothesis, perhaps the clear visual difference observed across the three species-specific regression lines could provide useful insight into this classification task.\nIn general, this plot reveals some useful information about the differences observed across each penguin species from two relevant variables. While this plot likely does not provide highly convincing information pertaining to the species classification of penguins from certain features, it does highlight a relationship between two key quantitative variables that displays a preliminary approach to this classification task.\nThe figure to the right displays the general distribution of the Culmen Ratio (L/D) feature across penguin sex and penguin species. The Culmen Ratio (L/D) is the ratio of culmen length (mm) to culmen depth (mm). With no prior knowledge about culmen size and dimensions in penguins, I thought it would be interesting to compute the length-depth ratio for each penguin and see how this ratio differed by sex and across each species. Observing the comparison of the culmen ratio between male and female penguins, there does not appear to be as much visually obvious information. However, to me, there appears to be minimal distribution overlap in the culmen ratio across each species. I believe this suggests that the culmen ratio or related features (culmen length and culmen depth) could be useful in model construction to successfully complete this classification task.\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.groupby(['Species', 'Sex']).aggregate({\"Flipper Length (mm)\" : [\"mean\", \"std\", cv], \n                                                             \"Body Mass (g)\" : [\"mean\", \"std\", cv], \"Culmen Length (mm)\": [\"mean\", \"std\", cv], \n                                                             \"Culmen Depth (mm)\": [\"mean\", \"std\", cv], \"Culmen Ratio (L/D)\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {'mean': 'Mean', 'std': 'STD', 'cv': 'CV (%)'})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nBody Mass (g)\nCulmen Length (mm)\nCulmen Depth (mm)\nCulmen Ratio (L/D)\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\nFEMALE\n187.92\n5.43\n2.89\n3350.47\n262.87\n7.85\n37.43\n1.95\n5.20\n17.64\n0.92\n5.21\n2.13\n0.15\n6.96\n\n\nMALE\n192.33\n7.00\n3.64\n4052.87\n331.57\n8.18\n40.40\n2.37\n5.86\n19.08\n1.05\n5.48\n2.12\n0.17\n7.89\n\n\nChinstrap penguin (Pygoscelis antarctica)\nFEMALE\n192.06\n5.90\n3.07\n3523.39\n294.95\n8.37\n46.72\n3.17\n6.78\n17.61\n0.80\n4.55\n2.66\n0.19\n7.21\n\n\nMALE\n200.69\n6.29\n3.13\n4005.77\n368.53\n9.20\n51.33\n1.60\n3.13\n19.27\n0.77\n3.97\n2.67\n0.10\n3.93\n\n\nGentoo penguin (Pygoscelis papua)\nFEMALE\n212.84\n3.47\n1.63\n4684.69\n297.46\n6.35\n45.46\n1.97\n4.34\n14.21\n0.54\n3.78\n3.20\n0.14\n4.45\n\n\nMALE\n221.20\n5.22\n2.36\n5476.70\n301.32\n5.50\n49.01\n2.29\n4.68\n15.73\n0.79\n5.00\n3.12\n0.18\n5.77\n\n\n\n\n\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAbove is a general statistics table for the quantitative features present in the penguins data. Some noteworthy observations from this table are below.\nAdelie penguins:\n\nFemales\n\nSmallest average flipper length, body mass, culmen length, and culmen ratio\nLargest average culmen depth\n\nMales\n\nSmallest average flipper length, culmen length, and culmen ratio\n\n\nChinstrap penguins:\n\nFemales\n\nLargest average culmen length\n\nMales\n\nSmallest average body mass\nLargest average culmen length and culmen depth\n\n\nGentoo penguins:\n\nFemales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\nMales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\n\nRegarding the variability in the distribution of each feature represented in the table above, the coefficient of variation (as a percentage) is below 10% for all feature distributions. According to some brief research on CV, the CV values shown in the table above suggest that there is a relatively low degree of variability in the distributions of each feature."
  },
  {
    "objectID": "posts/post_1/index.html#testing-the-model",
    "href": "posts/post_1/index.html#testing-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Testing the Model",
    "text": "Testing the Model\nAfter refining my model, I then tested it on the testing data. To my excitement, the model dispayed a \\(98.529\\%\\) testing accuracy.\n\n\nCode\n# Accessing test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Testing the model!\nX_test, y_test = prepare_data(test)\ntest_score = rfc_refined.score(X_test[X_train_selected.columns], y_test)\nts2 = rfc_base.score(X_test[X_train_selected.columns], y_test)\nprint(f'Refined (cross-validated) Model Test Accuracy: {test_score * 100: .3f}%')\n\n\nRefined (cross-validated) Model Test Accuracy:  98.529%\n\n\nBelow are the decision regions determined by the model for both the training and testing data. Visually, the decision regions for the training and testing data appear to be extremely similar. Additionally, I feel that it is reasonable to state that the decision regions for both the training and testing data do not display a high degree of model-overfitting.\n\n\nCode\n# Decision region plotting - code provided by Prof. Chodrow\ndef plot_regions(model, X, y, type):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (10, 5))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      colors = ['#2A7A7A', '#B85ED4', '#F28234']\n      og = ['red', 'green', 'blue']\n      cmap = ListedColormap(colors)\n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = cmap, alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = cmap, vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i][7:] + \" Island\")\n      \n      patches = []\n      for color, spec in zip(['#F28234', '#B85ED4', '#2A7A7A'], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n\n      if (type):\n         fig.suptitle(\"Decision Regions for Training Data\")\n      else:\n         fig.suptitle(\"Decision Regions for Testing Data\")\n      \n      plt.tight_layout()\n\nplot_regions(rfc_refined, X_train_selected, y_train, 1)\nplot_regions(rfc_refined, X_test[X_train_selected.columns], y_test, 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI made some minor adjustments to the code above provided by Prof. Chodrow (primarily debugging, color changing, and adding titles)"
  },
  {
    "objectID": "posts/post_1/index.html#confusion-matrix-for-the-model",
    "href": "posts/post_1/index.html#confusion-matrix-for-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Confusion Matrix for the Model",
    "text": "Confusion Matrix for the Model\nBelow is the confusion matrix to evaluate the model’s testing performance. As expected with \\(&lt; 100\\%\\) (\\(98.529\\%\\)) testing accuracy, the confusion matrix has at least some (in this case exactly 1) non-zero entries off the diagonal. This indicates that the model made 1 misclassification. That is, all Adelie penguins and Chinstrap penguins were correctly classified, but there was one Gentoo penguin who was misclassified as an Adelie penguin (shucks).\n\n\nCode\n# Establishing model predictions for the test data\ny_test_pred = rfc_refined.predict(X_test[X_train_selected.columns])\nC = confusion_matrix(y_test, y_test_pred)\nspecies = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\n# Creating a heatmap for better confusion matrix visualization\nplt.figure(figsize=(6, 5))\nsns.heatmap(C, annot = True, fmt = \"d\", cmap = 'Greens', cbar = False, xticklabels = species, yticklabels = species)\n\n# Setting labels and title\nplt.xlabel(\"Predicted Species Classification\")\nplt.ylabel(\"True Species Classification\")\nplt.title(\"Palmer Penguins Classification Confusion Matrix\")\n\nplt.show()\n\n# Printing confusion matrix results\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\n\n\n\n\n\n\n\n\nThere were 31 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 11 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 1 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 25 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua)."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSCI 0451A Blog - Spring 2025",
    "section": "",
    "text": "Post 1 - Classifying Palmer Penguins\n\n\n\n\n\nA ternary classification of penguin species: Gentoo, Adelie, and Chinstrap\n\n\n\n\n\nFeb 17, 2025\n\n\nCol McDermott\n\n\n\n\n\n\n\n\n\n\n\n\nPost 2 - Exploring Automated Decision Models\n\n\n\n\n\nAn introductory analysis of an automated decision model in the context of credit-risk prediction\n\n\n\n\n\nFeb 17, 2025\n\n\nCol McDermott\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post_1/index.html#feature-selection",
    "href": "posts/post_1/index.html#feature-selection",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Feature Selection",
    "text": "Feature Selection\nCode Description\nAnalysis of feature selection."
  },
  {
    "objectID": "posts/post_1/index.html#creating-a-scoring-function",
    "href": "posts/post_1/index.html#creating-a-scoring-function",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Creating a Scoring Function",
    "text": "Creating a Scoring Function\nCode Description\nAnalysis of creating scoring function."
  },
  {
    "objectID": "posts/post_1/index.html#choosing-a-threshold",
    "href": "posts/post_1/index.html#choosing-a-threshold",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Choosing a Threshold",
    "text": "Choosing a Threshold\nCode Description\nAnalysis of choosing a threshold."
  },
  {
    "objectID": "posts/post_1/index.html#perspective-of-the-bank",
    "href": "posts/post_1/index.html#perspective-of-the-bank",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Bank",
    "text": "Perspective of the Bank\nCode Description\nAnalysis of model evaluation from the perspective of the bank."
  },
  {
    "objectID": "posts/post_1/index.html#perspective-of-the-borrower",
    "href": "posts/post_1/index.html#perspective-of-the-borrower",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Borrower",
    "text": "Perspective of the Borrower\nCode Description\nAnalysis of model evaluation from the perspective of the borrower."
  },
  {
    "objectID": "posts/post_2/index.html",
    "href": "posts/post_2/index.html",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "",
    "text": "Code\n# Includuing all additional imports\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ntrain = pd.read_csv(\"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\")\n\n\nIncluding all additional imports\n\n\n\n\n\n\n\nCode\n# Data modification\ntrain_viz = train.copy()\nloan_status_recode = {0: 'Paid in Full', 1: 'Defaulted'}\ntrain_viz['Loan Repayment'] = train_viz['loan_status'].map(loan_status_recode)\ntrain_viz = train_viz.dropna()\n\n# Subsetting data by loan status\ndefault = train_viz[train_viz['loan_status'] == 1].copy().dropna()\nrepaid = train_viz[train_viz['loan_status'] == 0].copy().dropna()\n\n\nModifying training data for visualization\n\n\nCode\n# Creating linear regression models and calculating R^2 values\n## Default\nc1 = np.polyfit(default['loan_amnt'], default['person_income'], 1)\np1 = np.polyval(c1, default['loan_amnt'])\nr1 = default['person_income'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((default['person_income'] - np.mean(default['loan_amnt']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Repaid\nc2 = np.polyfit(repaid['loan_amnt'], repaid['person_income'], 1)\np2 = np.polyval(c2, repaid['loan_amnt'])\nr2 = repaid['person_income'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((repaid['person_income'] - np.mean(repaid['loan_amnt']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (15, 10))\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# Scatterplot and regression line for borrower income by loan amount of defaulted loans\nax[0] = sns.scatterplot(data = default, x = 'loan_amnt', y = 'person_income', color = 'purple', edgecolor = 'purple', alpha = 0.25, ax = ax[0])\nsns.regplot(data = default, x = 'loan_amnt', y = 'person_income', scatter = False, line_kws={'color': 'darkorange'}, ax = ax[0])\nax[0].set_yscale('log', base = 2)\nax[0].set_xlabel('')\nax[0].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[0].set_xticklabels(['$0', '$5000', '$10000', '$15000', '$20000', '$25000', '$30000', '$35000'], rotation=30)\nax[0].set_ylabel(f'Borrower\\'s Income ($\\log_2$ scale)', fontsize = 14, labelpad = 15)\nax[0].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19])\nax[0].set_yticklabels([f'\\$$2^{{12}}$', f'\\$$2^{{13}}$', f'\\$$2^{{14}}$', f'\\$$2^{{15}}$', f'\\$$2^{{16}}$', f'\\$$2^{{17}}$', f'\\$$2^{{18}}$', f'\\$$2^{{19}}$'])\nax[0].set_title('Defaulted Loans', fontsize = 16)\nax[0].text(27000, 12288, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'gray', boxstyle = 'round,pad=0.3'))\nax[0].text(24000, 12288, '\\u2013', color='darkorange', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Scatterplot and regression line for borrower income by loan amount of repaid loans\nax[1] = sns.scatterplot(data = repaid, x = 'loan_amnt', y = 'person_income', color = 'darkorange', edgecolor = 'darkorange', alpha = 0.5, ax = ax[1])\nsns.regplot(data = repaid, x = 'loan_amnt', y = 'person_income', scatter = False, line_kws={'color': 'purple'}, ax = ax[1])\nax[1].set_yscale('log', base = 2)\nax[1].set_xlabel('')\nax[1].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[1].set_xticklabels(['$0', '$5000', '$10000', '$15000', '$20000', '$25000', '$30000', '$35000'], rotation=30)\nax[1].set_ylabel('')\nax[1].set_yticks([2**14, 2**16, 2**18, 2**20, 2**22])\nax[1].set_yticklabels([f'\\$$2^{{14}}$', f'\\$$2^{{16}}$', f'\\$$2^{{18}}$', f'\\$$2^{{20}}$', f'\\$$2^{{22}}$'])\nax[1].set_title('Repaid Loans', fontsize = 16)\nax[1].text(27000, 12288, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'gray', boxstyle = 'round,pad=0.3'))\nax[1].text(24000, 12288, '\\u2013', color='purple', ha='left', va='center', fontsize=15, fontweight='bold')\n\nfig.suptitle('Borrower\\'s Income by Loan Amount Displayed by Loan Repayment Status', fontsize = 18)\nfig.text(0.475, 0.05, 'Loan Amount', fontsize = 14)\n\n\nText(0.475, 0.05, 'Loan Amount')\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Additional figure\n\n# Creating subplots of loan-percent-income by person age (for each loan grade)\n# fig, ax = plt.subplots(1, 1, figsize = (3, 3))\nsns.relplot(train_viz, x = 'person_age', y = 'loan_percent_income', col = 'loan_grade')\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode Description\nAnalysis of the above figures.\n\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAnalysis of the summary statistics table."
  },
  {
    "objectID": "posts/post_2/index.html#summary-statistics-and-preliminary-visualizations",
    "href": "posts/post_2/index.html#summary-statistics-and-preliminary-visualizations",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "",
    "text": "Code\n# Creating linear regression models and calculating r^2 values\n\n## Adelie\nc1 = np.polyfit(adelie['Body Mass (g)'], adelie['Flipper Length (mm)'], 1)\np1 = np.polyval(c1, adelie['Body Mass (g)'])\nr1 = adelie['Flipper Length (mm)'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((adelie['Flipper Length (mm)'] - np.mean(adelie['Flipper Length (mm)']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Chinstrap\nc2 = np.polyfit(chinstrap['Body Mass (g)'], chinstrap['Flipper Length (mm)'], 1)\np2 = np.polyval(c2, chinstrap['Body Mass (g)'])\nr2 = chinstrap['Flipper Length (mm)'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((chinstrap['Flipper Length (mm)'] - np.mean(chinstrap['Flipper Length (mm)']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n## Gentoo\nc3 = np.polyfit(gentoo['Body Mass (g)'], gentoo['Flipper Length (mm)'], 1)\np3 = np.polyval(c3, gentoo['Body Mass (g)'])\nr3 = gentoo['Flipper Length (mm)'] - p3\nssr3 = np.sum(r3**2)\nsst3 = np.sum((gentoo['Flipper Length (mm)'] - np.mean(gentoo['Flipper Length (mm)']))**2)\nrs3 = 1 - (ssr3 / sst3)\n\n\nAbove, I’m creating a linear regression model of flipper length by body mass for each species (using np.polyfit). I’m also extracting the \\(R^2\\) values (using predictions from np.polyval to calculate residuals) for each regression model to include in my plots below. I searched online how to use these two functions.\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (10, 7))\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Setting up the initial scatter plot\nax[0] = sns.scatterplot(data = train_viz, x = 'Body Mass (g)', y = 'Flipper Length (mm)', hue = 'Species', palette = ['#B85ED4', '#2A7A7A', '#F28234'], style = 'Species', s = 50, ax = ax[0])\n\n# Adding regression lines for each species\nsns.regplot(data = adelie, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#F28234'}, ax = ax[0])\nsns.regplot(data = chinstrap, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#B85ED4'}, ax = ax[0])\nsns.regplot(data = gentoo, x = 'Body Mass (g)', y = 'Flipper Length (mm)', scatter = False, line_kws={'color': '#2A7A7A'}, ax = ax[0])\n\n# Plot styling to make colors match up and the text boxes look nicer\nax[0].set_title(\"Penguin Flipper Length (mm) by Body Mass (g)\\nColored by Species\")\nax[0].legend(frameon = True, prop = {'size': 9})\nax[0].text(5200, 175.75, '           \\n', fontsize = 20, bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'grey', boxstyle = 'round, pad=0.3'))\nax[0].text(5555, 180, f'     $R^2 = {rs3:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 178, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5555, 176, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'none', boxstyle = 'round,pad=0.3'))\nax[0].text(5200, 180.1, '\\u2013', color='#2A7A7A', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 178.1, '\\u2013', color='#B85ED4', ha='left', va='center', fontsize=15, fontweight='bold')\nax[0].text(5200, 176.1, '\\u2013', color='#F28234', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Setting up the box plot and doing some simple styling\nax[1] = sns.boxplot(train_viz, x = \"Species\", y = \"Culmen Ratio (L/D)\", hue = \"Sex\", ax = ax[1])\nax[1].set_xticks([0, 1, 2])\nax[1].set_xticklabels([\"Chinstrap\", \"Gentoo\", \"Adelie\"])\nax[1].legend(prop = {'size': 10}, frameon = True)\nax[1].set_title(\"Penguin Culmen Ratio (L/D) by Species\\nGrouped by Sex\")\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.2)\n\n\n\n\n\n\n\n\n\nIn the figure to the left, the relationship between penguin flipper length (mm) and body mass (g) for each species of penguin is displayed. Visually, there appears to be a notable positive, linear relationship between flipper length and body mass in general. That is, it seems that as penguin body mass increases, the flipper length increases as well regardless of species.\nAdditionally, there appears to be some clustering by species shown in this relationship. Gentoo penguins appear to have both the largest flipper lengths and body masses. There is less of a visually obvious distinction between Chinstrap and Adelie penguins shown by the relationship between body mass and flipper length. However, I believe it is reasonable to hypothesize that Chinstrap penguins have a slightly greater average flipper length while Adelie penguins have a slightly greater body mass.\nFrom the \\(R^2\\) values for the regression lines corresponding to the relationship between body mass and flipper length for each penguin species, I feel that it’s reasonable to say the positive linear relationships between the two variables in question for each species range from weak/moderate to moderate in strength. Further, while I do not have the statistical knowledge to confirm nor deny this hypothesis, perhaps the clear visual difference observed across the three species-specific regression lines could provide useful insight into this classification task.\nIn general, this plot reveals some useful information about the differences observed across each penguin species from two relevant variables. While this plot likely does not provide highly convincing information pertaining to the species classification of penguins from certain features, it does highlight a relationship between two key quantitative variables that displays a preliminary approach to this classification task.\nThe figure to the right displays the general distribution of the Culmen Ratio (L/D) feature across penguin sex and penguin species. The Culmen Ratio (L/D) is the ratio of culmen length (mm) to culmen depth (mm). With no prior knowledge about culmen size and dimensions in penguins, I thought it would be interesting to compute the length-depth ratio for each penguin and see how this ratio differed by sex and across each species. Observing the comparison of the culmen ratio between male and female penguins, there does not appear to be as much visually obvious information. However, to me, there appears to be minimal distribution overlap in the culmen ratio across each species. I believe this suggests that the culmen ratio or related features (culmen length and culmen depth) could be useful in model construction to successfully complete this classification task.\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n# Creating a table grouped by penguin species and sex, showing general summary stats for several quantitative variables\nsum_stats = train_viz.groupby(['Species', 'Sex']).aggregate({\"Flipper Length (mm)\" : [\"mean\", \"std\", cv], \n                                                             \"Body Mass (g)\" : [\"mean\", \"std\", cv], \"Culmen Length (mm)\": [\"mean\", \"std\", cv], \n                                                             \"Culmen Depth (mm)\": [\"mean\", \"std\", cv], \"Culmen Ratio (L/D)\": [\"mean\", \"std\", cv]})\nsum_stats = sum_stats.rename(columns = {'mean': 'Mean', 'std': 'STD', 'cv': 'CV (%)'})\nsum_stats = sum_stats.round(2)\nsum_stats\n\n\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nBody Mass (g)\nCulmen Length (mm)\nCulmen Depth (mm)\nCulmen Ratio (L/D)\n\n\n\n\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\nMean\nSTD\nCV (%)\n\n\nSpecies\nSex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\nFEMALE\n187.92\n5.43\n2.89\n3350.47\n262.87\n7.85\n37.43\n1.95\n5.20\n17.64\n0.92\n5.21\n2.13\n0.15\n6.96\n\n\nMALE\n192.33\n7.00\n3.64\n4052.87\n331.57\n8.18\n40.40\n2.37\n5.86\n19.08\n1.05\n5.48\n2.12\n0.17\n7.89\n\n\nChinstrap penguin (Pygoscelis antarctica)\nFEMALE\n192.06\n5.90\n3.07\n3523.39\n294.95\n8.37\n46.72\n3.17\n6.78\n17.61\n0.80\n4.55\n2.66\n0.19\n7.21\n\n\nMALE\n200.69\n6.29\n3.13\n4005.77\n368.53\n9.20\n51.33\n1.60\n3.13\n19.27\n0.77\n3.97\n2.67\n0.10\n3.93\n\n\nGentoo penguin (Pygoscelis papua)\nFEMALE\n212.84\n3.47\n1.63\n4684.69\n297.46\n6.35\n45.46\n1.97\n4.34\n14.21\n0.54\n3.78\n3.20\n0.14\n4.45\n\n\nMALE\n221.20\n5.22\n2.36\n5476.70\n301.32\n5.50\n49.01\n2.29\n4.68\n15.73\n0.79\n5.00\n3.12\n0.18\n5.77\n\n\n\n\n\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAbove is a general statistics table for the quantitative features present in the penguins data. Some noteworthy observations from this table are below.\nAdelie penguins:\n\nFemales\n\nSmallest average flipper length, body mass, culmen length, and culmen ratio\nLargest average culmen depth\n\nMales\n\nSmallest average flipper length, culmen length, and culmen ratio\n\n\nChinstrap penguins:\n\nFemales\n\nLargest average culmen length\n\nMales\n\nSmallest average body mass\nLargest average culmen length and culmen depth\n\n\nGentoo penguins:\n\nFemales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\nMales\n\nLargest average flipper length, body mass, and culmen ratio\nSmallest average culmen depth\n\n\nRegarding the variability in the distribution of each feature represented in the table above, the coefficient of variation (as a percentage) is below 10% for all feature distributions. According to some brief research on CV, the CV values shown in the table above suggest that there is a relatively low degree of variability in the distributions of each feature."
  },
  {
    "objectID": "posts/post_2/index.html#testing-the-model",
    "href": "posts/post_2/index.html#testing-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Testing the Model",
    "text": "Testing the Model\nAfter refining my model, I then tested it on the testing data. To my excitement, the model dispayed a \\(98.529\\%\\) testing accuracy.\n\n\nCode\n# Accessing test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Testing the model!\nX_test, y_test = prepare_data(test)\ntest_score = rfc_refined.score(X_test[X_train_selected.columns], y_test)\nts2 = rfc_base.score(X_test[X_train_selected.columns], y_test)\nprint(f'Refined (cross-validated) Model Test Accuracy: {test_score * 100: .3f}%')\n\n\nRefined (cross-validated) Model Test Accuracy:  98.529%\n\n\nBelow are the decision regions determined by the model for both the training and testing data. Visually, the decision regions for the training and testing data appear to be extremely similar. Additionally, I feel that it is reasonable to state that the decision regions for both the training and testing data do not display a high degree of model-overfitting.\n\n\nCode\n# Decision region plotting - code provided by Prof. Chodrow\ndef plot_regions(model, X, y, type):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (10, 5))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      colors = ['#2A7A7A', '#B85ED4', '#F28234']\n      og = ['red', 'green', 'blue']\n      cmap = ListedColormap(colors)\n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = cmap, alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = cmap, vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i][7:] + \" Island\")\n      \n      patches = []\n      for color, spec in zip(['#F28234', '#B85ED4', '#2A7A7A'], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n\n      if (type):\n         fig.suptitle(\"Decision Regions for Training Data\")\n      else:\n         fig.suptitle(\"Decision Regions for Testing Data\")\n      \n      plt.tight_layout()\n\nplot_regions(rfc_refined, X_train_selected, y_train, 1)\nplot_regions(rfc_refined, X_test[X_train_selected.columns], y_test, 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI made some minor adjustments to the code above provided by Prof. Chodrow (primarily debugging, color changing, and adding titles)"
  },
  {
    "objectID": "posts/post_2/index.html#confusion-matrix-for-the-model",
    "href": "posts/post_2/index.html#confusion-matrix-for-the-model",
    "title": "Post 1 - Classifying Palmer Penguins",
    "section": "Confusion Matrix for the Model",
    "text": "Confusion Matrix for the Model\nBelow is the confusion matrix to evaluate the model’s testing performance. As expected with \\(&lt; 100\\%\\) (\\(98.529\\%\\)) testing accuracy, the confusion matrix has at least some (in this case exactly 1) non-zero entries off the diagonal. This indicates that the model made 1 misclassification. That is, all Adelie penguins and Chinstrap penguins were correctly classified, but there was one Gentoo penguin who was misclassified as an Adelie penguin (shucks).\n\n\nCode\n# Establishing model predictions for the test data\ny_test_pred = rfc_refined.predict(X_test[X_train_selected.columns])\nC = confusion_matrix(y_test, y_test_pred)\nspecies = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n\n# Creating a heatmap for better confusion matrix visualization\nplt.figure(figsize=(6, 5))\nsns.heatmap(C, annot = True, fmt = \"d\", cmap = 'Greens', cbar = False, xticklabels = species, yticklabels = species)\n\n# Setting labels and title\nplt.xlabel(\"Predicted Species Classification\")\nplt.ylabel(\"True Species Classification\")\nplt.title(\"Palmer Penguins Classification Confusion Matrix\")\n\nplt.show()\n\n# Printing confusion matrix results\nfor i in range(3):\n    for j in range(3):\n        print(f\"There were {C[i,j]} {le.classes_[i]} penguin(s) who were classified as {le.classes_[j]}.\")\n\n\n\n\n\n\n\n\n\nThere were 31 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Adelie Penguin (Pygoscelis adeliae) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 11 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 0 Chinstrap penguin (Pygoscelis antarctica) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua).\nThere were 1 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Adelie Penguin (Pygoscelis adeliae).\nThere were 0 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Chinstrap penguin (Pygoscelis antarctica).\nThere were 25 Gentoo penguin (Pygoscelis papua) penguin(s) who were classified as Gentoo penguin (Pygoscelis papua)."
  },
  {
    "objectID": "posts/post_1/index.html#exploring-the-data",
    "href": "posts/post_1/index.html#exploring-the-data",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "",
    "text": "Code\n# Plotting\n\n\nCode Description\nAnalysis of the above figures.\n\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAnalysis of the summary statistics table."
  },
  {
    "objectID": "posts/post_2/index.html#exploring-the-data",
    "href": "posts/post_2/index.html#exploring-the-data",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "",
    "text": "Code\n# Data modification\ntrain_viz = train.copy()\nloan_status_recode = {0: 'Paid in Full', 1: 'Defaulted'}\ntrain_viz['Loan Repayment'] = train_viz['loan_status'].map(loan_status_recode)\ntrain_viz = train_viz.dropna()\n\n# Subsetting data by loan status\ndefault = train_viz[train_viz['loan_status'] == 1].copy().dropna()\nrepaid = train_viz[train_viz['loan_status'] == 0].copy().dropna()\n\n\nModifying training data for visualization\n\n\nCode\n# Creating linear regression models and calculating R^2 values\n## Default\nc1 = np.polyfit(default['loan_amnt'], default['person_income'], 1)\np1 = np.polyval(c1, default['loan_amnt'])\nr1 = default['person_income'] - p1\nssr1 = np.sum(r1**2)\nsst1 = np.sum((default['person_income'] - np.mean(default['loan_amnt']))**2)\nrs1 = 1 - (ssr1 / sst1)\n\n## Repaid\nc2 = np.polyfit(repaid['loan_amnt'], repaid['person_income'], 1)\np2 = np.polyval(c2, repaid['loan_amnt'])\nr2 = repaid['person_income'] - p2\nssr2 = np.sum(r2**2)\nsst2 = np.sum((repaid['person_income'] - np.mean(repaid['loan_amnt']))**2)\nrs2 = 1 - (ssr2 / sst2)\n\n\n\n\nCode\n# Plotting\nfig, ax = plt.subplots(1, 2, figsize = (15, 10))\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# Scatterplot and regression line for borrower income by loan amount of defaulted loans\nax[0] = sns.scatterplot(data = default, x = 'loan_amnt', y = 'person_income', color = 'purple', edgecolor = 'purple', alpha = 0.25, ax = ax[0])\nsns.regplot(data = default, x = 'loan_amnt', y = 'person_income', scatter = False, line_kws={'color': 'darkorange'}, ax = ax[0])\nax[0].set_yscale('log', base = 2)\nax[0].set_xlabel('')\nax[0].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[0].set_xticklabels(['$0', '$5000', '$10000', '$15000', '$20000', '$25000', '$30000', '$35000'], rotation=30)\nax[0].set_ylabel(f'Borrower\\'s Income ($\\log_2$ scale)', fontsize = 14, labelpad = 15)\nax[0].set_yticks([2**12, 2**13, 2**14, 2**15, 2**16, 2**17, 2**18, 2**19])\nax[0].set_yticklabels([f'\\$$2^{{12}}$', f'\\$$2^{{13}}$', f'\\$$2^{{14}}$', f'\\$$2^{{15}}$', f'\\$$2^{{16}}$', f'\\$$2^{{17}}$', f'\\$$2^{{18}}$', f'\\$$2^{{19}}$'])\nax[0].set_title('Defaulted Loans', fontsize = 16)\nax[0].text(27000, 12288, f'     $R^2 = {rs1:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'gray', boxstyle = 'round,pad=0.3'))\nax[0].text(24000, 12288, '\\u2013', color='darkorange', ha='left', va='center', fontsize=15, fontweight='bold')\n\n# Scatterplot and regression line for borrower income by loan amount of repaid loans\nax[1] = sns.scatterplot(data = repaid, x = 'loan_amnt', y = 'person_income', color = 'darkorange', edgecolor = 'darkorange', alpha = 0.5, ax = ax[1])\nsns.regplot(data = repaid, x = 'loan_amnt', y = 'person_income', scatter = False, line_kws={'color': 'purple'}, ax = ax[1])\nax[1].set_yscale('log', base = 2)\nax[1].set_xlabel('')\nax[1].set_xticks([0, 5000, 10000, 15000, 20000, 25000, 30000, 35000])\nax[1].set_xticklabels(['$0', '$5000', '$10000', '$15000', '$20000', '$25000', '$30000', '$35000'], rotation=30)\nax[1].set_ylabel('')\nax[1].set_yticks([2**14, 2**16, 2**18, 2**20, 2**22])\nax[1].set_yticklabels([f'\\$$2^{{14}}$', f'\\$$2^{{16}}$', f'\\$$2^{{18}}$', f'\\$$2^{{20}}$', f'\\$$2^{{22}}$'])\nax[1].set_title('Repaid Loans', fontsize = 16)\nax[1].text(27000, 12288, f'     $R^2 = {rs2:.3f}$', ha = 'center', va = 'center', fontsize = 9, \n        bbox = dict(facecolor = 'white', alpha = 0.5, edgecolor = 'gray', boxstyle = 'round,pad=0.3'))\nax[1].text(24000, 12288, '\\u2013', color='purple', ha='left', va='center', fontsize=15, fontweight='bold')\n\nfig.suptitle('Borrower\\'s Income by Loan Amount Displayed by Loan Repayment Status', fontsize = 18)\nfig.text(0.475, 0.05, 'Loan Amount', fontsize = 14)\n\n\nText(0.475, 0.05, 'Loan Amount')\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Additional figure\n\n# Creating subplots of loan-percent-income by person age (for each loan grade)\n# fig, ax = plt.subplots(1, 1, figsize = (3, 3))\nsns.relplot(train_viz, x = 'person_age', y = 'loan_percent_income', col = 'loan_grade')\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\nCode Description\nAnalysis of the above figures.\n\n\n\n\n\nCode\n# Summary Statistics\n\n# Helper method to calculate coefficient of variation (%)\ndef cv(col):\n    return (col.std() / col.mean()) * 100\n\n\nIn creating the table above, I looked up how to calculate the CV for each of the columns to more easily interpret the STD and created the helper method\nAnalysis of the summary statistics table."
  },
  {
    "objectID": "posts/post_2/index.html#feature-selection",
    "href": "posts/post_2/index.html#feature-selection",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Feature Selection",
    "text": "Feature Selection\nCode Description\nAnalysis of feature selection."
  },
  {
    "objectID": "posts/post_2/index.html#creating-a-scoring-function",
    "href": "posts/post_2/index.html#creating-a-scoring-function",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Creating a Scoring Function",
    "text": "Creating a Scoring Function\nCode Description\nAnalysis of creating scoring function."
  },
  {
    "objectID": "posts/post_2/index.html#choosing-a-threshold",
    "href": "posts/post_2/index.html#choosing-a-threshold",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Choosing a Threshold",
    "text": "Choosing a Threshold\nCode Description\nAnalysis of choosing a threshold."
  },
  {
    "objectID": "posts/post_2/index.html#perspective-of-the-bank",
    "href": "posts/post_2/index.html#perspective-of-the-bank",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Bank",
    "text": "Perspective of the Bank\nCode Description\nAnalysis of model evaluation from the perspective of the bank."
  },
  {
    "objectID": "posts/post_2/index.html#perspective-of-the-borrower",
    "href": "posts/post_2/index.html#perspective-of-the-borrower",
    "title": "Post 2 - Exploring Automated Decision Models",
    "section": "Perspective of the Borrower",
    "text": "Perspective of the Borrower\nCode Description\nAnalysis of model evaluation from the perspective of the borrower."
  }
]